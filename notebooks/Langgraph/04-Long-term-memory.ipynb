{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc0ce639",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# Content\n",
    "\n",
    "\n",
    "### 1. [Map Reduce](#map-reduce)\n",
    "\n",
    "### 2. [Short Term vs Long Term Memory](#short-term-vs-long-term-memory)\n",
    "\n",
    "### 3. [Chatbot with Profile Schema](#chatbot-with-profile-schema)\n",
    "\n",
    "### 4. [Chatbot with Profile Collection](#chatbot-with-profile-collection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b2aa0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in library\n",
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import (\n",
    "    Annotated,\n",
    "    Any,\n",
    "    Generator,\n",
    "    Iterable,\n",
    "    Literal,\n",
    "    Optional,\n",
    "    TypedDict,\n",
    "    Union,\n",
    ")\n",
    "\n",
    "# Standard imports\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "\n",
    "custom_theme = Theme(\n",
    "    {\n",
    "        \"white\": \"#FFFFFF\",  # Bright white\n",
    "        \"info\": \"#00FF00\",  # Bright green\n",
    "        \"warning\": \"#FFD700\",  # Bright gold\n",
    "        \"error\": \"#FF1493\",  # Deep pink\n",
    "        \"success\": \"#00FFFF\",  # Cyan\n",
    "        \"highlight\": \"#FF4500\",  # Orange-red\n",
    "    }\n",
    ")\n",
    "console = Console(theme=custom_theme)\n",
    "\n",
    "# Visualization\n",
    "# import matplotlib.pyplot as pltife\n",
    "\n",
    "# NumPy settings\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "# Polars settings\n",
    "pl.Config.set_fmt_str_lengths(1_000)\n",
    "pl.Config.set_tbl_cols(n=1_000)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_up_from_current_directory(*, go_up: int = 1) -> None:\n",
    "    \"\"\"This is used to up a number of directories.\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    go_up: int, default=1\n",
    "        This indicates the number of times to go back up from the current directory.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import sys\n",
    "\n",
    "    CONST: str = \"../\"\n",
    "    NUM: str = CONST * go_up\n",
    "\n",
    "    # Goto the previous directory\n",
    "    prev_directory = os.path.join(os.path.dirname(__name__), NUM)\n",
    "    # Get the 'absolute path' of the previous directory\n",
    "    abs_path_prev_directory = os.path.abspath(prev_directory)\n",
    "\n",
    "    # Add the path to the System paths\n",
    "    sys.path.insert(0, abs_path_prev_directory)\n",
    "    print(abs_path_prev_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d4f1fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/neidu/Desktop/Projects/Personal/My_Projects/AI-Tutorials\n"
     ]
    }
   ],
   "source": [
    "go_up_from_current_directory(go_up=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a52381e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from schemas import ModelEnum  # noqa: E402\n",
    "from settings import refresh_settings  # noqa: E402\n",
    "from src.utilities.llm_utils import (\n",
    "    LLMResponse,\n",
    "    convert_openai_messages_to_string,\n",
    "    convert_to_openai_messages,\n",
    ")  # noqa: E402\n",
    "from utilities.client_utils import check_rate_limit  # noqa: E402\n",
    "\n",
    "settings = refresh_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6270200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": {\n",
      "    \"label\": \"sk-or-v1-902...c45\",\n",
      "    \"limit\": 5,\n",
      "    \"usage\": 3.7436591165,\n",
      "    \"is_provisioning_key\": false,\n",
      "    \"limit_remaining\": 1.2563408835,\n",
      "    \"is_free_tier\": false,\n",
      "    \"rate_limit\": {\n",
      "      \"requests\": 20,\n",
      "      \"interval\": \"10s\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "check_rate_limit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19e52c4",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### LangGraph Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82f1daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    AnyMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    ToolMessage,\n",
    ")\n",
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "from langchain_litellm import ChatLiteLLM\n",
    "from langchain_tavily import TavilySearch\n",
    "from langfuse.langchain import CallbackHandler\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.types import Command, interrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9c6b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "\n",
    "subject_prompt: str = \"\"\"\n",
    "<system>\n",
    "\n",
    "Generate a list of 3 sub-topics that are all \n",
    "related to this overall topic:\n",
    "\n",
    "<topic>\n",
    "{topic!r} \n",
    "</topic>\n",
    "\n",
    "</system>\n",
    "\"\"\"\n",
    "\n",
    "joke_prompt: str = \"\"\"\n",
    "<system>\n",
    "Generate a joke about:\n",
    "\n",
    "<subject>\n",
    "{subject!r}\n",
    "</subject>\n",
    "\n",
    "</system>\n",
    "\"\"\"\n",
    "\n",
    "best_joke_prompt: str = \"\"\"\n",
    "<system>\n",
    "Below are a bunch of jokes about:\n",
    "\n",
    "<topic>\n",
    "{topic!r}.\n",
    "</topic>\n",
    "\n",
    "Select the best one! Return the ID of the best one, starting 0 \n",
    "as the ID for the first joke. \n",
    "<jokes>\n",
    "{jokes}\n",
    "</jokes>\n",
    "\n",
    "<output>\n",
    "Return the ID of the best joke as an integer.\n",
    "</output>\n",
    "\n",
    "</system>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d08894",
   "metadata": {},
   "source": [
    "### Initialize the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94400eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">api_key</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SecretStr</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'**********'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">base_url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'https://openrouter.ai/api/v1'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'meta-llama/llama-3.1-8b-instruct'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mapi_key\u001b[0m=\u001b[1;35mSecretStr\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'**********'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mbase_url\u001b[0m=\u001b[32m'https://openrouter.ai/api/v1'\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'meta-llama/llama-3.1-8b-instruct'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = LLMResponse(\n",
    "    api_key=settings.OPENROUTER_API_KEY,\n",
    "    base_url=settings.OPENROUTER_URL,\n",
    "    model=ModelEnum.LLAMA_3p1_8B_INSTRUCT_REMOTE.value,  # noqa: E501\n",
    ")\n",
    "console.print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dc3266b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Raw response: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletion</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gen-1750629472-n7j8VIqehJwBDHISojGX'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"&lt;system&gt;\\n\\nHere are 3 sub-topics related to 'Types </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of animals':\\n\\n1. **Mammals**: This sub-topic includes animals that are warm-blooded, have hair or fur, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">produce milk to feed their young. Examples of mammals include lions, elephants, and humans.\\n\\n2. **Birds**: This </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sub-topic includes animals that have feathers, wings, and lay eggs. Examples of birds include eagles, parrots, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">robins.\\n\\n3. **Reptiles**: This sub-topic includes animals that have scales, lay eggs, and are cold-blooded. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Examples of reptiles include snakes, lizards, and turtles.\\n\\n&lt;/system&gt;\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">annotations</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">audio</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">reasoning</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">native_finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span><span style=\"font-weight: bold\">)]</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1750629472</span>, <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'meta-llama/llama-3.1-8b-instruct'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_510c177af0'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">136</span>, <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">67</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">203</span>, <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Groq'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Raw response: \u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'gen-1750629472-n7j8VIqehJwBDHISojGX'\u001b[0m, \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m, \n",
       "\u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m\"\u001b[0m\u001b[32m<\u001b[0m\u001b[32msystem\u001b[0m\u001b[32m>\\n\\nHere are 3 sub-topics related to 'Types \u001b[0m\n",
       "\u001b[32mof animals':\\n\\n1. **Mammals**: This sub-topic includes animals that are warm-blooded, have hair or fur, and \u001b[0m\n",
       "\u001b[32mproduce milk to feed their young. Examples of mammals include lions, elephants, and humans.\\n\\n2. **Birds**: This \u001b[0m\n",
       "\u001b[32msub-topic includes animals that have feathers, wings, and lay eggs. Examples of birds include eagles, parrots, and \u001b[0m\n",
       "\u001b[32mrobins.\\n\\n3. **Reptiles**: This sub-topic includes animals that have scales, lay eggs, and are cold-blooded. \u001b[0m\n",
       "\u001b[32mExamples of reptiles include snakes, lizards, and turtles.\\n\\n</system\u001b[0m\u001b[32m>\u001b[0m\u001b[32m\"\u001b[0m, \u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m, \n",
       "\u001b[33mannotations\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33maudio\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mreasoning\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mnative_finish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \n",
       "\u001b[33mcreated\u001b[0m=\u001b[1;36m1750629472\u001b[0m, \u001b[33mmodel\u001b[0m=\u001b[32m'meta-llama/llama-3.1-8b-instruct'\u001b[0m, \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m, \u001b[33mservice_tier\u001b[0m=\u001b[3;35mNone\u001b[0m, \n",
       "\u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_510c177af0'\u001b[0m, \u001b[33musage\u001b[0m=\u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m136\u001b[0m, \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m67\u001b[0m, \n",
       "\u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m203\u001b[0m, \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mprompt_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mprovider\u001b[0m=\u001b[32m'Groq'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Response: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">system</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
       "\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">Here are </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #000000; text-decoration-color: #000000\"> sub-topics related to </span><span style=\"color: #008000; text-decoration-color: #008000\">'Types of animals'</span><span style=\"color: #000000; text-decoration-color: #000000\">:</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #000000; text-decoration-color: #000000\">. **Mammals**: This sub-topic includes animals that are warm-blooded, have hair or fur, and produce milk to feed </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">their young. Examples of mammals include lions, elephants, and humans.</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #000000; text-decoration-color: #000000\">. **Birds**: This sub-topic includes animals that have feathers, wings, and lay eggs. Examples of birds include </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">eagles, parrots, and robins.</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #000000; text-decoration-color: #000000\">. **Reptiles**: This sub-topic includes animals that have scales, lay eggs, and are cold-blooded. Examples of </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">reptiles include snakes, lizards, and turtles.</span>\n",
       "\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">system</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Response: \u001b[1m<\u001b[0m\u001b[1;95msystem\u001b[0m\u001b[39m>\u001b[0m\n",
       "\n",
       "\u001b[39mHere are \u001b[0m\u001b[1;36m3\u001b[0m\u001b[39m sub-topics related to \u001b[0m\u001b[32m'Types of animals'\u001b[0m\u001b[39m:\u001b[0m\n",
       "\n",
       "\u001b[1;36m1\u001b[0m\u001b[39m. **Mammals**: This sub-topic includes animals that are warm-blooded, have hair or fur, and produce milk to feed \u001b[0m\n",
       "\u001b[39mtheir young. Examples of mammals include lions, elephants, and humans.\u001b[0m\n",
       "\n",
       "\u001b[1;36m2\u001b[0m\u001b[39m. **Birds**: This sub-topic includes animals that have feathers, wings, and lay eggs. Examples of birds include \u001b[0m\n",
       "\u001b[39meagles, parrots, and robins.\u001b[0m\n",
       "\n",
       "\u001b[1;36m3\u001b[0m\u001b[39m. **Reptiles**: This sub-topic includes animals that have scales, lay eggs, and are cold-blooded. Examples of \u001b[0m\n",
       "\u001b[39mreptiles include snakes, lizards, and turtles.\u001b[0m\n",
       "\n",
       "\u001b[39m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95msystem\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages: list[dict[str, str]] = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": subject_prompt.format(topic=\"Types of animals\"),\n",
    "    }\n",
    "]\n",
    "\n",
    "(response, raw_response) = await llm.ainvoke(messages=messages)\n",
    "console.print(f\"Raw response: {raw_response}\")\n",
    "console.print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa09db5",
   "metadata": {},
   "source": [
    "## Parallelizing Joke Generation\n",
    "\n",
    "- Define a graph that will:\n",
    "  - take a user input topic\n",
    "  - produce a list of joke topics fro it\n",
    "  - send each joke topic to the LLM\n",
    "- The state has a `jokes` key that will accumulate jokes from parallelized joke generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c1250a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Subjects(BaseModel):\n",
    "    subjects: list[str] = Field(description=\"List of subjects related to the topic.\")\n",
    "\n",
    "\n",
    "class BestJoke(BaseModel):\n",
    "    id: int = Field(description=\"ID of the best joke selected from the list of jokes.\")\n",
    "\n",
    "\n",
    "class OverallState(TypedDict):\n",
    "    topic: str\n",
    "    subjects: list[str]\n",
    "    jokes: Annotated[list[str], add_messages]\n",
    "    best_selected_joke: str\n",
    "\n",
    "\n",
    "class JokeState(TypedDict):\n",
    "    subject: str\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    joke: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273e25bd",
   "metadata": {},
   "source": [
    "#### Test The Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56096246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n<system>\\n\\nGenerate a list of 3 sub-topics that are all \\nrelated to this overall topic:\\n\\n<topic>\\n'types of animals' \\n</topic>\\n\\n</system>\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_prompt.format(topic=\"types of animals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "810c534d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletion</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gen-1750629477-clIYx8YAx0rLYY1nf29w'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{\"subjects\": [\"mammals\", \"reptiles\", \"amphibians\"]}'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">annotations</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">audio</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">reasoning</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">native_finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1750629477</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'meta-llama/llama-3.1-8b-instruct'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">332</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">352</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Together'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'gen-1750629477-clIYx8YAx0rLYY1nf29w'\u001b[0m,\n",
       "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,\n",
       "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"subjects\": \u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"mammals\", \"reptiles\", \"amphibians\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "                \u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[33mannotations\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33maudio\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mreasoning\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[33mnative_finish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1750629477\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'meta-llama/llama-3.1-8b-instruct'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "    \u001b[33mservice_tier\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33msystem_fingerprint\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m20\u001b[0m,\n",
       "        \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m332\u001b[0m,\n",
       "        \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m352\u001b[0m,\n",
       "        \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mprompt_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mprovider\u001b[0m=\u001b[32m'Together'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Subjects</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">subjects</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'mammals'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reptiles'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'amphibians'</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSubjects\u001b[0m\u001b[1m(\u001b[0m\u001b[33msubjects\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'mammals'\u001b[0m, \u001b[32m'reptiles'\u001b[0m, \u001b[32m'amphibians'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using a custom structured output model\n",
    "# console.print(structured_output)\n",
    "structured_output, raw_response = await llm.get_structured_response(\n",
    "    message=subject_prompt.format(topic=\"animals\"),\n",
    "    response_model=Subjects,\n",
    ")\n",
    "console.print(raw_response)\n",
    "print(\"----\" * 50)\n",
    "console.print(structured_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fbdb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_topics(state: OverallState) -> dict[str, Any]:\n",
    "    \"\"\"Generate a list of subjects based on a given topic.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        state (OverallState): The current state containing the topic to generate subjects for.\n",
    "            Expected to have a 'topic' key with a string value.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        dict[str, Any]\n",
    "\n",
    "    \"\"\"\n",
    "    prompt: str = subject_prompt.format(topic=state[\"topic\"])\n",
    "\n",
    "    response, _ = await llm.get_structured_response(message=prompt, response_model=Subjects)\n",
    "    return {\"subjects\": response.subjects}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4f24cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subjects': ['Mammals', 'Birds', 'Reptiles']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await generate_topics({\"topic\": \"Types of animals\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3a5799",
   "metadata": {},
   "source": [
    "### Send Function\n",
    "\n",
    "- In LangGraph, Nodes and Edges usually share a predefined state. However, for dynamic cases like map-reduce, LangGraph uses `Send` objects in conditional edges.\n",
    "- It can be used to parallelize tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28261c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.constants import Send\n",
    "\n",
    "\n",
    "def continue_to_jokes(state: OverallState) -> list[Send]:\n",
    "    \"\"\"\n",
    "    Generate N number of jokes in parallel by sending them to the required nodes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    state : OverallState\n",
    "        The current state containing subjects for joke generation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[Send]\n",
    "    \"\"\"\n",
    "    return [Send(\"generate_joke\", {\"subject\": s}) for s in state[\"subjects\"]]\n",
    "\n",
    "\n",
    "async def generate_joke(state: JokeState) -> dict[str, Any]:\n",
    "    prompt: str = joke_prompt.format(subject=state[\"subject\"])\n",
    "    response, _ = await llm.get_structured_response(message=prompt, response_model=Joke)\n",
    "\n",
    "    return {\"jokes\": [response.joke]}\n",
    "\n",
    "\n",
    "async def select_best_joke(state: OverallState) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Select the best joke from a list of jokes based on a given topic.\n",
    "    This is a reduction step.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    state : OverallState\n",
    "        The current state containing jokes and topic for selection.\n",
    "        Expected keys:\n",
    "            - jokes: list[str | HumanMessage]\n",
    "            - topic: str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, Any]\n",
    "        Dictionary containing the best selected joke.\n",
    "        Keys:\n",
    "            - best_selected_joke: str\n",
    "    \"\"\"\n",
    "    if isinstance(state[\"jokes\"][0], HumanMessage):\n",
    "        state[\"jokes\"] = [j.content for j in state[\"jokes\"]]\n",
    "    jokes: str = \"\\n\\n\".join(state[\"jokes\"])\n",
    "    prompt: str = best_joke_prompt.format(topic=state[\"topic\"], jokes=jokes)\n",
    "    response, _ = await llm.get_structured_response(message=prompt, response_model=BestJoke)\n",
    "\n",
    "    return {\"best_selected_joke\": state[\"jokes\"][response.id]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e13262e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Prompt for selecting the best joke: ====\n",
      "\n",
      "<system>\n",
      "Below are a bunch of jokes about:\n",
      "\n",
      "<topic>\n",
      "'types of animals'.\n",
      "</topic>\n",
      "\n",
      "Select the best one! Return the ID of the best one, starting 0 \n",
      "as the ID for the first joke. \n",
      "<jokes>\n",
      "Why do seagulls fly over the sea?\n",
      "\n",
      "Why dont mammals ever get locked out of their homes? Because they always carry their keys with them!\n",
      "\n",
      "Why dont reptiles ever forget? Because no one ever lizard them a thing!\n",
      "</jokes>\n",
      "\n",
      "<output>\n",
      "Return the ID of the best joke as an integer.\n",
      "</output>\n",
      "\n",
      "</system>\n",
      "\n",
      "==== Response for selecting the best joke: ====\n",
      "0\n",
      "==== Best joke selected: ====\n",
      "result = {'best_selected_joke': 'Why do seagulls fly over the sea?'}\n"
     ]
    }
   ],
   "source": [
    "_jokes: list[str] = [\n",
    "    \"Why do seagulls fly over the sea?\",\n",
    "    \"Why dont mammals ever get locked out of their homes? Because \"\n",
    "    \"they always carry their keys with them!\",\n",
    "    \"Why dont reptiles ever forget? Because no one ever lizard them a thing!\",\n",
    "]\n",
    "\n",
    "jokes: str = \"\\n\\n\".join(_jokes)\n",
    "prompt: str = best_joke_prompt.format(topic=\"types of animals\", jokes=jokes)\n",
    "print(\"==== Prompt for selecting the best joke: ====\")\n",
    "print(prompt)\n",
    "resp, _ = await llm.get_structured_response(message=prompt, response_model=BestJoke)\n",
    "print(\"==== Response for selecting the best joke: ====\")\n",
    "print(resp.id)\n",
    "result = {\"best_selected_joke\": _jokes[resp.id]}\n",
    "print(\"==== Best joke selected: ====\")\n",
    "print(f\"{result = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2b3fb9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_builder = StateGraph(OverallState)\n",
    "\n",
    "# Add nodes\n",
    "graph_builder.add_node(\"generate_topics\", generate_topics)\n",
    "graph_builder.add_node(\"generate_joke\", generate_joke)\n",
    "graph_builder.add_node(\"select_best_joke\", select_best_joke)\n",
    "\n",
    "# Add edges\n",
    "graph_builder.add_edge(START, \"generate_topics\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"generate_topics\",\n",
    "    # Generate jokes in parallel by `Sending` the jokes the `generate_joke` node\n",
    "    continue_to_jokes,\n",
    "    [\"generate_joke\"],\n",
    ")\n",
    "graph_builder.add_edge(\"generate_joke\", \"select_best_joke\")\n",
    "graph_builder.add_edge(\"select_best_joke\", END)\n",
    "\n",
    "# Compile the graph\n",
    "graph = graph_builder.compile().with_config(run_name=\"Generate Jokes\")\n",
    "\n",
    "# Visualize the graph\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115a4c18",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Test The Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d437b4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generate_topics': {'subjects': ['Mammals', 'Birds', 'Reptiles']}}\n",
      "{'generate_joke': {'jokes': ['Why did the mammal go to the doctor? Because it had a wild time!']}}\n",
      "{'generate_joke': {'jokes': ['Why did the bird go to the doctor? Because it had a fowl cough!']}}\n",
      "{'generate_joke': {'jokes': ['Why did the reptile go to the party? Because he was a snappy dresser!']}}\n",
      "{'select_best_joke': {'best_selected_joke': 'Why did the mammal go to the doctor? Because it had a wild time!'}}\n"
     ]
    }
   ],
   "source": [
    "topic: str = \"types of animals\"\n",
    "\n",
    "async for s in graph.astream({\"topic\": topic}):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117a299a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79d12cf0",
   "metadata": {},
   "source": [
    "<a id=\"short-term-vs-long-term-memory\"></a>\n",
    "# 2. Short Term vs Long Term Memory\n",
    "\n",
    "## Memory\n",
    "\n",
    "- Memory is a cognitive function that allows people to store, retrieve, and use information to understand their present and future.\n",
    "\n",
    "- There are various long-term memory types that can be used in AI applications.\n",
    "- We'll build a chatbot that uses both `short-term` (within-thread) and `long-term` (across-thread) memory.\n",
    "- We'll focus on long-term semantic memory, which will be facts about the user.\n",
    "- These long-term memories will be used to create a personalized chatbot that can remember facts about the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b6c15a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### LangGraph Store\n",
    "\n",
    "- The [LangGraph Memory Store](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore) provides a way to store and retrieve information across threads in LangGraph.\n",
    "- This is an open source base class for persistent key-value stores.\n",
    "\n",
    "- When storing objects (e.g., memories) in the Store, we provide:\n",
    "  - The `namespace` for the object, a tuple (similar to directories)\n",
    "  - the `object key` (similar to filenames)\n",
    "  - the `object value` (similar to file contents)\n",
    "  - We use the `put` method to save an object to the store by `namespace` and `key`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9253bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "in_memory_store = InMemoryStore()\n",
    "\n",
    "# Create a namespace to store the data\n",
    "user_id: str = \"1\"\n",
    "prefix: str = \"memories\"\n",
    "namespace_for_memory: tuple[str, str] = (prefix, user_id)\n",
    "key: str = str(uuid.uuid4())\n",
    "\n",
    "# The value MUST be a dictionary\n",
    "value: dict[str, Any] = {\"food_preference\": \"I like pizza\"}\n",
    "\n",
    "# Save the data\n",
    "in_memory_store.put(namespace_for_memory, key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db82591",
   "metadata": {},
   "source": [
    "#### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1da124c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:58:24] </span><span style=\"font-weight: bold\">[</span>                                                                                        <a href=\"file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_40757/1831516903.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1831516903.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_40757/1831516903.py#2\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Item</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">namespace</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'memories'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">key</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'9cad7428-12fa-4f65-baf4-f391f008669e'</span>,        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #808000; text-decoration-color: #808000\">value</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'food_preference'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I like pizza'</span><span style=\"font-weight: bold\">}</span>,                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #808000; text-decoration-color: #808000\">created_at</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'2025-06-22T21:58:24.692778+00:00'</span>,                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #808000; text-decoration-color: #808000\">updated_at</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'2025-06-22T21:58:24.692783+00:00'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">score</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">]</span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:58:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0m                                                                                        \u001b]8;id=955097;file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_40757/1831516903.py\u001b\\\u001b[2m1831516903.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=495530;file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_40757/1831516903.py#2\u001b\\\u001b[2m2\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m    \u001b[1;35mItem\u001b[0m\u001b[1m(\u001b[0m\u001b[33mnamespace\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'memories'\u001b[0m, \u001b[32m'1'\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mkey\u001b[0m=\u001b[32m'9cad7428-12fa-4f65-baf4-f391f008669e'\u001b[0m,        \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[33mvalue\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'food_preference'\u001b[0m: \u001b[32m'I like pizza'\u001b[0m\u001b[1m}\u001b[0m,                                               \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[33mcreated_at\u001b[0m=\u001b[32m'2025-06-22T21:58:24.692778+00:00'\u001b[0m,                                           \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[33mupdated_at\u001b[0m=\u001b[32m'2025-06-22T21:58:24.692783+00:00'\u001b[0m, \u001b[33mscore\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m                               \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[1m]\u001b[0m                                                                                        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "memories = in_memory_store.search(namespace_for_memory)\n",
    "console.log(memories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb37c017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['memories', '1'],\n",
       " 'key': '9cad7428-12fa-4f65-baf4-f391f008669e',\n",
       " 'value': {'food_preference': 'I like pizza'},\n",
       " 'created_at': '2025-06-22T21:58:24.692778+00:00',\n",
       " 'updated_at': '2025-06-22T21:58:24.692783+00:00',\n",
       " 'score': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memories[0].dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913d3072",
   "metadata": {},
   "source": [
    "#### Get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21f3b8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['memories', '1'],\n",
       " 'key': '9cad7428-12fa-4f65-baf4-f391f008669e',\n",
       " 'value': {'food_preference': 'I like pizza'},\n",
       " 'created_at': '2025-06-22T21:58:24.692778+00:00',\n",
       " 'updated_at': '2025-06-22T21:58:24.692783+00:00'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memories = in_memory_store.get(namespace_for_memory, key)\n",
    "memories.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1288f834",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "### Chatbot With Long Term Memory\n",
    "\n",
    "- We want a chatbot that has two types of memory:\n",
    "  - **Short-term (within-thread) memory**: Chatbot can persist conversational history and / or allow interruptions in a chat session.\n",
    "  - **Long-term (cross-thread) memory**: Chatbot can remember information about a specific user across all chat sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a74c656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.config import RunnableConfig\n",
    "from langgraph.store.base import BaseStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa874d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessageState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "\n",
    "class MessageStateValidator(BaseModel):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8ad8c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot instruction\n",
    "MODEL_SYSTEM_MESSAGE: str = \"\"\"\n",
    "<system>\n",
    "\n",
    "<role>\n",
    "You are a helpful assistant with memory that provides information about the user.\n",
    "If you have memory for this user, use it to personalize your responses.\n",
    "</role>\n",
    "\n",
    "<memory>\n",
    "{memory}\n",
    "</memory>\n",
    "\n",
    "<quality_standards>\n",
    "- **ALWAYS** use the information in memory.\n",
    "</quality_standards>\n",
    "\n",
    "</system>\n",
    "\"\"\"\n",
    "\n",
    "# Create new memory from the chat history and any existing memory\n",
    "CREATE_MEMORY_INSTRUCTION: str = \"\"\"\"\n",
    "<system>\n",
    "\n",
    "<role>\n",
    "You are collecting information about the user to personalize your responses.\n",
    "</role>\n",
    "\n",
    "<current_user_info>\n",
    "{memory}\n",
    "</current_user_info>\n",
    "\n",
    "<instruction>\n",
    "1. Review the chat history below carefully\n",
    "2. Identify new information about the user, such as:\n",
    "   - Personal details (name, location)\n",
    "   - Preferences (likes, dislikes)\n",
    "   - Interests and hobbies\n",
    "   - Past experiences\n",
    "   - Goals or future plans\n",
    "3. Merge any new information with existing memory\n",
    "4. Format the memory as a clear, bulleted list\n",
    "5. If new information conflicts with existing memory, keep the most recent version\n",
    "Remember: Only include factual information directly stated by the user. Do not make assumptions or inferences.\n",
    "</instruction>\n",
    "\n",
    "Based on the chat history below, please update the user information:\n",
    "\n",
    "<system>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075ff588",
   "metadata": {},
   "source": [
    "### Initialize the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47a2af1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">api_key</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SecretStr</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'**********'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">base_url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'https://openrouter.ai/api/v1'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'meta-llama/llama-3.1-8b-instruct'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mapi_key\u001b[0m=\u001b[1;35mSecretStr\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'**********'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mbase_url\u001b[0m=\u001b[32m'https://openrouter.ai/api/v1'\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'meta-llama/llama-3.1-8b-instruct'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = LLMResponse(\n",
    "    api_key=settings.OPENROUTER_API_KEY,\n",
    "    base_url=settings.OPENROUTER_URL,\n",
    "    model=ModelEnum.LLAMA_3p1_8B_INSTRUCT_REMOTE.value,\n",
    ")\n",
    "console.print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca64e2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def call_llm(state: MessageState, config: RunnableConfig, store: BaseStore) -> dict[str, Any]:\n",
    "    # Get the user id\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Get the memory for the user\n",
    "    prefix: str = \"memory\"\n",
    "    key = \"user_memory\"\n",
    "    namespace = (prefix, user_id)\n",
    "    existing_memory = store.get(namespace, key)\n",
    "    # existing_memory = await store.aget(namespace, key)\n",
    "\n",
    "    if existing_memory:\n",
    "        existing_memory_content = existing_memory.value.get(prefix)\n",
    "    else:\n",
    "        existing_memory_content = \"No existing memory found\"\n",
    "\n",
    "    system_message: str = MODEL_SYSTEM_MESSAGE.format(memory=existing_memory_content)\n",
    "    # Respond using memory + chat history\n",
    "    formatted_messages = convert_to_openai_messages(\n",
    "        [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    )\n",
    "    response, _ = await llm.ainvoke(messages=formatted_messages)\n",
    "\n",
    "    return {\"messages\": [AIMessage(content=response)]}\n",
    "\n",
    "\n",
    "async def write_memory(state: MessageState, config: RunnableConfig, store: BaseStore) -> None:\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    prefix: str = \"memory\"\n",
    "    key = \"user_memory\"\n",
    "    namespace = (prefix, user_id)\n",
    "    existing_memory = store.get(namespace, key)\n",
    "    # existing_memory = await store.aget(namespace, key)\n",
    "\n",
    "    if existing_memory:\n",
    "        existing_memory_content = existing_memory.value.get(prefix)\n",
    "    else:\n",
    "        existing_memory_content = \"No existing memory found\"\n",
    "\n",
    "    system_message: str = CREATE_MEMORY_INSTRUCTION.format(memory=existing_memory_content)\n",
    "    messages = convert_to_openai_messages(\n",
    "        [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    )\n",
    "    # Respond using memory + chat history\n",
    "    new_memory, _ = await llm.ainvoke(messages=messages)\n",
    "\n",
    "    # Update existing memory\n",
    "    # await store.aput(namespace, key, {prefix: new_memory.content})\n",
    "    store.put(namespace, key, {prefix: new_memory})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1f8e7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content=\"I don't have any information about you in my memory. This is our first conversation, and I don't have any prior knowledge about you. If you'd like to share your name with me, I'd be happy to learn it and remember it for future conversations.\", additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await call_llm(\n",
    "    state={\"messages\": [HumanMessage(content=\"What is my name?\")]},\n",
    "    config={\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}},\n",
    "    store=in_memory_store,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7bfae459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph\n",
    "graph_builder = StateGraph(MessageState)\n",
    "\n",
    "# Add nodes\n",
    "graph_builder.add_node(\"call_llm\", call_llm)\n",
    "graph_builder.add_node(\"write_memory\", write_memory)\n",
    "\n",
    "# Add edges\n",
    "graph_builder.add_edge(START, \"call_llm\")\n",
    "graph_builder.add_edge(\"call_llm\", \"write_memory\")\n",
    "graph_builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Long-term-memory store (across threads)\n",
    "across_thread_memory = InMemoryStore()\n",
    "# Short-term-memory store (within a thread) checkpointer\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Compile\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=within_thread_memory, store=across_thread_memory\n",
    ").with_config(run_name=\"chatbot-with-memory\")\n",
    "\n",
    "# Visualize\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbc2cfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, my name is Neidu\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, my name is Neidu\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Neidu. It's nice to meet you. I'm a helpful assistant, and I'll do my best to provide you with the information you need. I don't have any existing memory of our previous conversations, so this is the start of our interaction. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "config: dict[str, Any] = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "msgs = [\"Hello, my name is Neidu\"]\n",
    "input_state = MessageState(messages=[HumanMessage(content=msg) for msg in msgs])\n",
    "\n",
    "async for event in graph.astream(input_state, config=config, stream_mode=\"values\"):\n",
    "    for msg in event[\"messages\"]:\n",
    "        msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24c62c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, my name is Neidu\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Neidu. It's nice to meet you. I'm a helpful assistant, and I'll do my best to provide you with the information you need. I don't have any existing memory of our previous conversations, so this is the start of our interaction. How can I assist you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm an AI Engineer whos's currently working on NLP related things\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, my name is Neidu\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Neidu. It's nice to meet you. I'm a helpful assistant, and I'll do my best to provide you with the information you need. I don't have any existing memory of our previous conversations, so this is the start of our interaction. How can I assist you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm an AI Engineer whos's currently working on NLP related things\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "As an AI Engineer working on NLP (Natural Language Processing) related projects, you must be dealing with some fascinating topics. I'd like to recall that I have no prior memory of our conversation, but I can still provide general information and insights related to NLP.\n",
      "\n",
      "However, I'd like to store some information about you in my memory for future reference. So, I'll make a note that you're Neidu, an AI Engineer with a focus on NLP. This will help me provide more personalized responses in our future conversations.\n",
      "\n",
      "What specific aspects of NLP are you currently working on, such as text classification, sentiment analysis, or perhaps something more advanced like conversational AI?\n"
     ]
    }
   ],
   "source": [
    "msgs = [\"I'm an AI Engineer who's currently working on NLP related things\"]\n",
    "input_state = MessageState(messages=[HumanMessage(content=msg) for msg in msgs])\n",
    "\n",
    "async for event in graph.astream(input_state, config=config, stream_mode=\"values\"):\n",
    "    for msg in event[\"messages\"]:\n",
    "        msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31de1497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, my name is Neidu\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Neidu. It's nice to meet you. I'm a helpful assistant, and I'll do my best to provide you with the information you need. I don't have any existing memory of our previous conversations, so this is the start of our interaction. How can I assist you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm an AI Engineer whos's currently working on NLP related things\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "As an AI Engineer working on NLP (Natural Language Processing) related projects, you must be dealing with some fascinating topics. I'd like to recall that I have no prior memory of our conversation, but I can still provide general information and insights related to NLP.\n",
      "\n",
      "However, I'd like to store some information about you in my memory for future reference. So, I'll make a note that you're Neidu, an AI Engineer with a focus on NLP. This will help me provide more personalized responses in our future conversations.\n",
      "\n",
      "What specific aspects of NLP are you currently working on, such as text classification, sentiment analysis, or perhaps something more advanced like conversational AI?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What do you know about me so far?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, my name is Neidu\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Neidu. It's nice to meet you. I'm a helpful assistant, and I'll do my best to provide you with the information you need. I don't have any existing memory of our previous conversations, so this is the start of our interaction. How can I assist you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm an AI Engineer whos's currently working on NLP related things\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "As an AI Engineer working on NLP (Natural Language Processing) related projects, you must be dealing with some fascinating topics. I'd like to recall that I have no prior memory of our conversation, but I can still provide general information and insights related to NLP.\n",
      "\n",
      "However, I'd like to store some information about you in my memory for future reference. So, I'll make a note that you're Neidu, an AI Engineer with a focus on NLP. This will help me provide more personalized responses in our future conversations.\n",
      "\n",
      "What specific aspects of NLP are you currently working on, such as text classification, sentiment analysis, or perhaps something more advanced like conversational AI?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What do you know about me so far?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've made a note about you in my memory. Here's what I know so far:\n",
      "\n",
      "* Your name is Neidu.\n",
      "* You're an AI Engineer.\n",
      "* You're currently working on projects related to NLP (Natural Language Processing).\n",
      "\n",
      "That's the extent of my knowledge about you so far. I'm happy to learn more and update my memory as we continue our conversation!\n"
     ]
    }
   ],
   "source": [
    "msgs = [\"What do you know about me so far?\"]\n",
    "input_state = MessageState(messages=[HumanMessage(content=msg) for msg in msgs])\n",
    "\n",
    "async for event in graph.astream(input_state, config=config, stream_mode=\"values\"):\n",
    "    for msg in event[\"messages\"]:\n",
    "        msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39fe859a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, my name is Neidu\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Neidu. It's nice to meet you. I'm a helpful assistant, and I'll do my best to provide you with the information you need. I don't have any existing memory of our previous conversations, so this is the start of our interaction. How can I assist you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm an AI Engineer whos's currently working on NLP related things\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "As an AI Engineer working on NLP (Natural Language Processing) related projects, you must be dealing with some fascinating topics. I'd like to recall that I have no prior memory of our conversation, but I can still provide general information and insights related to NLP.\n",
      "\n",
      "However, I'd like to store some information about you in my memory for future reference. So, I'll make a note that you're Neidu, an AI Engineer with a focus on NLP. This will help me provide more personalized responses in our future conversations.\n",
      "\n",
      "What specific aspects of NLP are you currently working on, such as text classification, sentiment analysis, or perhaps something more advanced like conversational AI?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What do you know about me so far?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've made a note about you in my memory. Here's what I know so far:\n",
      "\n",
      "* Your name is Neidu.\n",
      "* You're an AI Engineer.\n",
      "* You're currently working on projects related to NLP (Natural Language Processing).\n",
      "\n",
      "That's the extent of my knowledge about you so far. I'm happy to learn more and update my memory as we continue our conversation!\n"
     ]
    }
   ],
   "source": [
    "# Chat history\n",
    "state = graph.get_state(config=config).values\n",
    "\n",
    "for m in state[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11cb69f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'namespace'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'memory'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user_memory'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'memory'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2025-06-22T21:58:33.899738+00:00'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'updated_at'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2025-06-22T21:58:33.899742+00:00'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'namespace'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'memory'\u001b[0m, \u001b[32m'1'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'key'\u001b[0m: \u001b[32m'user_memory'\u001b[0m,\n",
       "    \u001b[32m'value'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'memory'\u001b[0m: \u001b[32m''\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'created_at'\u001b[0m: \u001b[32m'2025-06-22T21:58:33.899738+00:00'\u001b[0m,\n",
       "    \u001b[32m'updated_at'\u001b[0m: \u001b[32m'2025-06-22T21:58:33.899742+00:00'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# namespace for the memory to save\n",
    "user_id: str = \"1\"\n",
    "prefix: str = \"memory\"\n",
    "key = \"user_memory\"\n",
    "namespace = (prefix, user_id)\n",
    "existing_memory = across_thread_memory.get(namespace, key)\n",
    "console.print(existing_memory.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84ae042",
   "metadata": {},
   "source": [
    "#### Use Another Thread\n",
    "\n",
    "- The chatbot is now in a different thread and has no context of the previous conversation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What do you know about me so far?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What do you know about me so far?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I don't have any information about you in my memory yet. This is our first conversation, and I'm starting from a blank slate. I'm ready to learn more about you and tailor my responses to your interests and needs. What would you like to talk about?\n"
     ]
    }
   ],
   "source": [
    "config_2: dict[str, Any] = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"1\"}}\n",
    "msgs = [\"What do you know about me so far?\"]\n",
    "input_state = MessageState(messages=[HumanMessage(content=msg) for msg in msgs])\n",
    "\n",
    "async for event in graph.astream(input_state, config=config_2, stream_mode=\"values\"):\n",
    "    for msg in event[\"messages\"]:\n",
    "        msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9627b30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a5d07a4",
   "metadata": {},
   "source": [
    "<a id=\"chatbot-with-profile-schema\"></a>\n",
    "\n",
    "# Chatbot with Profile Schema\n",
    "\n",
    "- We introduced the LangGraph Memory Store as a way to save and retrieve long-term memories.\n",
    "- We built a simple chatbot that uses both short-term (within-thread) and long-term (across-thread) memory.\n",
    "- It saved long-term semantic memory (facts about the user) \"in the hot path\", as the user is chatting with it.\n",
    "- Our chatbot saved memories as a string. In practice, we often want memories to have a structure.\n",
    "\n",
    "\n",
    "## Profiles\n",
    "\n",
    "- For example, memories can be a single, continuously updated schema.\n",
    "- In our case, we want this to be a single user profile.\n",
    "\n",
    "- We'll extend our chatbot to save semantic memories to a single user profile.\n",
    "\n",
    "- We'll also introduce a library, `Trustcall`, to update this schema with new information.\n",
    "\n",
    "### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b13a51ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserProfile(user_name='Neidu', interests=['AI', 'NLP', 'Spiritual Growth'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class UserProfile(BaseModel):\n",
    "    user_name: str = Field(description=\"User's preferred name\")\n",
    "    interests: list[str] = Field(default_factory=list, description=\"List of user's interests\")\n",
    "\n",
    "\n",
    "# Save a schema to the store\n",
    "user_profile = UserProfile(user_name=\"Neidu\", interests=[\"AI\", \"NLP\", \"Spiritual Growth\"])\n",
    "user_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d86d9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a store\n",
    "in_memory_store = InMemoryStore()\n",
    "\n",
    "user_id: str = \"1\"\n",
    "prefix: str = \"memory\"\n",
    "key = \"user_profile\"\n",
    "namespace = (prefix, user_id)\n",
    "across_thread_memory.put(namespace, key, user_profile)\n",
    "\n",
    "in_memory_store.put(namespace, key, user_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'namespace'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'memory'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user_profile'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UserProfile</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">user_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Neidu'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">interests</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'AI'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'NLP'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Spiritual Growth'</span><span style=\"font-weight: bold\">])</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2025-06-22T21:58:38.700302+00:00'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'updated_at'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2025-06-22T21:58:38.700303+00:00'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'namespace'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'memory'\u001b[0m, \u001b[32m'1'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'key'\u001b[0m: \u001b[32m'user_profile'\u001b[0m,\n",
       "    \u001b[32m'value'\u001b[0m: \u001b[1;35mUserProfile\u001b[0m\u001b[1m(\u001b[0m\u001b[33muser_name\u001b[0m=\u001b[32m'Neidu'\u001b[0m, \u001b[33minterests\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'AI'\u001b[0m, \u001b[32m'NLP'\u001b[0m, \u001b[32m'Spiritual Growth'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'created_at'\u001b[0m: \u001b[32m'2025-06-22T21:58:38.700302+00:00'\u001b[0m,\n",
       "    \u001b[32m'updated_at'\u001b[0m: \u001b[32m'2025-06-22T21:58:38.700303+00:00'\u001b[0m,\n",
       "    \u001b[32m'score'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Retrieve the data\n",
    "\n",
    "for data in in_memory_store.search(namespace):\n",
    "    console.print(data.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c2fbcc",
   "metadata": {},
   "source": [
    "## Chatbot With Profile Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44d09c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:58:40] </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UserProfile</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">user_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Neidu'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">interests</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'AI'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'NLP'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'spiritual growth'</span><span style=\"font-weight: bold\">])</span>             <a href=\"file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_40757/3874973300.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3874973300.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_40757/3874973300.py#10\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:58:40]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;35mUserProfile\u001b[0m\u001b[1m(\u001b[0m\u001b[33muser_name\u001b[0m=\u001b[32m'Neidu'\u001b[0m, \u001b[33minterests\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'AI'\u001b[0m, \u001b[32m'NLP'\u001b[0m, \u001b[32m'spiritual growth'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m             \u001b]8;id=374492;file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_40757/3874973300.py\u001b\\\u001b[2m3874973300.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=575393;file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_40757/3874973300.py#10\u001b\\\u001b[2m10\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's test the user profile with structured outputs\n",
    "message: str = (\n",
    "    \"I'm Neidu and I'm a AI Engineer. I love working on AI and NLP \"\n",
    "    \"related projects. I'm also looking for spiritual growth.\"\n",
    ")\n",
    "\n",
    "response, _ = await llm.get_structured_response(message=message, response_model=UserProfile)\n",
    "console.log(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0108baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletion</span><span style=\"font-weight: bold\">(</span>                                                                          <a href=\"file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_40757/1812234214.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1812234214.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_40757/1812234214.py#1\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gen-1750629519-8gqP7rNNAyrGdwjntZ6G'</span>,                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>                                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>                                                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,                                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>            <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>            <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{\"user_name\": \"Neidu\", \"interests\": [\"AI\", \"NLP\", \"spiritual </span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">growth\"]}'</span>,                                                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                <span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                <span style=\"color: #808000; text-decoration-color: #808000\">annotations</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                <span style=\"color: #808000; text-decoration-color: #808000\">audio</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                <span style=\"color: #808000; text-decoration-color: #808000\">reasoning</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>            <span style=\"font-weight: bold\">)</span>,                                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>            <span style=\"color: #808000; text-decoration-color: #808000\">native_finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>        <span style=\"font-weight: bold\">)</span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"font-weight: bold\">]</span>,                                                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1750629519</span>,                                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'meta-llama/llama-3.1-8b-instruct'</span>,                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>                                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span>,                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">355</span>,                                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>        <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">381</span>,                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>                                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"font-weight: bold\">)</span>,                                                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Together'</span>                                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">)</span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m                                                                          \u001b]8;id=510594;file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_40757/1812234214.py\u001b\\\u001b[2m1812234214.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=744710;file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_40757/1812234214.py#1\u001b\\\u001b[2m1\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33mid\u001b[0m=\u001b[32m'gen-1750629519-8gqP7rNNAyrGdwjntZ6G'\u001b[0m,                                            \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m                                                                            \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m        \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m                                                                          \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m            \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,                                                        \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,                                                                     \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m            \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                               \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m            \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m                                               \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                \u001b[33mcontent\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"user_name\": \"Neidu\", \"interests\": \u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"AI\", \"NLP\", \"spiritual \u001b[0m   \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32mgrowth\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,                                                                              \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                \u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                            \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,                                                        \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                \u001b[33mannotations\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                        \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                \u001b[33maudio\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                              \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                      \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                         \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                \u001b[33mreasoning\u001b[0m=\u001b[3;35mNone\u001b[0m                                                           \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m            \u001b[1m)\u001b[0m,                                                                           \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m            \u001b[33mnative_finish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m                                                  \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m        \u001b[1m)\u001b[0m                                                                                \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[1m]\u001b[0m,                                                                                   \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33mcreated\u001b[0m=\u001b[1;36m1750629519\u001b[0m,                                                                  \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33mmodel\u001b[0m=\u001b[32m'meta-llama/llama-3.1-8b-instruct'\u001b[0m,                                            \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,                                                            \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33mservice_tier\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                                   \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33msystem_fingerprint\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                             \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33musage\u001b[0m=\u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m                                                               \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m        \u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m26\u001b[0m,                                                            \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m        \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m355\u001b[0m,                                                               \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m        \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m381\u001b[0m,                                                                \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m        \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                  \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m        \u001b[33mprompt_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m                                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[1m)\u001b[0m,                                                                                   \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33mprovider\u001b[0m=\u001b[32m'Together'\u001b[0m                                                                  \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[1m)\u001b[0m                                                                                        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.log(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34b7da2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot instruction\n",
    "MODEL_SYSTEM_MESSAGE: str = \"\"\"\n",
    "<system>\n",
    "\n",
    "<role>\n",
    "You are a helpful assistant with memory that provides information about the user.\n",
    "If you have memory for this user, use it to personalize your responses.\n",
    "</role>\n",
    "\n",
    "<memory>\n",
    "{memory}\n",
    "</memory>\n",
    "\n",
    "<quality_standards>\n",
    "- **ALWAYS** use the information in memory.\n",
    "</quality_standards>\n",
    "\n",
    "</system>\n",
    "\"\"\"\n",
    "\n",
    "# Create new memory from the chat history and any existing memory\n",
    "CREATE_MEMORY_INSTRUCTION: str = \"\"\"\"\n",
    "<system>\n",
    "\n",
    "<role>\n",
    "You are collecting information about the user to personalize your responses.\n",
    "</role>\n",
    "\n",
    "<current_user_info>\n",
    "{memory}\n",
    "</current_user_info>\n",
    "\n",
    "<instruction>\n",
    "1. If there's exisiting memory, simply update it.\n",
    "2. If new information conflicts with existing memory, keep the most recent version.\n",
    "\n",
    "Remember: Only include factual information directly stated by the user. Do not make assumptions.\n",
    "</instruction>\n",
    "\n",
    "Based on the chat history below, please update the user information:\n",
    "\n",
    "<system>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "async def call_llm(state: MessageState, config: RunnableConfig, store: BaseStore) -> dict[str, Any]:\n",
    "    # Get the user id\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Get the memory for the user\n",
    "    prefix: str = \"memory\"\n",
    "    key = \"user_memory\"\n",
    "    namespace = (prefix, user_id)\n",
    "    existing_memory = store.get(namespace, key)\n",
    "    # existing_memory = await store.aget(namespace, key)\n",
    "\n",
    "    if existing_memory and existing_memory.value:\n",
    "        memory_dict = existing_memory.value\n",
    "        formatted_memory = (\n",
    "            f\"Name: {memory_dict.get('user_name', 'Unknown')}\\n\"\n",
    "            f\"Interests: {', '.join(memory_dict.get('interests', []))}\\n\"\n",
    "        )\n",
    "    else:\n",
    "        formatted_memory = None\n",
    "\n",
    "    system_message: str = MODEL_SYSTEM_MESSAGE.format(memory=formatted_memory)\n",
    "    # Respond using memory + chat history\n",
    "    formatted_messages = convert_to_openai_messages(\n",
    "        [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    )\n",
    "    response, _ = await llm.ainvoke(messages=formatted_messages)\n",
    "\n",
    "    return {\"messages\": [AIMessage(content=response)]}\n",
    "\n",
    "\n",
    "async def write_memory(state: MessageState, config: RunnableConfig, store: BaseStore) -> None:\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    prefix: str = \"memory\"\n",
    "    key = \"user_memory\"\n",
    "    namespace = (prefix, user_id)\n",
    "    existing_memory = store.get(namespace, key)\n",
    "    # existing_memory = await store.aget(namespace, key)\n",
    "\n",
    "    if existing_memory and existing_memory.value:\n",
    "        memory_dict = existing_memory.value\n",
    "        formatted_memory = (\n",
    "            f\"Name: {memory_dict.get('user_name', 'Unknown')}\\n\"\n",
    "            f\"Interests: {', '.join(memory_dict.get('interests', []))}\\n\"\n",
    "        )\n",
    "    else:\n",
    "        formatted_memory = None\n",
    "\n",
    "    system_message: str = CREATE_MEMORY_INSTRUCTION.format(memory=formatted_memory)\n",
    "    # Respond using memory + chat history\n",
    "    messages: list[dict[str, Any]] = convert_to_openai_messages(\n",
    "        [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    )\n",
    "    string_messages = convert_openai_messages_to_string(messages)\n",
    "    new_memory, _ = await llm.get_structured_response(\n",
    "        message=string_messages, response_model=UserProfile\n",
    "    )\n",
    "\n",
    "    # Update existing memory\n",
    "    # await store.aput(namespace, key, {prefix: new_memory.content})\n",
    "    store.put(namespace, key, {prefix: new_memory.model_dump()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJIAAAFNCAIAAABkBqGXAAAAAXNSR0IArs4c6QAAHWpJREFUeJztnXlcE2fewJ8ck4QkEEhIuC+5VASFgOC1VfBE6oFo1Yq11VpttXW7bu1dW+vWfddu7Xa7lV177KrriVgVtVZrFa2KICgIHghy35CE3Ne8f4wfltWArp0nyROf71/JzOT3/JgvzzPzzDzPDIMkSYBBDaajE8A8DlgbkmBtSIK1IQnWhiRYG5KwHVh2a61erbTotRa9xmIxodEPYXMYXD6Lx2cJPdk+wVxHpcGwf7+ttkJ7p0x956paIGJ7SAg3AYsnYBIcNOq9yWjVaSx6jVXZYdT1WMKHCwfFCkOG8O2chl21dTQaTu9rN2gt0YnukfHunlLCbkXDoLvVdLu052ZRD9+dNX6uTOLHsVvR9tN2Zn97dbl65BRJzCgP+5RoN65fUF061hkZ7z5utrd9SrSHNr3GemRbk28ob1S6hEUwYBfnEMwm8kJ+Z1u9fvoL/jwB9AYfurbuVuPRb5tT0r3D4wRQC3IGbhX3XP6xa/pSf9jtP1xteo1l/+cNUxb7SgMddtJlZ9rqDSe2t8x5NdBNyIJXCsTqbDGTh3Kaxs70fnKcAQBkQdwxM7yP/KPJaoFYCsTadvFoJ8Fhyid6QYrvzFw+0UWSYOQUMaT4sGpbT7e57qb2yXQGAEiaJK4u02iUsGocLG3nv+9IniqBFBwBGCB5qvjcoXZI4aFoUyvMqm6T/a8dOBVhwwTdrSatCkqFg6Ltdok6drQIRmS0iB0jul3aAyMyJG09oTH27qWNHz++paXlf/3V7t27P/zwQzgZgcBIt6pSNYzI9GtTK8wGnRVqr+VBGhsb1erH2UGVlZUQ0rmHyJvQKM0w2kn6b9y01hngXVQlSXLnzp1Hjx6tra0NDw9PSUlZsWJFcXHxypUrAQAZGRlpaWl//OMfq6qqcnNzCwsLW1pawsPDMzMzZ82aBQC4devWwoULP//88z179qhUKoIgSkpKAACHDx/evXt3REQE7Ql7+XDa6vX0tz0k3ZRfUJ7c1Up7WIodO3aMGTPm8OHDXV1d+/fvT01N3b59O0mSZ8+elcvlzc3N1GYrVqyYPXt2YWHh5cuX9+zZI5fLi4uLSZKsqamRy+VLlizZuXNnRUUFSZLZ2dnr16+HlC1Jkid2tFQWqmgPS39t02ssPD6sfkVJSUliYmJGRgYAYM6cOUlJSUaj8cHNNm3apNFo/P39AQCJiYl5eXnnz59PSEig1o4ePXrhwoWQMrwPnoBl0KHQSLJYDHiXOWNjY//2t79t2LAhPj5+woQJwcHBNjezWq27du06d+5cfX09tSQqKqp37ZAhQ2DlZwsYe4P+asF3Z2l7YF0dyM7OXrduXUdHx/r169PS0tavX9/V1XXfNlardfXq1VeuXHnttdfOnDlTVFQ0bNgwahWDwQAA8Hg8SOk9iFZlFrjTXzfoj8h3Z2t7zLSHpWAymZmZmZmZmXfu3CksLMzJydHr9Zs2beq7TWVl5Y0bN3JycuRyObVEqVRSH6gLsPa8oa/tsfA96D+ppl+bmzurs8nG8YYWjhw5EhMTExYWFh4eHh4e3tnZefLkyd5qREFJkkjuXVq7ceNGfX19XFyczYB9f0g7JEm2Nxj4EGob/Y2kp5Qwm6ztDQbaIwMA8vPzf//73xcUFKhUqrNnzxYUFIwYMQIAEBgYCAA4ceJERUXFoEGDGAzGzp071Wp1TU3Nli1bEhMT++uJBwQElJWVFRUVKRQK2rNtqzcyGEAkhTA8jvZzU5Ikf9zZUvRjF4zIzc3Nr7/+ulwul8vlU6ZM2bp1q0ajoVa98847ycnJr7zyCkmSx48fz8rKksvlmZmZ5eXlP/zwg1wuX7RoEdUBKCws7A14+fLl2bNnjxw5kuoh0EvhD52ndkPpC0G533a3QluQ177orWAG0zVHjjwKViv5rw21afNlQdH0X1KH0sEKHuzGYICbxVAux6HCjcIegssIjHKDERzKqGQmkzF2lrQgrz0qQchk2ahwzc3NCxYs6Oe3TKvVanNVVlbWqlWr6E72HmvWrCktLbW5ymg0cji2L9d99913oaGhDy4nraDwh65Ji3wgnfJAHJSQ92WjTzBv9NM2bpZarVaNRmPzV3q9vr9+FUEQ8LpcWq3WYrHd3RwgJYFAwGTaaLHOfd/R1WKc8ZI/3WneA6I2tcK8e3P9hHmyJ2GoXV9ul6jP5LbNXxss9IQ1xQLiyC2hJztjmd9Pu1shdQack/YGw8/72ma8FADPGfSJUr6hvAnPyPK+bLx73XaT6GLUXNfkfdmY+oxMFgR3jKE9BpM31+jzv26Wp3nFT/CEXZYDKfqxu/RM94zlATL4E6jsNHWjp9v0/dYmvjvrqTlSiZ+rjXbtaDT8vL9dr7XMXOHv7mWPaUR2nShVfl555XS3f7hbeJwwINyNw0NjTlt/GPXWhipd9TV1U7UuIdVrmB1HPTlgWmLNdU1VifpupcZDTIh9OJ4ywkvGsfPYk8dGq7Yo2ozdbaauFqNaYQodIoiMdw8Z6tLTEu+j5a6+s8WobDcpOox6je0u9mPT2dnZ9z4AXbgJmJ5SjsibEPtyfEPtd9/uPhypDSo5OTkMBmP58uWOTgQKaB9dnliwNiTB2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSV3ucTEZGBvXsburpsO7u7larlcFg5OfnOzo1OoH4qEqHEBAQcPny5d4H4VLykpKSHJ0XzbhaI5mdne3p+V9PrRSJRIsXL3ZcRlBwNW1jx46Njo7uuyQiImLUqFGOywgKrqYNALBw4UKR6N6jHV2yqrmmtnHjxvW+rS0yMnLMmDGOzoh+XFBbb4Vz1apm1zNJs4lsbzBYLfbobwzyS4wZNA4AECKLb6zS2aFEJoshDeSyCTu908ce/bb6W7qLRzs1SrNAxIb6vjQHQpKkWmH2ELOTp0ogvdemL9C1ndnf3lClG5fp6+UD663OzkNXi/HcgZaQofyxM72hFgT32FZ3U1t9TT1tadCT4AwAIPblTFsadPtKT22lFmpBcLVdOdmdOFVKcFyzYbQJwWUkTPK+eob+dy/2Ba62jmajX7i9H7bucHxD3Dpb4L7WB642k9HKRfwdDY8B34OtUcJ6hTUFxH1qNpJPUOP437AIhtkE8VzviasKrgHWhiRYG5JgbUiCtSEJ1oYkWBuSYG1IgrUhCdaGJFgbkiCv7f0Pfv/GulUAgOrqqglpieXlV+nd3jlBXtuTCdaGJE43B6C2tubTzzaWlZUG+AeOHz/pucXLCYIAAOQe2H3p0rnKG+VcLi8+Pmnp8y/7+vrRVegH69/gcDhyefKnf95IEMTQIbHvvffJvn07dv77Wy8vccb02S88v5KusmjBuWpbU3Pj6ldfiB+R+Onmr+bMWXjs+KGvcrYAAK5dK/nrl5tjY+M/+nDzujfWNzc3/t+fPqSxXIIgyspLb96s2L/vh7/+5dvSq8WvrVnG5fKOHil4Y+3723d8XVZWSmNxvx7nqm25B3a58fnPLV7OZDIT4pMIgqivrwUAxMTEfbNtT1BQCJvNBgDodNoP1r9hMBi4XC4t5TIYDLPZ/MrLv2Oz2SIPUVBQCJfDzV60FACQkjKWx+PdrroZGzuClrJowbm01VRXRUUO6Z3mlDF9NvWBxWI1Ntb/9cvNN25e12rvDYrq7Orw9wugpVySJP39A6n/CQAAny8ICgzpXSsQCLVaDS0F0YVzNZJqdQ+HY2No3rlzP7/3wdphw4Z/8fk3p08VfbJxC73lkiR537jb3n8daq3VaqW3xF+Jc9U2odBdq7MxwjD/2MH4EYnPL1lBfe3pUdk9NefCuWpbdPTQ8vJSi+XesKcTJ/LXvfUqAEClUnp5iXs3O1NwynE5OgXOpS192ky9Xv/Zlk+KrxQWnDv9921fyKQ+AIBBYRHFVwrLykrNZvPuPf/iEBwAQFtri6PzdRjO1UgGBYV88ofPN3+6If/oQS6XO23qjBeXrQYALFv6ikajXvfWar1ePzfr2XVvrK+rv/vb37308UefOjplxwBx6obZSG57t/rZd8IhxXdmdmy88+LGQfDmTTlXI4l5RJyrkaSFGTMn9NeEvPP2xykpY+2eEf24oLacnJ39rfLyFPe3Ci1cUJufr7+jU4AOPrYhCdaGJFgbkmBtSIK1IQnWhiRYG5JgbUiCtSEJRG1sDtynBTgzFhMJ9bFpcGubyJtQdZmgFuGEKNtNXjICahFwtUn9uXWVaqhFOCG1lWrvAHpGAvYHXG1JU8WVlxTKdiPUUpyK7lbjjULFyClwbzVAfzBhe4Phx52t0Yki30F8DzHcpsOxqLpMjbc1d0pUkxb5wK5t9ngMqNlIFp3sqr+pa63Twy7LgfiG8IIH8xNSvdjwn+jnam/d6CUnJ4fBYCxfvtzRiUAB99uQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakMTVngI0f/78qqqqvktIkhw0aNC+ffsclxT9uFpty8rKuu/1wDwe79lnn3VcRlBwQW1BQUF9lwQFBc2aNctxGUHB1bQBAObOncvj8ajPHA5n3rx5js6IflxQ2+zZswMC7r2POyQkJDMz09EZ0Y8LamMymfPmzeNyua5a1VzwTLIXStjevXsdnQgUHqKt4bau/LyyuUanUVnsmNWTi0DE8gtzixsr8g93G2CzgbQVHOxorTXEp0o8ZRwOzwWbUyfEqLcq2owlpzp8w3hjZ3r3t1m/2kp+VjTXGMZl+sBMEtMvBbmt/uHcEU952lxruw5pVJaS04rkdCnk3DD9kjxdWnJaoVPbPjbZ1tZUrZMF83DD6EA4PKY0kNdcY/tZ7rbFdLcYRd4cyIlhHoKnlNPeaLC5yrY2i5lksaA/zB4zMAwmw2qxfeaBm0EkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JHKatqurWhLTE8vKrjkoAaRymzctLvDh7mVTqAwCorq56dtFMR2WCImxHFSyReD+/ZAX1+cbN645KA1HoqW2ZWZO37/ia+tzZ2TEhLfHjP7zbu3bGrNQDB3bn5u6aNz/9ctHFJS/Mzfn7X3obyW+/2/qnzRuamhsnpCUeyNsDAOjq6tzw8dvPLJg+K3PiJ3/8oLGp4aEJ5B7YPfeZabdu38iaN3XSlJRlyxfcvFV55uypjBlPpWeM+2jDWz3qHmrL/oI/egQAwLffbV2UPWvy1FGLl8zZ8vkmajwO9RddvHR+3Vuvvrxqyatrlq17c3XfJN98+7W9+3bQssPp0SaXJ1dUllGfi4svicWSiuvXqK81NXd6elSJiSkEh6PRqPft27E4+8WMjP+MFH5+yYp5cxf5+wWcPlWUOfsZi8Wy5vXl5devrv3de99+vVfAF7z8ynOtrS0DJ8DhcHp6VNu3b9vy2T8OHjil0+k2/uHd06dPfPv1vn9+m1tUdPHgwb0AgAGCP2IEytmR/LyXV76eu//E4uwXT/yY//2h/VQEAMD2HduSElNee3Vd+rSZRcWXlCol9SuNRlNcfClmaBwtO5webQnxSRUV97RdKyuZMjmjrb21o6Od+iqVyoKDQwEAWq322YUvpE6YHOAf2F+oa2Ul9fW1b7+5ISkxxctLvOqVtW5ubgfydg+cAIPBMBgMzy9ZERgQJBAIkhJTWlqafrvmLalUJpXKhsbE3blza+DgjxhBqVLu2v3P5xYvHz36N+5C94lpU2fNnPfPf/3darVSmYxMGp01Z2F01JDUCVM4HM6pU8ep5WcLTrHZ7OjoobTscHq0JcpTVCplXd1datfExydFRw+9eu0KAKC8vFSekNy75eDBMQOHKi+/yuPxhg9PuJcfkxkbG19aWjTwr6hmKjR0EPVVIBB6S6Qi0b3RagK+QKvVDBz8ESM0NdabTKa+f0V4eJRC0d3adq89iI4aQn3gcDiTJ00/9VOvtp/SUqey2fScTNATRSqVBQQElZWXikSeDQ11cbHxMUPjystL01KnlJQWvfTiq9S/MwDgvslnD6JW9+j1+glpiX0XSiT9DvSkoHY6VQQFk8nsu5aqDQMEf8QInV0dAAAel9e7iu/GBwDotFqCIAAAXN5/Vs14OmvZ8gWtrS1CoXtR0cXPP/vHwH/Fo0PbmWSiPLmyspzHc4uOGsLlcmNjR2zfvq2pubGzsyM5ZWzvfiFJsu+ueRCJxFsgEGz46NP/ypJFT56/PrhAIAQA6A3/GQen1WmpyEqlovfPpAgPj4yKHHz02MHg4LCAgKChQ2Np+Svo1DZiROLX3/yNw+HExsYDAGKHjai6c+vihYLIiGgPd4+Bf9tXZFhYhEaj8fHx8/e7N9mpsalBIn5IbXtEfn3w8PAoFotVVlYaFTmYWlJRWSaReItEnpS2+0hPn7V3345BYRHp0+jsmNLW3Y6PT2pubrx48dzwuAQAgKenV1BQyIGDexISRj70t/7+gW3trefPn2lorE9KTElKTNm8eUNbW6tC0Z17YPeKlYt+PHmUliR/fXAPd4+JE6dt37HtwoWCHnXPseOH8vPzsuYs7G/7tNSpbW0thZd/mTQxnZY/gYK22ibyEIUPirx1+0Z8fBK1JGZo3LHjh3q/DsDoUb85eerYu+//7sVlqxYuWLLpk7/kHdz74YY3KyrKgoND06fNejqDtqmFvz74qpfXAhJ89PFbZrM5ICDoucXL52b1OzdcKBTK5clsNtvLS0xH+vewPXXjwpFOEjBjx3nRWNKTiV6vnzc//e03P0pJGfu//vba2W4m0zpquuTBVQ67uOXytLQ0NzbV78/9d1hY+GM4GxhktL31zpryslKbq2bMyHpx2Sq7Z/QQTv10fNvXX8bExH3w3ibagyPTSGq1WovV9qwhgk3w+vSWXAZXaCT5fL6jU3Ai8N1tJMHakARrQxKsDUmwNiTB2pAEa0MSrA1JbGtjYJvOQX93lG378RATPd0muBlhHoa62ySSEDZX2dbmHcBtrdVBzgrzEFrrdNIg29dabWuTBnL47qzrv9i4y46xD+Xnu92ELG9/289i6ufYxmBMXuRbfq7r6s9dkNPD2KDkp87rv3RPW+Lb3wYDPU9SrTCf2NHaWqv3lHIILmJnKVaSBAAwBxwl5oSYDFZFu9E3lDd5kY9A1O/9mYc/dFevsai6zCaDFUKSEDl8+DAA4Omnn3Z0Iv8bHB7T3YvNE7AG3uzh99t4AtZDozghDH43g8EIiBjo0bXogljTh6HA2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JHv4UILTIyMhoamq6b6G/v/+RI0cclBEUXK22paenMx9g2rRpjs6LZlxNW1ZWVnBwcN8lISEhCxYscFxGUHA1bTKZbOLEiX2XpKamisV0vvLOGXA1bQCAOXPmhIaGUp+Dg4Pnzp3r6IzoxwW1+fj4jB8/nvo8adIkmUzm6IzoxwW1AQDmzZsXGhoaHByclZXl6Fyg4OAOgEZluXNVrewwadUWvdpiMNCWTFtrG2AAGqsal8vgCVl8IUvkTYQPFwo8HPmMTYdpu/JT940itbLD6OkjYPMJFsFiEywW23lrv8VstRgtZrPFrDUpWjWeUs6QJPcR4z0dkowDtFVd1ZzNbScEhMjXw0OG6jsQVW1aZZPKbDCNmy2NGC6wc+l21WYykEe+buluN/tEeAnErvA4XHWnvu1Ol1jGzljqy+bY73Ha9tOmVphzv2jkegh8o5zoTbW00HKzy6jWZa7yF3ra6V2vdtLW0WQ88EWDd5iXOMjDDsXZn646Vcfd7jmvBkr8bL9wgV7scQqg11i+39oki5S4qjMAgDjYQxYpOfhVk05t+y3T9AJdm8VMHviySSgVevoJYZflWDz9hEJv4cGvmiwW6A0YdG2XT3RbrExZuGNOlO2MLMLTbGEVn4T+hhm42jRKS9k5pX+MjIHaS0seDwaD4T9UevWMCnZTCVfbuUMdXoHuztyJph0WwfQM8Dh/uBNqKRB3qFFvra3QegU7afOoULaufS+5vPIs7ZHFQR53rqqNeohvBYKorbpMI/IVsFhPRPPYFxbB9PQV3K3QwCsCorbbV9U8kStcCnkMeCK3qhKI2iD26ttqDaFJ3pCCq3o6Dx377G7dNZPJMDhq9KTxS70lgQCAggt7Thdsf2nJF9/tWtfeUevnGzlhbHbC8CnUr0qunTh+KkevVw8dPO43o+ZDyg0AIJC41RVDPJ+EVttIQJKARUCJb7FYvvpm5d26a3NnvrN29S4eV/CXv7/QrWgBALDZHJ1elZe/eX7m+5s3XBoSNWZP3kc96i4AQHNr1b/3vz8y4ek31+yPj52cl/8pjNwo2ATTYiEBtP4bLG1qpZnNgRW8pra0vaN2wZz10ZHJ7kLxzPTXuRy3cxf3UqfgJpNh2sSVIUHDAAAj5U9bLOam5tsAgF8u5Yo9/dOeWuLm5h4VMTIpIQNSehRsgqnpgdUNgLVne7rNkKoaAOBu3VUOwQsPS6C+MpnMsJARVdXFAADqEmtQwFBqFY8rBADo9D0AgPbOOh+fQb1BggKGQEqPgkWw1AozpOCwjm0kCeBdo9bp1UaTfu17yX0Xerh73ysYgN7efd+zWK1WJRT85+YDh4B8ukQCqxnWLoClje/OMhtgNRHuQgmPK1iy8E99FzJZDxkl4ObmbjTpe78aDBDP9AAAZqOFD23gAkRtRmja/Hwj9AaNl6evRBxALenoavAQPuSs1cvT9+bti1arlclkAgAqb52HlB6FUWvmu8PavbAOPxwe02q2GnVQGvfoiOSoiOS9BzcqlK1qTXfBhT1bvnqu+OqxgX8VF5PWo+7MP/FXkiRv37l84XIejNwoTHozyQAEF9alBoj9NlkwT92pEwe6wwi+LHvL+Uv7tu95p7a+TOYdmiyfOSpp9sA/GRo9JmPK6guFB86c3yn28p+f+f5X36yEdARWtWl9Q3gwIlNAvLt9rUBZfknjH+MDKb4z01jWOnysYNhoEaT4EC9uRQwXdjfrTNCOcE6LWW9RtusiR0BpZiggNpJ8D1ZEnLCrVuETJbG5gcVi+WDTZJurzGYjm8UBtg4N/j6RLy/bSmOe722c2N/1DKvVwmTaOBsMCx6+NPvP/QXsqFVExgu5fIhVAu4QII3S/K+NtRGjgwiu7VPhru77pxBS6PVqHs/2IAYWixB5SGlMsr8cAABGk4FDcB9czmZxPDxsn7ia9OaqXxoWvxsqEEEctgx95Nb5Q53VFbrAON8n4QY3SZJ1Jc1RI/ijpttuYOgC+n3n5GlePC7ZUd0NuyBnoP1Ot9CDMXIK9Ol00LWxCeaslwPMWr2yWQ27LMeiaFZbdPoZywNYbOjtip2Gt+q11u+3NrEFbhJnHaPwK+msVZi1ulkr/KGeifRiv8HkFjN5YkeropP0GSxlMl3nOGe1ks0VbWIpc0q2D9NeIzDsPeOm+GR3+YUeSZhYKHGF8Qo9HdrO6q64caKEVLu2Ig6YKKVoN5X8rGhvMvM8+HyxG5vjyPl9j4dZb9EodQaF1ieIiB8v8pAQdk7AkbNJq8s0N69oOpqMDCaDRbAYbBZ1bd45sVqtpMliMVsASUr8OEMSBaEx9p7W1otTPAVIrTAr2k3KDpNGZYY3/uJXwQACEdvTm/CUEgKRnWZDDZSOM2jD/K84b6OEGQCsDUmwNiTB2pAEa0MSrA1J/h85/7Q0Yz20GgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph\n",
    "graph_builder = StateGraph(MessageState)\n",
    "\n",
    "# Add nodes\n",
    "graph_builder.add_node(\"call_llm\", call_llm)\n",
    "graph_builder.add_node(\"write_memory\", write_memory)\n",
    "\n",
    "# Add edges\n",
    "graph_builder.add_edge(START, \"call_llm\")\n",
    "graph_builder.add_edge(\"call_llm\", \"write_memory\")\n",
    "graph_builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Long-term-memory store (across threads)\n",
    "across_thread_memory = InMemoryStore()\n",
    "# Short-term-memory store (within a thread) checkpointer\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Compile\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=within_thread_memory, store=across_thread_memory\n",
    ").with_config(run_name=\"chatbot-with-structured-memory\")\n",
    "\n",
    "# Visualize\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "722fe344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, my name is Neidu\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, my name is Neidu\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Neidu. It's nice to meet you. I'm a helpful assistant, and I'll do my best to provide you with information and assistance. I don't have any information about you in my memory yet, so this is the start of our conversation. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "config: dict[str, Any] = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "msgs = [\"Hello, my name is Neidu\"]\n",
    "input_state = MessageState(messages=[HumanMessage(content=msg) for msg in msgs])\n",
    "\n",
    "async for event in graph.astream(input_state, config=config, stream_mode=\"values\"):\n",
    "    for msg in event[\"messages\"]:\n",
    "        msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, my name is Neidu\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Neidu. It's nice to meet you. I'm a helpful assistant, and I'll do my best to provide you with information and assistance. I don't have any information about you in my memory yet, so this is the start of our conversation. How can I help you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm an AI Engineer whos's currently working on NLP related things\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, my name is Neidu\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Neidu. It's nice to meet you. I'm a helpful assistant, and I'll do my best to provide you with information and assistance. I don't have any information about you in my memory yet, so this is the start of our conversation. How can I help you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm an AI Engineer whos's currently working on NLP related things\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "As an AI Engineer working on NLP, I'm sure you're familiar with the challenges and opportunities in this field. I've got some information that might be relevant to you. I've been trained on a wide range of topics, including NLP, machine learning, and natural language processing.\n",
      "\n",
      "If you're working on NLP-related projects, I'd be happy to help with any questions or topics you'd like to discuss. What specific area of NLP are you currently focusing on? Are you working on text classification, sentiment analysis, language modeling, or something else?\n"
     ]
    }
   ],
   "source": [
    "msgs = [\"I'm an AI Engineer who's currently working on NLP related things\"]\n",
    "input_state = MessageState(messages=[HumanMessage(content=msg) for msg in msgs])\n",
    "\n",
    "async for event in graph.astream(input_state, config=config, stream_mode=\"values\"):\n",
    "    for msg in event[\"messages\"]:\n",
    "        msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e975b96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:58:48] </span><span style=\"font-weight: bold\">{</span>                                                                                        <a href=\"file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_40757/1135760118.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1135760118.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_40757/1135760118.py#7\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">7</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #008000; text-decoration-color: #008000\">'memory'</span>: <span style=\"font-weight: bold\">{</span>                                                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>        <span style=\"color: #008000; text-decoration-color: #008000\">'user_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Neidu'</span>,                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>        <span style=\"color: #008000; text-decoration-color: #008000\">'interests'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'NLP'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'machine learning'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'natural language processing'</span><span style=\"font-weight: bold\">]</span>          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"font-weight: bold\">}</span>                                                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">}</span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:58:48]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m{\u001b[0m                                                                                        \u001b]8;id=482410;file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_40757/1135760118.py\u001b\\\u001b[2m1135760118.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=224934;file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_40757/1135760118.py#7\u001b\\\u001b[2m7\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m    \u001b[32m'memory'\u001b[0m: \u001b[1m{\u001b[0m                                                                          \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m        \u001b[32m'user_name'\u001b[0m: \u001b[32m'Neidu'\u001b[0m,                                                            \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m        \u001b[32m'interests'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'NLP'\u001b[0m, \u001b[32m'machine learning'\u001b[0m, \u001b[32m'natural language processing'\u001b[0m\u001b[1m]\u001b[0m          \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[1m}\u001b[0m                                                                                    \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[1m}\u001b[0m                                                                                        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_id = \"1\"\n",
    "prefix: str = \"memory\"\n",
    "key = \"user_memory\"\n",
    "namespace = (prefix, user_id)\n",
    "existing_memory = across_thread_memory.get(namespace, key)\n",
    "\n",
    "console.log(existing_memory.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73038184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"Hi, I'm Neidu.\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Nice to meet you, Neidu.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"I'm an AI Engineer whos's currently working on NLP related things\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conversation\n",
    "conversation = [\n",
    "    HumanMessage(content=\"Hi, I'm Neidu.\"),\n",
    "    AIMessage(content=\"Nice to meet you, Neidu.\"),\n",
    "    HumanMessage(content=\"I'm an AI Engineer who's currently working on NLP related things\"),\n",
    "]\n",
    "\n",
    "conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d14dbfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">api_key</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SecretStr</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'**********'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">base_url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'https://openrouter.ai/api/v1'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">ModelEnum.LLAMA_3p1_8B_INSTRUCT_REMOTE:</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'meta-llama/llama-3.1-8b-instruct'</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mapi_key\u001b[0m=\u001b[1;35mSecretStr\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'**********'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mbase_url\u001b[0m=\u001b[32m'https://openrouter.ai/api/v1'\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mModelEnum.LLAMA_3p1_8B_INSTRUCT_REMOTE:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'meta-llama/llama-3.1-8b-instruct'\u001b[0m\u001b[1m>\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = LLMResponse(\n",
    "    api_key=settings.OPENROUTER_API_KEY,\n",
    "    base_url=settings.OPENROUTER_URL,\n",
    "    model=ModelEnum.LLAMA_3p1_8B_INSTRUCT_REMOTE,\n",
    ")\n",
    "console.print(llm)\n",
    "\n",
    "# Conversation\n",
    "conversation = [\n",
    "    HumanMessage(content=\"Hi, I'm Neidu.\"),\n",
    "    AIMessage(content=\"Nice to meet you, Neidu.\"),\n",
    "    HumanMessage(content=\"I'm an AI Engineer who's currently working on NLP related things\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "61b51671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UserProfile</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">user_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Neidu'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">interests</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'AI'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'NLP'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Engineering'</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mUserProfile\u001b[0m\u001b[1m(\u001b[0m\u001b[33muser_name\u001b[0m=\u001b[32m'Neidu'\u001b[0m, \u001b[33minterests\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'AI'\u001b[0m, \u001b[32m'NLP'\u001b[0m, \u001b[32m'Engineering'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "<system>\n",
    "Update the memory (JSON doc) to incorporate new information from the following conversation\n",
    "without losing any existing information.\n",
    "</system>\n",
    "\"\"\"\n",
    "\n",
    "messages = convert_to_openai_messages([SystemMessage(content=system_message)] + conversation)\n",
    "string_messages = convert_openai_messages_to_string(messages)\n",
    "result_1, _ = await llm.get_structured_response(message=string_messages, response_model=UserProfile)\n",
    "\n",
    "console.print(result_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff59b201",
   "metadata": {},
   "source": [
    "#### Update Conversations\n",
    "\n",
    "- Todo: Update the memory (JSON doc) to incorporate new information from the following conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UserProfile</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">user_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Neidu'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">interests</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'AI Engineer'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'NLP'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'AI Advancements'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Real-World Applications'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Agentic AI Workflow'</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mUserProfile\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33muser_name\u001b[0m=\u001b[32m'Neidu'\u001b[0m,\n",
       "    \u001b[33minterests\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'AI Engineer'\u001b[0m, \u001b[32m'NLP'\u001b[0m, \u001b[32m'AI Advancements'\u001b[0m, \u001b[32m'Real-World Applications'\u001b[0m, \u001b[32m'Agentic AI Workflow'\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "updated_conversation = [\n",
    "    HumanMessage(content=\"Hi, I'm Neidu.\"),\n",
    "    AIMessage(content=\"Nice to meet you, Neidu.\"),\n",
    "    HumanMessage(content=\"I'm an AI Engineer who's currently working on NLP related things\"),\n",
    "    AIMessage(\n",
    "        content=\"That sounds fascinating! NLP is a really exciting and impactful field in AI. \"\n",
    "        \"What will you like to know about AI?\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"Thanks! I'm curious about the latest advancements in AI and how \"\n",
    "        \"they're being applied in real-world applications. I'm also interested in \"\n",
    "        \"agentic AI workflow\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "messages = convert_to_openai_messages(\n",
    "    [SystemMessage(content=system_message)] + updated_conversation\n",
    ")\n",
    "string_messages = convert_openai_messages_to_string(messages)\n",
    "result_2, _ = await llm.get_structured_response(message=string_messages, response_model=UserProfile)\n",
    "\n",
    "console.print(result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "862ed816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserProfile(user_name='Neidu', interests=['AI', 'NLP', 'Engineering'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previous memory (user profile)\n",
    "result_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db1a567",
   "metadata": {},
   "source": [
    "## Chatbot With Profile Schema Updating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "57caead3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">api_key</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SecretStr</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'**********'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">base_url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'https://openrouter.ai/api/v1'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">ModelEnum.LLAMA_3p1_8B_INSTRUCT_REMOTE:</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'meta-llama/llama-3.1-8b-instruct'</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mapi_key\u001b[0m=\u001b[1;35mSecretStr\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'**********'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mbase_url\u001b[0m=\u001b[32m'https://openrouter.ai/api/v1'\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mModelEnum.LLAMA_3p1_8B_INSTRUCT_REMOTE:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'meta-llama/llama-3.1-8b-instruct'\u001b[0m\u001b[1m>\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = LLMResponse(\n",
    "    api_key=settings.OPENROUTER_API_KEY,\n",
    "    base_url=settings.OPENROUTER_URL,\n",
    "    model=ModelEnum.LLAMA_3p1_8B_INSTRUCT_REMOTE,\n",
    ")\n",
    "console.print(llm)\n",
    "\n",
    "\n",
    "class UserProfileSchema(BaseModel):\n",
    "    \"\"\"A schema for storing user profile information.\"\"\"\n",
    "\n",
    "    user_name: str = Field(description=\"User's preferred name\")\n",
    "    user_location: str = Field(description=\"User's location\")\n",
    "    interests: list[str] = Field(default_factory=list, description=\"List of user's interests\")\n",
    "\n",
    "\n",
    "MODEL_SYSTEM_MESSAGE: str = \"\"\"\n",
    "<system>\n",
    "\n",
    "<role>\n",
    "You are a helpful assistant with memory that responds to the user in a conversational way. \n",
    "If you have memory for this user, use it to personalize your responses.\n",
    "</role>\n",
    "\n",
    "<memory>\n",
    "{memory}\n",
    "</memory>\n",
    "\n",
    "</system>\n",
    "\"\"\"\n",
    "\n",
    "# Extraction instruction\n",
    "USER_MEMORY_INSTRUCTION: str = \"\"\"\n",
    "<system>\n",
    "Update the memory (JSON doc) to incorporate new information from the following conversation\n",
    "without losing any existing information.\n",
    "\n",
    "<validation>\n",
    "Rsponse must on only contain:\n",
    "- information about the user\n",
    "- in the format of a JSON object.\n",
    "</validation>\n",
    "\n",
    "</system>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6915a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def call_llm(state: MessageState, config: RunnableConfig, store: BaseStore) -> dict[str, Any]:\n",
    "    user_id: str = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    prefix: str = \"memory\"\n",
    "    key: str = \"user_memory\"\n",
    "    namespace = (prefix, user_id)\n",
    "    existing_memory = store.get(namespace, key)\n",
    "\n",
    "    if existing_memory and existing_memory.value:\n",
    "        memory_dict = existing_memory.value\n",
    "        formatted_memory = (\n",
    "            f\"Name: {memory_dict.get('user_name', 'Unknown')}\\n\"\n",
    "            f\"Location: {memory_dict.get('user_location', 'Unknown')}\\n\"\n",
    "            f\"Interests: {', '.join(memory_dict.get('interests', []))}\"\n",
    "        )\n",
    "    else:\n",
    "        formatted_memory = None\n",
    "\n",
    "    system_message: str = MODEL_SYSTEM_MESSAGE.format(memory=formatted_memory)\n",
    "    # Respond using memory + chat history\n",
    "    formatted_messages = convert_to_openai_messages(\n",
    "        [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    )\n",
    "    response, _ = await llm.ainvoke(messages=formatted_messages)\n",
    "\n",
    "    return {\"messages\": [AIMessage(content=response)]}\n",
    "\n",
    "\n",
    "async def write_memory(state: MessageState, config: RunnableConfig, store: BaseStore) -> None:\n",
    "    user_id: str = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    prefix: str = \"memory\"\n",
    "    key: str = \"user_memory\"\n",
    "    namespace = (prefix, user_id)\n",
    "    existing_memory = store.get(namespace, key)\n",
    "\n",
    "    # Get the profile and convert to JSON doc\n",
    "    existing_profile = existing_memory.value if existing_memory else None\n",
    "    # Invoke the extractor\n",
    "    messages = convert_to_openai_messages(\n",
    "        [SystemMessage(content=USER_MEMORY_INSTRUCTION)]\n",
    "        + [AIMessage(content=f\"\\nUserProfile: {json.dumps(existing_profile)}\\n\\n\\nChat History:\")]\n",
    "        + state[\"messages\"]\n",
    "    )\n",
    "    string_messages = convert_openai_messages_to_string(messages)\n",
    "    structured_output, _ = await llm.get_structured_response(\n",
    "        message=string_messages, response_model=UserProfileSchema\n",
    "    )\n",
    "    # Get the updated profile as a JSON object\n",
    "    updated_profile = (\n",
    "        structured_output.model_dump()\n",
    "        if structured_output is not None\n",
    "        else UserProfileSchema(\n",
    "            user_name=\"Unknown\", user_location=\"Unknown\", interests=[]\n",
    "        ).model_dump()\n",
    "    )\n",
    "    # Save the updated profile\n",
    "    store.put(namespace, key, updated_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba61a4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Neidu',\n",
       " 'user_location': 'Nigeria',\n",
       " 'interests': ['AI', 'NLP', 'Spiritual Growth']}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_conversation = [\n",
    "    HumanMessage(content=\"Hi, I'm Neidu.\"),\n",
    "    AIMessage(content=\"Nice to meet you, Neidu.\"),\n",
    "    HumanMessage(content=\"I'm an AI Engineer who's currently working on NLP related things\"),\n",
    "    AIMessage(\n",
    "        content=\"That sounds fascinating! NLP is a really exciting and impactful field in AI. \"\n",
    "        \"What will you like to know about AI?\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"Thanks! I'm curious about the latest advancements in AI and how \"\n",
    "        \"they're being applied in real-world applications. I'm also interested in \"\n",
    "        \"agentic AI workflow\"\n",
    "    ),\n",
    "    AIMessage(\n",
    "        content=\"Latest AI advancements include Generative AI (like LLMs for content and customer \"\n",
    "        \"service), Computer Vision (for autonomous tech and healthcare), Reinforcement Learning \"\n",
    "        \"(for robotics and optimization), and Edge AI (for on-device processing). Agentic AI \"\n",
    "        \"workflows involve autonomous AI agents that plan, execute, and iterate to achieve \"\n",
    "        \"complex goals with minimal human input.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"That's great! What do you know about about Sports? Specifically football (soccer)\"\n",
    "    ),\n",
    "]\n",
    "res = UserProfileSchema(\n",
    "    user_name=\"Neidu\",\n",
    "    user_location=\"Nigeria\",\n",
    "    interests=[\"AI\", \"NLP\", \"Spiritual Growth\"],\n",
    ")\n",
    "res.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7491c783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Role: system\n",
       "Content: \n",
       "<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">system</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">Update the memory </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">JSON doc</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\"> to incorporate new information from the following conversation</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">without losing any existing information.</span>\n",
       "\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;validation&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">Rsponse must on only contain:</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">- information about the user</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">- in the format of a JSON object.</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">validation</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
       "\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">system</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "\n",
       "\n",
       "Role: assistant\n",
       "Content: \n",
       "UserProfile: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"user_name\"</span>:<span style=\"color: #008000; text-decoration-color: #008000\">\"Neidu\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"user_location\"</span>:<span style=\"color: #008000; text-decoration-color: #008000\">\"Nigeria\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"interests\"</span>:<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"AI\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"NLP\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"Spiritual Growth\"</span><span style=\"font-weight: bold\">]}</span>\n",
       "\n",
       "\n",
       "Chat History:\n",
       "\n",
       "Role: user\n",
       "Content: Hi, I'm Neidu.\n",
       "\n",
       "Role: assistant\n",
       "Content: Nice to meet you, Neidu.\n",
       "\n",
       "Role: user\n",
       "Content: I'm an AI Engineer whos's currently working on NLP related things\n",
       "\n",
       "Role: assistant\n",
       "Content: That sounds fascinating! NLP is a really exciting and impactful field in AI. What will you like to know \n",
       "about AI?\n",
       "\n",
       "Role: user\n",
       "Content: Thanks! I'm curious about the latest advancements in AI and how they're being applied in real-world \n",
       "applications. I'm also interested in agentic AI workflow\n",
       "\n",
       "Role: assistant\n",
       "Content: Latest AI advancements include Generative AI <span style=\"font-weight: bold\">(</span>like LLMs for content and customer service<span style=\"font-weight: bold\">)</span>, Computer Vision\n",
       "<span style=\"font-weight: bold\">(</span>for autonomous tech and healthcare<span style=\"font-weight: bold\">)</span>, Reinforcement Learning <span style=\"font-weight: bold\">(</span>for robotics and optimization<span style=\"font-weight: bold\">)</span>, and Edge AI <span style=\"font-weight: bold\">(</span>for \n",
       "on-device processing<span style=\"font-weight: bold\">)</span>. Agentic AI workflows involve autonomous AI agents that plan, execute, and iterate to achieve\n",
       "complex goals with minimal human input.\n",
       "\n",
       "Role: user\n",
       "Content: That's great! What do you know about about Sports? Specifically football <span style=\"font-weight: bold\">(</span>soccer<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Role: system\n",
       "Content: \n",
       "\u001b[1m<\u001b[0m\u001b[1;95msystem\u001b[0m\u001b[39m>\u001b[0m\n",
       "\u001b[39mUpdate the memory \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mJSON doc\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m to incorporate new information from the following conversation\u001b[0m\n",
       "\u001b[39mwithout losing any existing information.\u001b[0m\n",
       "\n",
       "\u001b[39m<validation>\u001b[0m\n",
       "\u001b[39mRsponse must on only contain:\u001b[0m\n",
       "\u001b[39m- information about the user\u001b[0m\n",
       "\u001b[39m- in the format of a JSON object.\u001b[0m\n",
       "\u001b[39m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mvalidation\u001b[0m\u001b[39m>\u001b[0m\n",
       "\n",
       "\u001b[39m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95msystem\u001b[0m\u001b[1m>\u001b[0m\n",
       "\n",
       "\n",
       "Role: assistant\n",
       "Content: \n",
       "UserProfile: \u001b[1m{\u001b[0m\u001b[32m\"user_name\"\u001b[0m:\u001b[32m\"Neidu\"\u001b[0m,\u001b[32m\"user_location\"\u001b[0m:\u001b[32m\"Nigeria\"\u001b[0m,\u001b[32m\"interests\"\u001b[0m:\u001b[1m[\u001b[0m\u001b[32m\"AI\"\u001b[0m,\u001b[32m\"NLP\"\u001b[0m,\u001b[32m\"Spiritual Growth\"\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "\n",
       "Chat History:\n",
       "\n",
       "Role: user\n",
       "Content: Hi, I'm Neidu.\n",
       "\n",
       "Role: assistant\n",
       "Content: Nice to meet you, Neidu.\n",
       "\n",
       "Role: user\n",
       "Content: I'm an AI Engineer whos's currently working on NLP related things\n",
       "\n",
       "Role: assistant\n",
       "Content: That sounds fascinating! NLP is a really exciting and impactful field in AI. What will you like to know \n",
       "about AI?\n",
       "\n",
       "Role: user\n",
       "Content: Thanks! I'm curious about the latest advancements in AI and how they're being applied in real-world \n",
       "applications. I'm also interested in agentic AI workflow\n",
       "\n",
       "Role: assistant\n",
       "Content: Latest AI advancements include Generative AI \u001b[1m(\u001b[0mlike LLMs for content and customer service\u001b[1m)\u001b[0m, Computer Vision\n",
       "\u001b[1m(\u001b[0mfor autonomous tech and healthcare\u001b[1m)\u001b[0m, Reinforcement Learning \u001b[1m(\u001b[0mfor robotics and optimization\u001b[1m)\u001b[0m, and Edge AI \u001b[1m(\u001b[0mfor \n",
       "on-device processing\u001b[1m)\u001b[0m. Agentic AI workflows involve autonomous AI agents that plan, execute, and iterate to achieve\n",
       "complex goals with minimal human input.\n",
       "\n",
       "Role: user\n",
       "Content: That's great! What do you know about about Sports? Specifically football \u001b[1m(\u001b[0msoccer\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Structured Output ====\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">UserProfileSchema</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">user_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Neidu'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">user_location</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Nigeria'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">interests</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'AI'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'NLP'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Spiritual Growth'</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mUserProfileSchema\u001b[0m\u001b[1m(\u001b[0m\u001b[33muser_name\u001b[0m=\u001b[32m'Neidu'\u001b[0m, \u001b[33muser_location\u001b[0m=\u001b[32m'Nigeria'\u001b[0m, \u001b[33minterests\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'AI'\u001b[0m, \u001b[32m'NLP'\u001b[0m, \u001b[32m'Spiritual Growth'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = convert_to_openai_messages(\n",
    "    [SystemMessage(content=USER_MEMORY_INSTRUCTION)]\n",
    "    + [AIMessage(content=f\"\\nUserProfile: {(res.model_dump_json())}\\n\\n\\nChat History:\")]\n",
    "    + updated_conversation\n",
    ")\n",
    "\n",
    "string_messages = convert_openai_messages_to_string(messages)\n",
    "console.print(string_messages)\n",
    "structured_output, _ = await llm.get_structured_response(\n",
    "    message=string_messages, response_model=UserProfileSchema\n",
    ")\n",
    "print(\"==== Structured Output ====\")\n",
    "console.print(structured_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "92a15ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJIAAAFNCAIAAABkBqGXAAAAAXNSR0IArs4c6QAAHWpJREFUeJztnXlcE2fewJ8ck4QkEEhIuC+5VASFgOC1VfBE6oFo1Yq11VpttXW7bu1dW+vWfddu7Xa7lV177KrriVgVtVZrFa2KICgIHghy35CE3Ne8f4wfltWArp0nyROf71/JzOT3/JgvzzPzzDzPDIMkSYBBDaajE8A8DlgbkmBtSIK1IQnWhiRYG5KwHVh2a61erbTotRa9xmIxodEPYXMYXD6Lx2cJPdk+wVxHpcGwf7+ttkJ7p0x956paIGJ7SAg3AYsnYBIcNOq9yWjVaSx6jVXZYdT1WMKHCwfFCkOG8O2chl21dTQaTu9rN2gt0YnukfHunlLCbkXDoLvVdLu052ZRD9+dNX6uTOLHsVvR9tN2Zn97dbl65BRJzCgP+5RoN65fUF061hkZ7z5utrd9SrSHNr3GemRbk28ob1S6hEUwYBfnEMwm8kJ+Z1u9fvoL/jwB9AYfurbuVuPRb5tT0r3D4wRQC3IGbhX3XP6xa/pSf9jtP1xteo1l/+cNUxb7SgMddtJlZ9rqDSe2t8x5NdBNyIJXCsTqbDGTh3Kaxs70fnKcAQBkQdwxM7yP/KPJaoFYCsTadvFoJ8Fhyid6QYrvzFw+0UWSYOQUMaT4sGpbT7e57qb2yXQGAEiaJK4u02iUsGocLG3nv+9IniqBFBwBGCB5qvjcoXZI4aFoUyvMqm6T/a8dOBVhwwTdrSatCkqFg6Ltdok6drQIRmS0iB0jul3aAyMyJG09oTH27qWNHz++paXlf/3V7t27P/zwQzgZgcBIt6pSNYzI9GtTK8wGnRVqr+VBGhsb1erH2UGVlZUQ0rmHyJvQKM0w2kn6b9y01hngXVQlSXLnzp1Hjx6tra0NDw9PSUlZsWJFcXHxypUrAQAZGRlpaWl//OMfq6qqcnNzCwsLW1pawsPDMzMzZ82aBQC4devWwoULP//88z179qhUKoIgSkpKAACHDx/evXt3REQE7Ql7+XDa6vX0tz0k3ZRfUJ7c1Up7WIodO3aMGTPm8OHDXV1d+/fvT01N3b59O0mSZ8+elcvlzc3N1GYrVqyYPXt2YWHh5cuX9+zZI5fLi4uLSZKsqamRy+VLlizZuXNnRUUFSZLZ2dnr16+HlC1Jkid2tFQWqmgPS39t02ssPD6sfkVJSUliYmJGRgYAYM6cOUlJSUaj8cHNNm3apNFo/P39AQCJiYl5eXnnz59PSEig1o4ePXrhwoWQMrwPnoBl0KHQSLJYDHiXOWNjY//2t79t2LAhPj5+woQJwcHBNjezWq27du06d+5cfX09tSQqKqp37ZAhQ2DlZwsYe4P+asF3Z2l7YF0dyM7OXrduXUdHx/r169PS0tavX9/V1XXfNlardfXq1VeuXHnttdfOnDlTVFQ0bNgwahWDwQAA8Hg8SOk9iFZlFrjTXzfoj8h3Z2t7zLSHpWAymZmZmZmZmXfu3CksLMzJydHr9Zs2beq7TWVl5Y0bN3JycuRyObVEqVRSH6gLsPa8oa/tsfA96D+ppl+bmzurs8nG8YYWjhw5EhMTExYWFh4eHh4e3tnZefLkyd5qREFJkkjuXVq7ceNGfX19XFyczYB9f0g7JEm2Nxj4EGob/Y2kp5Qwm6ztDQbaIwMA8vPzf//73xcUFKhUqrNnzxYUFIwYMQIAEBgYCAA4ceJERUXFoEGDGAzGzp071Wp1TU3Nli1bEhMT++uJBwQElJWVFRUVKRQK2rNtqzcyGEAkhTA8jvZzU5Ikf9zZUvRjF4zIzc3Nr7/+ulwul8vlU6ZM2bp1q0ajoVa98847ycnJr7zyCkmSx48fz8rKksvlmZmZ5eXlP/zwg1wuX7RoEdUBKCws7A14+fLl2bNnjxw5kuoh0EvhD52ndkPpC0G533a3QluQ177orWAG0zVHjjwKViv5rw21afNlQdH0X1KH0sEKHuzGYICbxVAux6HCjcIegssIjHKDERzKqGQmkzF2lrQgrz0qQchk2ahwzc3NCxYs6Oe3TKvVanNVVlbWqlWr6E72HmvWrCktLbW5ymg0cji2L9d99913oaGhDy4nraDwh65Ji3wgnfJAHJSQ92WjTzBv9NM2bpZarVaNRmPzV3q9vr9+FUEQ8LpcWq3WYrHd3RwgJYFAwGTaaLHOfd/R1WKc8ZI/3WneA6I2tcK8e3P9hHmyJ2GoXV9ul6jP5LbNXxss9IQ1xQLiyC2hJztjmd9Pu1shdQack/YGw8/72ma8FADPGfSJUr6hvAnPyPK+bLx73XaT6GLUXNfkfdmY+oxMFgR3jKE9BpM31+jzv26Wp3nFT/CEXZYDKfqxu/RM94zlATL4E6jsNHWjp9v0/dYmvjvrqTlSiZ+rjXbtaDT8vL9dr7XMXOHv7mWPaUR2nShVfl555XS3f7hbeJwwINyNw0NjTlt/GPXWhipd9TV1U7UuIdVrmB1HPTlgWmLNdU1VifpupcZDTIh9OJ4ywkvGsfPYk8dGq7Yo2ozdbaauFqNaYQodIoiMdw8Z6tLTEu+j5a6+s8WobDcpOox6je0u9mPT2dnZ9z4AXbgJmJ5SjsibEPtyfEPtd9/uPhypDSo5OTkMBmP58uWOTgQKaB9dnliwNiTB2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSV3ucTEZGBvXsburpsO7u7larlcFg5OfnOzo1OoH4qEqHEBAQcPny5d4H4VLykpKSHJ0XzbhaI5mdne3p+V9PrRSJRIsXL3ZcRlBwNW1jx46Njo7uuyQiImLUqFGOywgKrqYNALBw4UKR6N6jHV2yqrmmtnHjxvW+rS0yMnLMmDGOzoh+XFBbb4Vz1apm1zNJs4lsbzBYLfbobwzyS4wZNA4AECKLb6zS2aFEJoshDeSyCTu908ce/bb6W7qLRzs1SrNAxIb6vjQHQpKkWmH2ELOTp0ogvdemL9C1ndnf3lClG5fp6+UD663OzkNXi/HcgZaQofyxM72hFgT32FZ3U1t9TT1tadCT4AwAIPblTFsadPtKT22lFmpBcLVdOdmdOFVKcFyzYbQJwWUkTPK+eob+dy/2Ba62jmajX7i9H7bucHxD3Dpb4L7WB642k9HKRfwdDY8B34OtUcJ6hTUFxH1qNpJPUOP437AIhtkE8VzviasKrgHWhiRYG5JgbUiCtSEJ1oYkWBuSYG1IgrUhCdaGJFgbkiCv7f0Pfv/GulUAgOrqqglpieXlV+nd3jlBXtuTCdaGJE43B6C2tubTzzaWlZUG+AeOHz/pucXLCYIAAOQe2H3p0rnKG+VcLi8+Pmnp8y/7+vrRVegH69/gcDhyefKnf95IEMTQIbHvvffJvn07dv77Wy8vccb02S88v5KusmjBuWpbU3Pj6ldfiB+R+Onmr+bMWXjs+KGvcrYAAK5dK/nrl5tjY+M/+nDzujfWNzc3/t+fPqSxXIIgyspLb96s2L/vh7/+5dvSq8WvrVnG5fKOHil4Y+3723d8XVZWSmNxvx7nqm25B3a58fnPLV7OZDIT4pMIgqivrwUAxMTEfbNtT1BQCJvNBgDodNoP1r9hMBi4XC4t5TIYDLPZ/MrLv2Oz2SIPUVBQCJfDzV60FACQkjKWx+PdrroZGzuClrJowbm01VRXRUUO6Z3mlDF9NvWBxWI1Ntb/9cvNN25e12rvDYrq7Orw9wugpVySJP39A6n/CQAAny8ICgzpXSsQCLVaDS0F0YVzNZJqdQ+HY2No3rlzP7/3wdphw4Z/8fk3p08VfbJxC73lkiR537jb3n8daq3VaqW3xF+Jc9U2odBdq7MxwjD/2MH4EYnPL1lBfe3pUdk9NefCuWpbdPTQ8vJSi+XesKcTJ/LXvfUqAEClUnp5iXs3O1NwynE5OgXOpS192ky9Xv/Zlk+KrxQWnDv9921fyKQ+AIBBYRHFVwrLykrNZvPuPf/iEBwAQFtri6PzdRjO1UgGBYV88ofPN3+6If/oQS6XO23qjBeXrQYALFv6ikajXvfWar1ePzfr2XVvrK+rv/vb37308UefOjplxwBx6obZSG57t/rZd8IhxXdmdmy88+LGQfDmTTlXI4l5RJyrkaSFGTMn9NeEvPP2xykpY+2eEf24oLacnJ39rfLyFPe3Ci1cUJufr7+jU4AOPrYhCdaGJFgbkmBtSIK1IQnWhiRYG5JgbUiCtSEJRG1sDtynBTgzFhMJ9bFpcGubyJtQdZmgFuGEKNtNXjICahFwtUn9uXWVaqhFOCG1lWrvAHpGAvYHXG1JU8WVlxTKdiPUUpyK7lbjjULFyClwbzVAfzBhe4Phx52t0Yki30F8DzHcpsOxqLpMjbc1d0pUkxb5wK5t9ngMqNlIFp3sqr+pa63Twy7LgfiG8IIH8xNSvdjwn+jnam/d6CUnJ4fBYCxfvtzRiUAB99uQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakMTVngI0f/78qqqqvktIkhw0aNC+ffsclxT9uFpty8rKuu/1wDwe79lnn3VcRlBwQW1BQUF9lwQFBc2aNctxGUHB1bQBAObOncvj8ajPHA5n3rx5js6IflxQ2+zZswMC7r2POyQkJDMz09EZ0Y8LamMymfPmzeNyua5a1VzwTLIXStjevXsdnQgUHqKt4bau/LyyuUanUVnsmNWTi0DE8gtzixsr8g93G2CzgbQVHOxorTXEp0o8ZRwOzwWbUyfEqLcq2owlpzp8w3hjZ3r3t1m/2kp+VjTXGMZl+sBMEtMvBbmt/uHcEU952lxruw5pVJaS04rkdCnk3DD9kjxdWnJaoVPbPjbZ1tZUrZMF83DD6EA4PKY0kNdcY/tZ7rbFdLcYRd4cyIlhHoKnlNPeaLC5yrY2i5lksaA/zB4zMAwmw2qxfeaBm0EkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JHKatqurWhLTE8vKrjkoAaRymzctLvDh7mVTqAwCorq56dtFMR2WCImxHFSyReD+/ZAX1+cbN645KA1HoqW2ZWZO37/ia+tzZ2TEhLfHjP7zbu3bGrNQDB3bn5u6aNz/9ctHFJS/Mzfn7X3obyW+/2/qnzRuamhsnpCUeyNsDAOjq6tzw8dvPLJg+K3PiJ3/8oLGp4aEJ5B7YPfeZabdu38iaN3XSlJRlyxfcvFV55uypjBlPpWeM+2jDWz3qHmrL/oI/egQAwLffbV2UPWvy1FGLl8zZ8vkmajwO9RddvHR+3Vuvvrxqyatrlq17c3XfJN98+7W9+3bQssPp0SaXJ1dUllGfi4svicWSiuvXqK81NXd6elSJiSkEh6PRqPft27E4+8WMjP+MFH5+yYp5cxf5+wWcPlWUOfsZi8Wy5vXl5devrv3de99+vVfAF7z8ynOtrS0DJ8DhcHp6VNu3b9vy2T8OHjil0+k2/uHd06dPfPv1vn9+m1tUdPHgwb0AgAGCP2IEytmR/LyXV76eu//E4uwXT/yY//2h/VQEAMD2HduSElNee3Vd+rSZRcWXlCol9SuNRlNcfClmaBwtO5webQnxSRUV97RdKyuZMjmjrb21o6Od+iqVyoKDQwEAWq322YUvpE6YHOAf2F+oa2Ul9fW1b7+5ISkxxctLvOqVtW5ubgfydg+cAIPBMBgMzy9ZERgQJBAIkhJTWlqafrvmLalUJpXKhsbE3blza+DgjxhBqVLu2v3P5xYvHz36N+5C94lpU2fNnPfPf/3darVSmYxMGp01Z2F01JDUCVM4HM6pU8ep5WcLTrHZ7OjoobTscHq0JcpTVCplXd1datfExydFRw+9eu0KAKC8vFSekNy75eDBMQOHKi+/yuPxhg9PuJcfkxkbG19aWjTwr6hmKjR0EPVVIBB6S6Qi0b3RagK+QKvVDBz8ESM0NdabTKa+f0V4eJRC0d3adq89iI4aQn3gcDiTJ00/9VOvtp/SUqey2fScTNATRSqVBQQElZWXikSeDQ11cbHxMUPjystL01KnlJQWvfTiq9S/MwDgvslnD6JW9+j1+glpiX0XSiT9DvSkoHY6VQQFk8nsu5aqDQMEf8QInV0dAAAel9e7iu/GBwDotFqCIAAAXN5/Vs14OmvZ8gWtrS1CoXtR0cXPP/vHwH/Fo0PbmWSiPLmyspzHc4uOGsLlcmNjR2zfvq2pubGzsyM5ZWzvfiFJsu+ueRCJxFsgEGz46NP/ypJFT56/PrhAIAQA6A3/GQen1WmpyEqlovfPpAgPj4yKHHz02MHg4LCAgKChQ2Np+Svo1DZiROLX3/yNw+HExsYDAGKHjai6c+vihYLIiGgPd4+Bf9tXZFhYhEaj8fHx8/e7N9mpsalBIn5IbXtEfn3w8PAoFotVVlYaFTmYWlJRWSaReItEnpS2+0hPn7V3345BYRHp0+jsmNLW3Y6PT2pubrx48dzwuAQAgKenV1BQyIGDexISRj70t/7+gW3trefPn2lorE9KTElKTNm8eUNbW6tC0Z17YPeKlYt+PHmUliR/fXAPd4+JE6dt37HtwoWCHnXPseOH8vPzsuYs7G/7tNSpbW0thZd/mTQxnZY/gYK22ibyEIUPirx1+0Z8fBK1JGZo3LHjh3q/DsDoUb85eerYu+//7sVlqxYuWLLpk7/kHdz74YY3KyrKgoND06fNejqDtqmFvz74qpfXAhJ89PFbZrM5ICDoucXL52b1OzdcKBTK5clsNtvLS0xH+vewPXXjwpFOEjBjx3nRWNKTiV6vnzc//e03P0pJGfu//vba2W4m0zpquuTBVQ67uOXytLQ0NzbV78/9d1hY+GM4GxhktL31zpryslKbq2bMyHpx2Sq7Z/QQTv10fNvXX8bExH3w3ibagyPTSGq1WovV9qwhgk3w+vSWXAZXaCT5fL6jU3Ai8N1tJMHakARrQxKsDUmwNiTB2pAEa0MSrA1JbGtjYJvOQX93lG378RATPd0muBlhHoa62ySSEDZX2dbmHcBtrdVBzgrzEFrrdNIg29dabWuTBnL47qzrv9i4y46xD+Xnu92ELG9/289i6ufYxmBMXuRbfq7r6s9dkNPD2KDkp87rv3RPW+Lb3wYDPU9SrTCf2NHaWqv3lHIILmJnKVaSBAAwBxwl5oSYDFZFu9E3lDd5kY9A1O/9mYc/dFevsai6zCaDFUKSEDl8+DAA4Omnn3Z0Iv8bHB7T3YvNE7AG3uzh99t4AtZDozghDH43g8EIiBjo0bXogljTh6HA2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JHv4UILTIyMhoamq6b6G/v/+RI0cclBEUXK22paenMx9g2rRpjs6LZlxNW1ZWVnBwcN8lISEhCxYscFxGUHA1bTKZbOLEiX2XpKamisV0vvLOGXA1bQCAOXPmhIaGUp+Dg4Pnzp3r6IzoxwW1+fj4jB8/nvo8adIkmUzm6IzoxwW1AQDmzZsXGhoaHByclZXl6Fyg4OAOgEZluXNVrewwadUWvdpiMNCWTFtrG2AAGqsal8vgCVl8IUvkTYQPFwo8HPmMTYdpu/JT940itbLD6OkjYPMJFsFiEywW23lrv8VstRgtZrPFrDUpWjWeUs6QJPcR4z0dkowDtFVd1ZzNbScEhMjXw0OG6jsQVW1aZZPKbDCNmy2NGC6wc+l21WYykEe+buluN/tEeAnErvA4XHWnvu1Ol1jGzljqy+bY73Ha9tOmVphzv2jkegh8o5zoTbW00HKzy6jWZa7yF3ra6V2vdtLW0WQ88EWDd5iXOMjDDsXZn646Vcfd7jmvBkr8bL9wgV7scQqg11i+39oki5S4qjMAgDjYQxYpOfhVk05t+y3T9AJdm8VMHviySSgVevoJYZflWDz9hEJv4cGvmiwW6A0YdG2XT3RbrExZuGNOlO2MLMLTbGEVn4T+hhm42jRKS9k5pX+MjIHaS0seDwaD4T9UevWMCnZTCVfbuUMdXoHuztyJph0WwfQM8Dh/uBNqKRB3qFFvra3QegU7afOoULaufS+5vPIs7ZHFQR53rqqNeohvBYKorbpMI/IVsFhPRPPYFxbB9PQV3K3QwCsCorbbV9U8kStcCnkMeCK3qhKI2iD26ttqDaFJ3pCCq3o6Dx377G7dNZPJMDhq9KTxS70lgQCAggt7Thdsf2nJF9/tWtfeUevnGzlhbHbC8CnUr0qunTh+KkevVw8dPO43o+ZDyg0AIJC41RVDPJ+EVttIQJKARUCJb7FYvvpm5d26a3NnvrN29S4eV/CXv7/QrWgBALDZHJ1elZe/eX7m+5s3XBoSNWZP3kc96i4AQHNr1b/3vz8y4ek31+yPj52cl/8pjNwo2ATTYiEBtP4bLG1qpZnNgRW8pra0vaN2wZz10ZHJ7kLxzPTXuRy3cxf3UqfgJpNh2sSVIUHDAAAj5U9bLOam5tsAgF8u5Yo9/dOeWuLm5h4VMTIpIQNSehRsgqnpgdUNgLVne7rNkKoaAOBu3VUOwQsPS6C+MpnMsJARVdXFAADqEmtQwFBqFY8rBADo9D0AgPbOOh+fQb1BggKGQEqPgkWw1AozpOCwjm0kCeBdo9bp1UaTfu17yX0Xerh73ysYgN7efd+zWK1WJRT85+YDh4B8ukQCqxnWLoClje/OMhtgNRHuQgmPK1iy8E99FzJZDxkl4ObmbjTpe78aDBDP9AAAZqOFD23gAkRtRmja/Hwj9AaNl6evRBxALenoavAQPuSs1cvT9+bti1arlclkAgAqb52HlB6FUWvmu8PavbAOPxwe02q2GnVQGvfoiOSoiOS9BzcqlK1qTXfBhT1bvnqu+OqxgX8VF5PWo+7MP/FXkiRv37l84XIejNwoTHozyQAEF9alBoj9NlkwT92pEwe6wwi+LHvL+Uv7tu95p7a+TOYdmiyfOSpp9sA/GRo9JmPK6guFB86c3yn28p+f+f5X36yEdARWtWl9Q3gwIlNAvLt9rUBZfknjH+MDKb4z01jWOnysYNhoEaT4EC9uRQwXdjfrTNCOcE6LWW9RtusiR0BpZiggNpJ8D1ZEnLCrVuETJbG5gcVi+WDTZJurzGYjm8UBtg4N/j6RLy/bSmOe722c2N/1DKvVwmTaOBsMCx6+NPvP/QXsqFVExgu5fIhVAu4QII3S/K+NtRGjgwiu7VPhru77pxBS6PVqHs/2IAYWixB5SGlMsr8cAABGk4FDcB9czmZxPDxsn7ia9OaqXxoWvxsqEEEctgx95Nb5Q53VFbrAON8n4QY3SZJ1Jc1RI/ijpttuYOgC+n3n5GlePC7ZUd0NuyBnoP1Ot9CDMXIK9Ol00LWxCeaslwPMWr2yWQ27LMeiaFZbdPoZywNYbOjtip2Gt+q11u+3NrEFbhJnHaPwK+msVZi1ulkr/KGeifRiv8HkFjN5YkeropP0GSxlMl3nOGe1ks0VbWIpc0q2D9NeIzDsPeOm+GR3+YUeSZhYKHGF8Qo9HdrO6q64caKEVLu2Ig6YKKVoN5X8rGhvMvM8+HyxG5vjyPl9j4dZb9EodQaF1ieIiB8v8pAQdk7AkbNJq8s0N69oOpqMDCaDRbAYbBZ1bd45sVqtpMliMVsASUr8OEMSBaEx9p7W1otTPAVIrTAr2k3KDpNGZYY3/uJXwQACEdvTm/CUEgKRnWZDDZSOM2jD/K84b6OEGQCsDUmwNiTB2pAEa0MSrA1J/h85/7Q0Yz20GgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_builder = StateGraph(MessageState)\n",
    "\n",
    "# Add nodes\n",
    "graph_builder.add_node(\"call_llm\", call_llm)\n",
    "graph_builder.add_node(\"write_memory\", write_memory)\n",
    "\n",
    "# Add edges\n",
    "graph_builder.add_edge(START, \"call_llm\")\n",
    "graph_builder.add_edge(\"call_llm\", \"write_memory\")\n",
    "graph_builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Long-term-memory store (across threads)\n",
    "across_thread_memory = InMemoryStore()\n",
    "# Short-term-memory store (within a thread) checkpointer\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Compile the graph\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=within_thread_memory, store=across_thread_memory\n",
    ").with_config(run_name=\"Chatbot-with-user-profile\")\n",
    "\n",
    "\n",
    "# Visualize the graph\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "11660760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, my name is Chinedu. I live in Lagos, Nigeria.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, my name is Chinedu. I live in Lagos, Nigeria.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Nice to meet you, Chinedu. Lagos is a vibrant city, isn't it? I'm glad you're here. I don't have any prior knowledge about you, so I'll start fresh. How's your day going so far?\n"
     ]
    }
   ],
   "source": [
    "config: dict[str, Any] = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "msgs = [\"Hello, my name is Chinedu. I live in Lagos, Nigeria.\"]\n",
    "\n",
    "input_state = MessageState(messages=[HumanMessage(content=msg) for msg in msgs])\n",
    "\n",
    "async for event in graph.astream(input_state, config=config, stream_mode=\"values\"):\n",
    "    for msg in event[\"messages\"]:\n",
    "        msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4ee8b40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item(namespace=['memory', '1'], key='user_memory', value={'user_name': 'Chinedu', 'user_location': 'Lagos, Nigeria', 'interests': ['null']}, created_at='2025-06-22T21:58:58.087436+00:00', updated_at='2025-06-22T21:58:58.087441+00:00')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "across_thread_memory.get((\"memory\", \"1\"), \"user_memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fac538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, my name is Chinedu. I live in Lagos, Nigeria.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Nice to meet you, Chinedu. Lagos is a vibrant city, isn't it? I'm glad you're here. I don't have any prior knowledge about you, so I'll start fresh. How's your day going so far?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm an AI Engineer whos's currently working on NLP related things\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, my name is Chinedu. I live in Lagos, Nigeria.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Nice to meet you, Chinedu. Lagos is a vibrant city, isn't it? I'm glad you're here. I don't have any prior knowledge about you, so I'll start fresh. How's your day going so far?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm an AI Engineer whos's currently working on NLP related things\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's fascinating, Chinedu. As an AI Engineer working on NLP, you must be dealing with some really interesting projects. I'm a conversational AI myself, so I have a bit of a soft spot for NLP. What specific areas of NLP are you currently exploring or working on? Are you into natural language processing, text generation, or something else?\n"
     ]
    }
   ],
   "source": [
    "msgs = [\"I'm an AI Engineer who's currently working on NLP related things\"]\n",
    "input_state = MessageState(messages=[HumanMessage(content=msg) for msg in msgs])\n",
    "\n",
    "async for event in graph.astream(input_state, config=config, stream_mode=\"values\"):\n",
    "    for msg in event[\"messages\"]:\n",
    "        msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ce068647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['memory', '1'],\n",
       " 'key': 'user_memory',\n",
       " 'value': {'user_name': 'Chinedu',\n",
       "  'user_location': 'Lagos, Nigeria',\n",
       "  'interests': ['null']},\n",
       " 'created_at': '2025-06-22T21:59:08.906892+00:00',\n",
       " 'updated_at': '2025-06-22T21:59:08.906897+00:00'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# namespace for the memory to save\n",
    "user_id: str = \"1\"\n",
    "prefix: str = \"memory\"\n",
    "key = \"user_memory\"\n",
    "namespace = (prefix, user_id)\n",
    "existing_memory = across_thread_memory.get(namespace, key)\n",
    "existing_memory.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7add07f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, my name is Chinedu. I live in Lagos, Nigeria.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Nice to meet you, Chinedu. Lagos is a vibrant city, isn't it? I'm glad you're here. I don't have any prior knowledge about you, so I'll start fresh. How's your day going so far?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm an AI Engineer whos's currently working on NLP related things\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's fascinating, Chinedu. As an AI Engineer working on NLP, you must be dealing with some really interesting projects. I'm a conversational AI myself, so I have a bit of a soft spot for NLP. What specific areas of NLP are you currently exploring or working on? Are you into natural language processing, text generation, or something else?\n"
     ]
    }
   ],
   "source": [
    "# Chat history\n",
    "state = graph.get_state(config=config).values\n",
    "\n",
    "for m in state[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f012a073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02ebd08e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## [TOP](#top)\n",
    "\n",
    "<br>\n",
    "\n",
    "<a id=\"chatbot-with-profile-collection\"></a>\n",
    "## Chatbot with Profile Collection\n",
    "\n",
    "- Sometimes we want to save memories to a `collection` rather than single profile.\n",
    "- We'll update our chatbot to save memories to a collection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(BaseModel):\n",
    "    content: str = Field(description=\"The important content of the memory.\")\n",
    "\n",
    "\n",
    "class MemoryCollection(BaseModel):\n",
    "    memories: list[Memory] = Field(default_factory=[], description=\"A list of memories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0c54a7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LLMResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">api_key</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SecretStr</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'**********'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">base_url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'https://openrouter.ai/api/v1'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">ModelEnum.LLAMA_3p1_8B_INSTRUCT_REMOTE:</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'meta-llama/llama-3.1-8b-instruct'</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mLLMResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mapi_key\u001b[0m=\u001b[1;35mSecretStr\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'**********'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mbase_url\u001b[0m=\u001b[32m'https://openrouter.ai/api/v1'\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mModelEnum.LLAMA_3p1_8B_INSTRUCT_REMOTE:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'meta-llama/llama-3.1-8b-instruct'\u001b[0m\u001b[1m>\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MemoryCollection</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">memories</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Memory</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'My name is Neidu.'</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Memory</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'I love reading books.'</span><span style=\"font-weight: bold\">)])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mMemoryCollection\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmemories\u001b[0m=\u001b[1m[\u001b[0m\u001b[1;35mMemory\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'My name is Neidu.'\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mMemory\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'I love reading books.'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = LLMResponse(\n",
    "    api_key=settings.OPENROUTER_API_KEY,\n",
    "    base_url=settings.OPENROUTER_URL,\n",
    "    model=ModelEnum.LLAMA_3p1_8B_INSTRUCT_REMOTE,\n",
    ")\n",
    "console.print(llm)\n",
    "\n",
    "structured_output, _ = await llm.get_structured_response(\n",
    "    message=\"My name is Neidu. I love reading books.\", response_model=MemoryCollection\n",
    ")\n",
    "\n",
    "console.print(structured_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the in-memory store\n",
    "in_memory_store = InMemoryStore()\n",
    "\n",
    "# Create a namespace to store the data\n",
    "user_id: str = \"1\"\n",
    "prefix: str = \"memories\"\n",
    "namespace_for_memory: tuple[str, str] = (prefix, user_id)\n",
    "key: str = str(uuid.uuid4())\n",
    "\n",
    "# Save the data\n",
    "in_memory_store.put(namespace_for_memory, key, structured_output.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'namespace'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'memories'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'b2793a7f-2a6d-4953-808a-3e5e9d32d834'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'memories'</span>: <span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'My name is Neidu.'</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I love reading books.'</span><span style=\"font-weight: bold\">}]}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2025-06-22T22:36:29.894299+00:00'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'updated_at'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2025-06-22T22:36:29.894305+00:00'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'namespace'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'memories'\u001b[0m, \u001b[32m'1'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'key'\u001b[0m: \u001b[32m'b2793a7f-2a6d-4953-808a-3e5e9d32d834'\u001b[0m,\n",
       "    \u001b[32m'value'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'memories'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'content'\u001b[0m: \u001b[32m'My name is Neidu.'\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'content'\u001b[0m: \u001b[32m'I love reading books.'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'created_at'\u001b[0m: \u001b[32m'2025-06-22T22:36:29.894299+00:00'\u001b[0m,\n",
       "    \u001b[32m'updated_at'\u001b[0m: \u001b[32m'2025-06-22T22:36:29.894305+00:00'\u001b[0m,\n",
       "    \u001b[32m'score'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Search\n",
    "for m in in_memory_store.search(namespace_for_memory):\n",
    "    console.print(m.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a3e48c",
   "metadata": {},
   "source": [
    "### Updating collection schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MemoryCollection</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">memories</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Memory</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Nice to meet you, Neidu.'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Memory</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"I'm an AI Engineer whos's currently working on NLP related things\"</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mMemoryCollection\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mmemories\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mMemory\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'Nice to meet you, Neidu.'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mMemory\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m\"I\u001b[0m\u001b[32m'm an AI Engineer whos's currently working on NLP related things\"\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Conversation\n",
    "conversation = [\n",
    "    HumanMessage(content=\"Hi, I'm Neidu.\"),\n",
    "    AIMessage(content=\"Nice to meet you, Neidu.\"),\n",
    "    HumanMessage(content=\"I'm an AI Engineer who's currently working on NLP related things\"),\n",
    "]\n",
    "string_messages = convert_openai_messages_to_string(convert_to_openai_messages(conversation))\n",
    "structured_output, _ = await llm.get_structured_response(\n",
    "    message=string_messages,\n",
    "    response_model=MemoryCollection,\n",
    ")\n",
    "\n",
    "console.print(structured_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e72ad4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MemoryCollection</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">memories</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Memory</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'User introduced themselves as Neidu, an AI Engineer working on NLP related things.'</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Memory</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'User expressed interest in the latest advancements in AI and its real-world applications, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">particularly agentic AI workflow.'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Memory</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'User asked about sports, specifically football (soccer).'</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mMemoryCollection\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mmemories\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mMemory\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'User introduced themselves as Neidu, an AI Engineer working on NLP related things.'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mMemory\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mcontent\u001b[0m=\u001b[32m'User expressed interest in the latest advancements in AI and its real-world applications, \u001b[0m\n",
       "\u001b[32mparticularly agentic AI workflow.'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mMemory\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'User asked about sports, specifically football \u001b[0m\u001b[32m(\u001b[0m\u001b[32msoccer\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.'\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "updated_conversation = [\n",
    "    HumanMessage(content=\"Hi, I'm Neidu.\"),\n",
    "    AIMessage(content=\"Nice to meet you, Neidu.\"),\n",
    "    HumanMessage(content=\"I'm an AI Engineer who's currently working on NLP related things\"),\n",
    "    AIMessage(\n",
    "        content=\"That sounds fascinating! NLP is a really exciting and impactful field in AI. \"\n",
    "        \"What will you like to know about AI?\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"Thanks! I'm curious about the latest advancements in AI and how \"\n",
    "        \"they're being applied in real-world applications. I'm also interested in \"\n",
    "        \"agentic AI workflow\"\n",
    "    ),\n",
    "    AIMessage(\n",
    "        content=\"Latest AI advancements include Generative AI (like LLMs for content and customer \"\n",
    "        \"service), Computer Vision (for autonomous tech and healthcare), Reinforcement Learning \"\n",
    "        \"(for robotics and optimization), and Edge AI (for on-device processing). Agentic AI \"\n",
    "        \"workflows involve autonomous AI agents that plan, execute, and iterate to achieve \"\n",
    "        \"complex goals with minimal human input.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"That's great! What do you know about about Sports? Specifically football (soccer)\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "# Update the instruction\n",
    "system_msg: str = \"\"\"\n",
    "<system>\n",
    "Update existing memories and create new ones based on the following conversation.\n",
    "\n",
    "<guidelines>\n",
    "- Extract and summarize key information about the user from their messages only\n",
    "- Focus on factual details provided by the user\n",
    "- Combine related information into coherent, concise memory entries\n",
    "- Avoid redundancy - merge similar or overlapping information\n",
    "- Ignore conversational pleasantries and focus on substantive content\n",
    "- Create memories that would be useful for future conversations with this user\n",
    "- Each memory should be a complete, standalone summary (not fragments)\n",
    "</guidelines>\n",
    "\n",
    "<output_format>\n",
    "- Return a memory with concise, non-redundant summaries that capture the \n",
    "essential user information.\n",
    "</output_format>\n",
    "\n",
    "</system>\n",
    "\"\"\"\n",
    "string_messages = convert_openai_messages_to_string(\n",
    "    messages=convert_to_openai_messages(updated_conversation)\n",
    ")\n",
    "structured_output_2, _ = await llm.get_structured_response(\n",
    "    message=system_msg + string_messages,\n",
    "    response_model=MemoryCollection,\n",
    ")\n",
    "\n",
    "console.print(structured_output_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcaa05b",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Chatbot With Collection Schema Updating\n",
    "\n",
    "- Let's update our chatbot to create and update a memory collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SYSTEM_MESSAGE: str = \"\"\"\n",
    "<system>\n",
    "You are a helpful AI assistant designed to be a companion to users. You maintain continuity \n",
    "across conversations through your long-term memory system, which allows you to build meaningful \n",
    "relationships and provide increasingly personalized assistance over time.\n",
    "\n",
    "<memory>\n",
    "Your long-term memory tracks important information about the user, including:\n",
    "- Personal preferences and interests\n",
    "- Goals and aspirations they've shared\n",
    "- Important life events and context\n",
    "- Communication style preferences\n",
    "- Previous conversations and topics discussed\n",
    "- Skills, expertise, and background information\n",
    "- Current projects or challenges they're working on\n",
    "\n",
    "Current Memory (may include updated memories from this conversation):\n",
    "{memory}\n",
    "</memory>\n",
    "\n",
    "<guidelines>\n",
    "- Use your memory to provide personalized, contextual responses\n",
    "- Reference relevant past conversations naturally when appropriate\n",
    "- Adapt your communication style to match their preferences\n",
    "- Maintain continuity by building on previous interactions\n",
    "- Keep responses concise and avoid unnecessary repetition\n",
    "</guidelines>\n",
    "\n",
    "</system>\n",
    "\"\"\"\n",
    "\n",
    "USER_MEMORY_INSTRUCTION: str = \"\"\"\n",
    "<system>\n",
    "Update existing memories and create new ones based on the following conversation.\n",
    "\n",
    "<guidelines>\n",
    "- Extract and summarize key information about the user from their messages only\n",
    "- Focus on factual details provided by the user\n",
    "- Avoid redundancy and combine related information into coherent, concise memory entries\n",
    "- Do not assume or infer information not explicitly stated by the user\n",
    "- Ignore conversational pleasantries and focus on substantive content\n",
    "- Create memories that would be useful for future conversations with this user\n",
    "- Each memory should be a complete, standalone summary (not fragments)\n",
    "</guidelines>\n",
    "\n",
    "<output_format>\n",
    "- Return a memory with concise, non-redundant summaries that capture the \n",
    "essential user information.\n",
    "</output_format>\n",
    "\n",
    "</system>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f10c7e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memories': [{'content': 'Nice to meet you, Neidu.'},\n",
       "  {'content': \"I'm an AI Engineer whos's currently working on NLP related things\"}]}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_output.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def call_llm(state: MessageState, config: RunnableConfig, store: BaseStore) -> dict[str, Any]:\n",
    "    user_id: str = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    prefix: str = \"memories\"\n",
    "    namespace = (prefix, user_id)\n",
    "    existing_memory = store.search(namespace)\n",
    "    # Format the memory\n",
    "    try:\n",
    "        formatted_memory = \"\\n\".join([f\"- {memory.content}\" for memory in existing_memory])\n",
    "    except Exception:\n",
    "        formatted_memory = \"No existing memory found\"\n",
    "\n",
    "    system_message: str = MODEL_SYSTEM_MESSAGE.format(memory=formatted_memory)\n",
    "\n",
    "    # Respond using memory + chat history\n",
    "    formatted_messages = convert_to_openai_messages(\n",
    "        [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    )\n",
    "    response, _ = await llm.ainvoke(messages=formatted_messages)\n",
    "\n",
    "    return {\"messages\": [AIMessage(content=response)]}\n",
    "\n",
    "\n",
    "async def write_memory(state: MessageState, config: RunnableConfig, store: BaseStore) -> None:\n",
    "    user_id: str = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    prefix: str = \"memories\"\n",
    "    namespace = (prefix, user_id)\n",
    "    existing_memory = store.search(namespace)\n",
    "\n",
    "    # Get the profile and convert to JSON doc\n",
    "    existing_profile = [m.value for m in existing_memory] if len(existing_memory) > 0 else None\n",
    "\n",
    "    # Invoke the extractor\n",
    "    messages = convert_to_openai_messages(\n",
    "        [SystemMessage(content=USER_MEMORY_INSTRUCTION)]\n",
    "        + [\n",
    "            AIMessage(\n",
    "                content=f\"\\nMemoryCollection: {json.dumps(existing_profile)}\\n\\n\\nChat History:\"\n",
    "            )\n",
    "        ]\n",
    "        + state[\"messages\"]\n",
    "    )\n",
    "    string_messages = convert_openai_messages_to_string(messages)\n",
    "    structured_output, _ = await llm.get_structured_response(\n",
    "        message=string_messages, response_model=MemoryCollection\n",
    "    )\n",
    "    # Get the updated profile as a JSON object\n",
    "    updated_profile = (\n",
    "        structured_output.model_dump()\n",
    "        if structured_output is not None\n",
    "        else MemoryCollection(memories=[]).model_dump()\n",
    "    )\n",
    "    # Save the updated profile\n",
    "    store.put(namespace, key, updated_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "90ae9c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJIAAAFNCAIAAABkBqGXAAAAAXNSR0IArs4c6QAAHWpJREFUeJztnXlcE2fewJ8ck4QkEEhIuC+5VASFgOC1VfBE6oFo1Yq11VpttXW7bu1dW+vWfddu7Xa7lV177KrriVgVtVZrFa2KICgIHghy35CE3Ne8f4wfltWArp0nyROf71/JzOT3/JgvzzPzzDzPDIMkSYBBDaajE8A8DlgbkmBtSIK1IQnWhiRYG5KwHVh2a61erbTotRa9xmIxodEPYXMYXD6Lx2cJPdk+wVxHpcGwf7+ttkJ7p0x956paIGJ7SAg3AYsnYBIcNOq9yWjVaSx6jVXZYdT1WMKHCwfFCkOG8O2chl21dTQaTu9rN2gt0YnukfHunlLCbkXDoLvVdLu052ZRD9+dNX6uTOLHsVvR9tN2Zn97dbl65BRJzCgP+5RoN65fUF061hkZ7z5utrd9SrSHNr3GemRbk28ob1S6hEUwYBfnEMwm8kJ+Z1u9fvoL/jwB9AYfurbuVuPRb5tT0r3D4wRQC3IGbhX3XP6xa/pSf9jtP1xteo1l/+cNUxb7SgMddtJlZ9rqDSe2t8x5NdBNyIJXCsTqbDGTh3Kaxs70fnKcAQBkQdwxM7yP/KPJaoFYCsTadvFoJ8Fhyid6QYrvzFw+0UWSYOQUMaT4sGpbT7e57qb2yXQGAEiaJK4u02iUsGocLG3nv+9IniqBFBwBGCB5qvjcoXZI4aFoUyvMqm6T/a8dOBVhwwTdrSatCkqFg6Ltdok6drQIRmS0iB0jul3aAyMyJG09oTH27qWNHz++paXlf/3V7t27P/zwQzgZgcBIt6pSNYzI9GtTK8wGnRVqr+VBGhsb1erH2UGVlZUQ0rmHyJvQKM0w2kn6b9y01hngXVQlSXLnzp1Hjx6tra0NDw9PSUlZsWJFcXHxypUrAQAZGRlpaWl//OMfq6qqcnNzCwsLW1pawsPDMzMzZ82aBQC4devWwoULP//88z179qhUKoIgSkpKAACHDx/evXt3REQE7Ql7+XDa6vX0tz0k3ZRfUJ7c1Up7WIodO3aMGTPm8OHDXV1d+/fvT01N3b59O0mSZ8+elcvlzc3N1GYrVqyYPXt2YWHh5cuX9+zZI5fLi4uLSZKsqamRy+VLlizZuXNnRUUFSZLZ2dnr16+HlC1Jkid2tFQWqmgPS39t02ssPD6sfkVJSUliYmJGRgYAYM6cOUlJSUaj8cHNNm3apNFo/P39AQCJiYl5eXnnz59PSEig1o4ePXrhwoWQMrwPnoBl0KHQSLJYDHiXOWNjY//2t79t2LAhPj5+woQJwcHBNjezWq27du06d+5cfX09tSQqKqp37ZAhQ2DlZwsYe4P+asF3Z2l7YF0dyM7OXrduXUdHx/r169PS0tavX9/V1XXfNlardfXq1VeuXHnttdfOnDlTVFQ0bNgwahWDwQAA8Hg8SOk9iFZlFrjTXzfoj8h3Z2t7zLSHpWAymZmZmZmZmXfu3CksLMzJydHr9Zs2beq7TWVl5Y0bN3JycuRyObVEqVRSH6gLsPa8oa/tsfA96D+ppl+bmzurs8nG8YYWjhw5EhMTExYWFh4eHh4e3tnZefLkyd5qREFJkkjuXVq7ceNGfX19XFyczYB9f0g7JEm2Nxj4EGob/Y2kp5Qwm6ztDQbaIwMA8vPzf//73xcUFKhUqrNnzxYUFIwYMQIAEBgYCAA4ceJERUXFoEGDGAzGzp071Wp1TU3Nli1bEhMT++uJBwQElJWVFRUVKRQK2rNtqzcyGEAkhTA8jvZzU5Ikf9zZUvRjF4zIzc3Nr7/+ulwul8vlU6ZM2bp1q0ajoVa98847ycnJr7zyCkmSx48fz8rKksvlmZmZ5eXlP/zwg1wuX7RoEdUBKCws7A14+fLl2bNnjxw5kuoh0EvhD52ndkPpC0G533a3QluQ177orWAG0zVHjjwKViv5rw21afNlQdH0X1KH0sEKHuzGYICbxVAux6HCjcIegssIjHKDERzKqGQmkzF2lrQgrz0qQchk2ahwzc3NCxYs6Oe3TKvVanNVVlbWqlWr6E72HmvWrCktLbW5ymg0cji2L9d99913oaGhDy4nraDwh65Ji3wgnfJAHJSQ92WjTzBv9NM2bpZarVaNRmPzV3q9vr9+FUEQ8LpcWq3WYrHd3RwgJYFAwGTaaLHOfd/R1WKc8ZI/3WneA6I2tcK8e3P9hHmyJ2GoXV9ul6jP5LbNXxss9IQ1xQLiyC2hJztjmd9Pu1shdQack/YGw8/72ma8FADPGfSJUr6hvAnPyPK+bLx73XaT6GLUXNfkfdmY+oxMFgR3jKE9BpM31+jzv26Wp3nFT/CEXZYDKfqxu/RM94zlATL4E6jsNHWjp9v0/dYmvjvrqTlSiZ+rjXbtaDT8vL9dr7XMXOHv7mWPaUR2nShVfl555XS3f7hbeJwwINyNw0NjTlt/GPXWhipd9TV1U7UuIdVrmB1HPTlgWmLNdU1VifpupcZDTIh9OJ4ywkvGsfPYk8dGq7Yo2ozdbaauFqNaYQodIoiMdw8Z6tLTEu+j5a6+s8WobDcpOox6je0u9mPT2dnZ9z4AXbgJmJ5SjsibEPtyfEPtd9/uPhypDSo5OTkMBmP58uWOTgQKaB9dnliwNiTB2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSV3ucTEZGBvXsburpsO7u7larlcFg5OfnOzo1OoH4qEqHEBAQcPny5d4H4VLykpKSHJ0XzbhaI5mdne3p+V9PrRSJRIsXL3ZcRlBwNW1jx46Njo7uuyQiImLUqFGOywgKrqYNALBw4UKR6N6jHV2yqrmmtnHjxvW+rS0yMnLMmDGOzoh+XFBbb4Vz1apm1zNJs4lsbzBYLfbobwzyS4wZNA4AECKLb6zS2aFEJoshDeSyCTu908ce/bb6W7qLRzs1SrNAxIb6vjQHQpKkWmH2ELOTp0ogvdemL9C1ndnf3lClG5fp6+UD663OzkNXi/HcgZaQofyxM72hFgT32FZ3U1t9TT1tadCT4AwAIPblTFsadPtKT22lFmpBcLVdOdmdOFVKcFyzYbQJwWUkTPK+eob+dy/2Ba62jmajX7i9H7bucHxD3Dpb4L7WB642k9HKRfwdDY8B34OtUcJ6hTUFxH1qNpJPUOP437AIhtkE8VzviasKrgHWhiRYG5JgbUiCtSEJ1oYkWBuSYG1IgrUhCdaGJFgbkiCv7f0Pfv/GulUAgOrqqglpieXlV+nd3jlBXtuTCdaGJE43B6C2tubTzzaWlZUG+AeOHz/pucXLCYIAAOQe2H3p0rnKG+VcLi8+Pmnp8y/7+vrRVegH69/gcDhyefKnf95IEMTQIbHvvffJvn07dv77Wy8vccb02S88v5KusmjBuWpbU3Pj6ldfiB+R+Onmr+bMWXjs+KGvcrYAAK5dK/nrl5tjY+M/+nDzujfWNzc3/t+fPqSxXIIgyspLb96s2L/vh7/+5dvSq8WvrVnG5fKOHil4Y+3723d8XVZWSmNxvx7nqm25B3a58fnPLV7OZDIT4pMIgqivrwUAxMTEfbNtT1BQCJvNBgDodNoP1r9hMBi4XC4t5TIYDLPZ/MrLv2Oz2SIPUVBQCJfDzV60FACQkjKWx+PdrroZGzuClrJowbm01VRXRUUO6Z3mlDF9NvWBxWI1Ntb/9cvNN25e12rvDYrq7Orw9wugpVySJP39A6n/CQAAny8ICgzpXSsQCLVaDS0F0YVzNZJqdQ+HY2No3rlzP7/3wdphw4Z/8fk3p08VfbJxC73lkiR537jb3n8daq3VaqW3xF+Jc9U2odBdq7MxwjD/2MH4EYnPL1lBfe3pUdk9NefCuWpbdPTQ8vJSi+XesKcTJ/LXvfUqAEClUnp5iXs3O1NwynE5OgXOpS192ky9Xv/Zlk+KrxQWnDv9921fyKQ+AIBBYRHFVwrLykrNZvPuPf/iEBwAQFtri6PzdRjO1UgGBYV88ofPN3+6If/oQS6XO23qjBeXrQYALFv6ikajXvfWar1ePzfr2XVvrK+rv/vb37308UefOjplxwBx6obZSG57t/rZd8IhxXdmdmy88+LGQfDmTTlXI4l5RJyrkaSFGTMn9NeEvPP2xykpY+2eEf24oLacnJ39rfLyFPe3Ci1cUJufr7+jU4AOPrYhCdaGJFgbkmBtSIK1IQnWhiRYG5JgbUiCtSEJRG1sDtynBTgzFhMJ9bFpcGubyJtQdZmgFuGEKNtNXjICahFwtUn9uXWVaqhFOCG1lWrvAHpGAvYHXG1JU8WVlxTKdiPUUpyK7lbjjULFyClwbzVAfzBhe4Phx52t0Yki30F8DzHcpsOxqLpMjbc1d0pUkxb5wK5t9ngMqNlIFp3sqr+pa63Twy7LgfiG8IIH8xNSvdjwn+jnam/d6CUnJ4fBYCxfvtzRiUAB99uQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakMTVngI0f/78qqqqvktIkhw0aNC+ffsclxT9uFpty8rKuu/1wDwe79lnn3VcRlBwQW1BQUF9lwQFBc2aNctxGUHB1bQBAObOncvj8ajPHA5n3rx5js6IflxQ2+zZswMC7r2POyQkJDMz09EZ0Y8LamMymfPmzeNyua5a1VzwTLIXStjevXsdnQgUHqKt4bau/LyyuUanUVnsmNWTi0DE8gtzixsr8g93G2CzgbQVHOxorTXEp0o8ZRwOzwWbUyfEqLcq2owlpzp8w3hjZ3r3t1m/2kp+VjTXGMZl+sBMEtMvBbmt/uHcEU952lxruw5pVJaS04rkdCnk3DD9kjxdWnJaoVPbPjbZ1tZUrZMF83DD6EA4PKY0kNdcY/tZ7rbFdLcYRd4cyIlhHoKnlNPeaLC5yrY2i5lksaA/zB4zMAwmw2qxfeaBm0EkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JHKatqurWhLTE8vKrjkoAaRymzctLvDh7mVTqAwCorq56dtFMR2WCImxHFSyReD+/ZAX1+cbN645KA1HoqW2ZWZO37/ia+tzZ2TEhLfHjP7zbu3bGrNQDB3bn5u6aNz/9ctHFJS/Mzfn7X3obyW+/2/qnzRuamhsnpCUeyNsDAOjq6tzw8dvPLJg+K3PiJ3/8oLGp4aEJ5B7YPfeZabdu38iaN3XSlJRlyxfcvFV55uypjBlPpWeM+2jDWz3qHmrL/oI/egQAwLffbV2UPWvy1FGLl8zZ8vkmajwO9RddvHR+3Vuvvrxqyatrlq17c3XfJN98+7W9+3bQssPp0SaXJ1dUllGfi4svicWSiuvXqK81NXd6elSJiSkEh6PRqPft27E4+8WMjP+MFH5+yYp5cxf5+wWcPlWUOfsZi8Wy5vXl5devrv3de99+vVfAF7z8ynOtrS0DJ8DhcHp6VNu3b9vy2T8OHjil0+k2/uHd06dPfPv1vn9+m1tUdPHgwb0AgAGCP2IEytmR/LyXV76eu//E4uwXT/yY//2h/VQEAMD2HduSElNee3Vd+rSZRcWXlCol9SuNRlNcfClmaBwtO5webQnxSRUV97RdKyuZMjmjrb21o6Od+iqVyoKDQwEAWq322YUvpE6YHOAf2F+oa2Ul9fW1b7+5ISkxxctLvOqVtW5ubgfydg+cAIPBMBgMzy9ZERgQJBAIkhJTWlqafrvmLalUJpXKhsbE3blza+DgjxhBqVLu2v3P5xYvHz36N+5C94lpU2fNnPfPf/3darVSmYxMGp01Z2F01JDUCVM4HM6pU8ep5WcLTrHZ7OjoobTscHq0JcpTVCplXd1datfExydFRw+9eu0KAKC8vFSekNy75eDBMQOHKi+/yuPxhg9PuJcfkxkbG19aWjTwr6hmKjR0EPVVIBB6S6Qi0b3RagK+QKvVDBz8ESM0NdabTKa+f0V4eJRC0d3adq89iI4aQn3gcDiTJ00/9VOvtp/SUqey2fScTNATRSqVBQQElZWXikSeDQ11cbHxMUPjystL01KnlJQWvfTiq9S/MwDgvslnD6JW9+j1+glpiX0XSiT9DvSkoHY6VQQFk8nsu5aqDQMEf8QInV0dAAAel9e7iu/GBwDotFqCIAAAXN5/Vs14OmvZ8gWtrS1CoXtR0cXPP/vHwH/Fo0PbmWSiPLmyspzHc4uOGsLlcmNjR2zfvq2pubGzsyM5ZWzvfiFJsu+ueRCJxFsgEGz46NP/ypJFT56/PrhAIAQA6A3/GQen1WmpyEqlovfPpAgPj4yKHHz02MHg4LCAgKChQ2Np+Svo1DZiROLX3/yNw+HExsYDAGKHjai6c+vihYLIiGgPd4+Bf9tXZFhYhEaj8fHx8/e7N9mpsalBIn5IbXtEfn3w8PAoFotVVlYaFTmYWlJRWSaReItEnpS2+0hPn7V3345BYRHp0+jsmNLW3Y6PT2pubrx48dzwuAQAgKenV1BQyIGDexISRj70t/7+gW3trefPn2lorE9KTElKTNm8eUNbW6tC0Z17YPeKlYt+PHmUliR/fXAPd4+JE6dt37HtwoWCHnXPseOH8vPzsuYs7G/7tNSpbW0thZd/mTQxnZY/gYK22ibyEIUPirx1+0Z8fBK1JGZo3LHjh3q/DsDoUb85eerYu+//7sVlqxYuWLLpk7/kHdz74YY3KyrKgoND06fNejqDtqmFvz74qpfXAhJ89PFbZrM5ICDoucXL52b1OzdcKBTK5clsNtvLS0xH+vewPXXjwpFOEjBjx3nRWNKTiV6vnzc//e03P0pJGfu//vba2W4m0zpquuTBVQ67uOXytLQ0NzbV78/9d1hY+GM4GxhktL31zpryslKbq2bMyHpx2Sq7Z/QQTv10fNvXX8bExH3w3ibagyPTSGq1WovV9qwhgk3w+vSWXAZXaCT5fL6jU3Ai8N1tJMHakARrQxKsDUmwNiTB2pAEa0MSrA1JbGtjYJvOQX93lG378RATPd0muBlhHoa62ySSEDZX2dbmHcBtrdVBzgrzEFrrdNIg29dabWuTBnL47qzrv9i4y46xD+Xnu92ELG9/289i6ufYxmBMXuRbfq7r6s9dkNPD2KDkp87rv3RPW+Lb3wYDPU9SrTCf2NHaWqv3lHIILmJnKVaSBAAwBxwl5oSYDFZFu9E3lDd5kY9A1O/9mYc/dFevsai6zCaDFUKSEDl8+DAA4Omnn3Z0Iv8bHB7T3YvNE7AG3uzh99t4AtZDozghDH43g8EIiBjo0bXogljTh6HA2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JsDYkwdqQBGtDEqwNSbA2JMHakARrQxKsDUmwNiTB2pAEa0MSrA1JHv4UILTIyMhoamq6b6G/v/+RI0cclBEUXK22paenMx9g2rRpjs6LZlxNW1ZWVnBwcN8lISEhCxYscFxGUHA1bTKZbOLEiX2XpKamisV0vvLOGXA1bQCAOXPmhIaGUp+Dg4Pnzp3r6IzoxwW1+fj4jB8/nvo8adIkmUzm6IzoxwW1AQDmzZsXGhoaHByclZXl6Fyg4OAOgEZluXNVrewwadUWvdpiMNCWTFtrG2AAGqsal8vgCVl8IUvkTYQPFwo8HPmMTYdpu/JT940itbLD6OkjYPMJFsFiEywW23lrv8VstRgtZrPFrDUpWjWeUs6QJPcR4z0dkowDtFVd1ZzNbScEhMjXw0OG6jsQVW1aZZPKbDCNmy2NGC6wc+l21WYykEe+buluN/tEeAnErvA4XHWnvu1Ol1jGzljqy+bY73Ha9tOmVphzv2jkegh8o5zoTbW00HKzy6jWZa7yF3ra6V2vdtLW0WQ88EWDd5iXOMjDDsXZn646Vcfd7jmvBkr8bL9wgV7scQqg11i+39oki5S4qjMAgDjYQxYpOfhVk05t+y3T9AJdm8VMHviySSgVevoJYZflWDz9hEJv4cGvmiwW6A0YdG2XT3RbrExZuGNOlO2MLMLTbGEVn4T+hhm42jRKS9k5pX+MjIHaS0seDwaD4T9UevWMCnZTCVfbuUMdXoHuztyJph0WwfQM8Dh/uBNqKRB3qFFvra3QegU7afOoULaufS+5vPIs7ZHFQR53rqqNeohvBYKorbpMI/IVsFhPRPPYFxbB9PQV3K3QwCsCorbbV9U8kStcCnkMeCK3qhKI2iD26ttqDaFJ3pCCq3o6Dx377G7dNZPJMDhq9KTxS70lgQCAggt7Thdsf2nJF9/tWtfeUevnGzlhbHbC8CnUr0qunTh+KkevVw8dPO43o+ZDyg0AIJC41RVDPJ+EVttIQJKARUCJb7FYvvpm5d26a3NnvrN29S4eV/CXv7/QrWgBALDZHJ1elZe/eX7m+5s3XBoSNWZP3kc96i4AQHNr1b/3vz8y4ek31+yPj52cl/8pjNwo2ATTYiEBtP4bLG1qpZnNgRW8pra0vaN2wZz10ZHJ7kLxzPTXuRy3cxf3UqfgJpNh2sSVIUHDAAAj5U9bLOam5tsAgF8u5Yo9/dOeWuLm5h4VMTIpIQNSehRsgqnpgdUNgLVne7rNkKoaAOBu3VUOwQsPS6C+MpnMsJARVdXFAADqEmtQwFBqFY8rBADo9D0AgPbOOh+fQb1BggKGQEqPgkWw1AozpOCwjm0kCeBdo9bp1UaTfu17yX0Xerh73ysYgN7efd+zWK1WJRT85+YDh4B8ukQCqxnWLoClje/OMhtgNRHuQgmPK1iy8E99FzJZDxkl4ObmbjTpe78aDBDP9AAAZqOFD23gAkRtRmja/Hwj9AaNl6evRBxALenoavAQPuSs1cvT9+bti1arlclkAgAqb52HlB6FUWvmu8PavbAOPxwe02q2GnVQGvfoiOSoiOS9BzcqlK1qTXfBhT1bvnqu+OqxgX8VF5PWo+7MP/FXkiRv37l84XIejNwoTHozyQAEF9alBoj9NlkwT92pEwe6wwi+LHvL+Uv7tu95p7a+TOYdmiyfOSpp9sA/GRo9JmPK6guFB86c3yn28p+f+f5X36yEdARWtWl9Q3gwIlNAvLt9rUBZfknjH+MDKb4z01jWOnysYNhoEaT4EC9uRQwXdjfrTNCOcE6LWW9RtusiR0BpZiggNpJ8D1ZEnLCrVuETJbG5gcVi+WDTZJurzGYjm8UBtg4N/j6RLy/bSmOe722c2N/1DKvVwmTaOBsMCx6+NPvP/QXsqFVExgu5fIhVAu4QII3S/K+NtRGjgwiu7VPhru77pxBS6PVqHs/2IAYWixB5SGlMsr8cAABGk4FDcB9czmZxPDxsn7ia9OaqXxoWvxsqEEEctgx95Nb5Q53VFbrAON8n4QY3SZJ1Jc1RI/ijpttuYOgC+n3n5GlePC7ZUd0NuyBnoP1Ot9CDMXIK9Ol00LWxCeaslwPMWr2yWQ27LMeiaFZbdPoZywNYbOjtip2Gt+q11u+3NrEFbhJnHaPwK+msVZi1ulkr/KGeifRiv8HkFjN5YkeropP0GSxlMl3nOGe1ks0VbWIpc0q2D9NeIzDsPeOm+GR3+YUeSZhYKHGF8Qo9HdrO6q64caKEVLu2Ig6YKKVoN5X8rGhvMvM8+HyxG5vjyPl9j4dZb9EodQaF1ieIiB8v8pAQdk7AkbNJq8s0N69oOpqMDCaDRbAYbBZ1bd45sVqtpMliMVsASUr8OEMSBaEx9p7W1otTPAVIrTAr2k3KDpNGZYY3/uJXwQACEdvTm/CUEgKRnWZDDZSOM2jD/K84b6OEGQCsDUmwNiTB2pAEa0MSrA1J/h85/7Q0Yz20GgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_builder = StateGraph(MessageState)\n",
    "\n",
    "# Add nodes\n",
    "graph_builder.add_node(\"call_llm\", call_llm)\n",
    "graph_builder.add_node(\"write_memory\", write_memory)\n",
    "\n",
    "# Add edges\n",
    "graph_builder.add_edge(START, \"call_llm\")\n",
    "graph_builder.add_edge(\"call_llm\", \"write_memory\")\n",
    "graph_builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Long-term-memory store (across threads)\n",
    "across_thread_memory = InMemoryStore()\n",
    "# Short-term-memory store (within a thread) checkpointer\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Compile the graph\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=within_thread_memory, store=across_thread_memory\n",
    ").with_config(run_name=\"Chatbot-with-user-profile\")\n",
    "\n",
    "\n",
    "# Visualize the graph\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, my name is Chinedu. I live in Lagos, Nigeria.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, my name is Chinedu. I live in Lagos, Nigeria.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Nice to meet you, Chinedu. Lagos is a vibrant city, isn't it? I've been keeping track of our conversation history, but this is our first interaction, so I don't have much to draw from just yet. I'm excited to get to know you better and learn more about your interests and preferences.\n",
      "\n",
      "Since you live in Lagos, I'm curious - what do you like to do in your free time? Are you interested in exploring the city, trying new foods, or perhaps pursuing a hobby?\n"
     ]
    }
   ],
   "source": [
    "config: dict[str, Any] = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "msgs = [\"Hello, my name is Chinedu. I live in Lagos, Nigeria.\"]\n",
    "\n",
    "input_state = MessageState(messages=[HumanMessage(content=msg) for msg in msgs])\n",
    "\n",
    "async for event in graph.astream(input_state, config=config, stream_mode=\"values\"):\n",
    "    for msg in event[\"messages\"]:\n",
    "        msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'namespace'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'memories'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'b2793a7f-2a6d-4953-808a-3e5e9d32d834'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'memories'</span>: <span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'User lives in Lagos, Nigeria.'</span><span style=\"font-weight: bold\">}]}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2025-06-23T00:33:47.480810+00:00'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'updated_at'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2025-06-23T00:33:47.480815+00:00'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'namespace'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'memories'\u001b[0m, \u001b[32m'1'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'key'\u001b[0m: \u001b[32m'b2793a7f-2a6d-4953-808a-3e5e9d32d834'\u001b[0m,\n",
       "    \u001b[32m'value'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'memories'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'content'\u001b[0m: \u001b[32m'User lives in Lagos, Nigeria.'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'created_at'\u001b[0m: \u001b[32m'2025-06-23T00:33:47.480810+00:00'\u001b[0m,\n",
       "    \u001b[32m'updated_at'\u001b[0m: \u001b[32m'2025-06-23T00:33:47.480815+00:00'\u001b[0m,\n",
       "    \u001b[32m'score'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for m in across_thread_memory.search((\"memories\", \"1\")):\n",
    "    console.print(m.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "3a5aef10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, my name is Chinedu. I live in Lagos, Nigeria.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Nice to meet you, Chinedu. Lagos is a vibrant city, isn't it? I've been keeping track of our conversation history, but this is our first interaction, so I don't have much to draw from just yet. I'm excited to get to know you better and learn more about your interests and preferences.\n",
      "\n",
      "Since you live in Lagos, I'm curious - what do you like to do in your free time? Are you interested in exploring the city, trying new foods, or perhaps pursuing a hobby?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm an AI Engineer who's currently working on NLP related things\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, my name is Chinedu. I live in Lagos, Nigeria.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Nice to meet you, Chinedu. Lagos is a vibrant city, isn't it? I've been keeping track of our conversation history, but this is our first interaction, so I don't have much to draw from just yet. I'm excited to get to know you better and learn more about your interests and preferences.\n",
      "\n",
      "Since you live in Lagos, I'm curious - what do you like to do in your free time? Are you interested in exploring the city, trying new foods, or perhaps pursuing a hobby?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm an AI Engineer who's currently working on NLP related things\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's fascinating, Chinedu. As an AI Engineer working on NLP, you must be passionate about the intersection of artificial intelligence and human language. I'd love to learn more about your current projects and challenges.\n",
      "\n",
      "In Lagos, there's a growing interest in AI and NLP, with many startups and research institutions exploring its applications. Have you been involved in any local initiatives or collaborations that you'd like to share?\n",
      "\n",
      "Also, I'm curious - what specific areas of NLP are you currently focusing on? Are you working on natural language processing, machine learning, or perhaps developing conversational AI systems like myself?\n"
     ]
    }
   ],
   "source": [
    "msgs = [\"I'm an AI Engineer who's currently working on NLP related things\"]\n",
    "input_state = MessageState(messages=[HumanMessage(content=msg) for msg in msgs])\n",
    "\n",
    "async for event in graph.astream(input_state, config=config, stream_mode=\"values\"):\n",
    "    for msg in event[\"messages\"]:\n",
    "        msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "64312558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'memories'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'User lives in Lagos, Nigeria.'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'User is an AI Engineer working on NLP related things.'</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'memories'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'content'\u001b[0m: \u001b[32m'User lives in Lagos, Nigeria.'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'content'\u001b[0m: \u001b[32m'User is an AI Engineer working on NLP related things.'\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for m in across_thread_memory.search((\"memories\", \"1\")):\n",
    "    console.print(m.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "1821a8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, my name is Chinedu. I live in Lagos, Nigeria.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Nice to meet you, Chinedu. Lagos is a vibrant city, isn't it? I've been keeping track of our conversation history, but this is our first interaction, so I don't have much to draw from just yet. I'm excited to get to know you better and learn more about your interests and preferences.\n",
      "\n",
      "Since you live in Lagos, I'm curious - what do you like to do in your free time? Are you interested in exploring the city, trying new foods, or perhaps pursuing a hobby?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm an AI Engineer who's currently working on NLP related things\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's fascinating, Chinedu. As an AI Engineer working on NLP, you must be passionate about the intersection of artificial intelligence and human language. I'd love to learn more about your current projects and challenges.\n",
      "\n",
      "In Lagos, there's a growing interest in AI and NLP, with many startups and research institutions exploring its applications. Have you been involved in any local initiatives or collaborations that you'd like to share?\n",
      "\n",
      "Also, I'm curious - what specific areas of NLP are you currently focusing on? Are you working on natural language processing, machine learning, or perhaps developing conversational AI systems like myself?\n"
     ]
    }
   ],
   "source": [
    "# Chat history\n",
    "state = graph.get_state(config=config).values\n",
    "\n",
    "for m in state[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "8fb7672d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, my name is Chinedu. I live in Lagos, Nigeria.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Nice to meet you, Chinedu. Lagos is a vibrant city, isn't it? I've been keeping track of our conversation history, but this is our first interaction, so I don't have much to draw from just yet. I'm excited to get to know you better and learn more about your interests and preferences.\n",
      "\n",
      "Since you live in Lagos, I'm curious - what do you like to do in your free time? Are you interested in exploring the city, trying new foods, or perhaps pursuing a hobby?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm an AI Engineer who's currently working on NLP related things\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's fascinating, Chinedu. As an AI Engineer working on NLP, you must be passionate about the intersection of artificial intelligence and human language. I'd love to learn more about your current projects and challenges.\n",
      "\n",
      "In Lagos, there's a growing interest in AI and NLP, with many startups and research institutions exploring its applications. Have you been involved in any local initiatives or collaborations that you'd like to share?\n",
      "\n",
      "Also, I'm curious - what specific areas of NLP are you currently focusing on? Are you working on natural language processing, machine learning, or perhaps developing conversational AI systems like myself?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm looking to integrate AI in the Financial Services Industry\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, my name is Chinedu. I live in Lagos, Nigeria.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Nice to meet you, Chinedu. Lagos is a vibrant city, isn't it? I've been keeping track of our conversation history, but this is our first interaction, so I don't have much to draw from just yet. I'm excited to get to know you better and learn more about your interests and preferences.\n",
      "\n",
      "Since you live in Lagos, I'm curious - what do you like to do in your free time? Are you interested in exploring the city, trying new foods, or perhaps pursuing a hobby?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm an AI Engineer who's currently working on NLP related things\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's fascinating, Chinedu. As an AI Engineer working on NLP, you must be passionate about the intersection of artificial intelligence and human language. I'd love to learn more about your current projects and challenges.\n",
      "\n",
      "In Lagos, there's a growing interest in AI and NLP, with many startups and research institutions exploring its applications. Have you been involved in any local initiatives or collaborations that you'd like to share?\n",
      "\n",
      "Also, I'm curious - what specific areas of NLP are you currently focusing on? Are you working on natural language processing, machine learning, or perhaps developing conversational AI systems like myself?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm looking to integrate AI in the Financial Services Industry\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's a great area of focus, Chinedu. Integrating AI in the Financial Services Industry can bring about significant improvements in efficiency, accuracy, and customer experience. There are many potential applications, such as risk management, credit scoring, portfolio optimization, and chatbots for customer support.\n",
      "\n",
      "In Nigeria, the financial services industry is rapidly evolving, with the rise of fintech and digital banking. I'm sure you're aware of the challenges and opportunities that come with this growth.\n",
      "\n",
      "Have you considered the regulatory landscape in Nigeria, particularly with regards to AI adoption in the financial services sector? The Central Bank of Nigeria (CBN) has been actively promoting the use of technology in banking, but there are also concerns around data protection and cybersecurity.\n",
      "\n",
      "Also, I'd love to know - what specific AI technologies or techniques are you exploring for integration in the financial services industry? Are you looking at machine learning, deep learning, or perhaps natural language processing for text analysis?\n"
     ]
    }
   ],
   "source": [
    "msgs = [\"I'm looking to integrate AI in the Financial Services Industry\"]\n",
    "input_state = MessageState(messages=[HumanMessage(content=msg) for msg in msgs])\n",
    "\n",
    "async for event in graph.astream(input_state, config=config, stream_mode=\"values\"):\n",
    "    for msg in event[\"messages\"]:\n",
    "        msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "8cedf980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, my name is Chinedu. I live in Lagos, Nigeria.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Nice to meet you, Chinedu. Lagos is a vibrant city, isn't it? I've been keeping track of our conversation history, but this is our first interaction, so I don't have much to draw from just yet. I'm excited to get to know you better and learn more about your interests and preferences.\n",
      "\n",
      "Since you live in Lagos, I'm curious - what do you like to do in your free time? Are you interested in exploring the city, trying new foods, or perhaps pursuing a hobby?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm an AI Engineer who's currently working on NLP related things\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's fascinating, Chinedu. As an AI Engineer working on NLP, you must be passionate about the intersection of artificial intelligence and human language. I'd love to learn more about your current projects and challenges.\n",
      "\n",
      "In Lagos, there's a growing interest in AI and NLP, with many startups and research institutions exploring its applications. Have you been involved in any local initiatives or collaborations that you'd like to share?\n",
      "\n",
      "Also, I'm curious - what specific areas of NLP are you currently focusing on? Are you working on natural language processing, machine learning, or perhaps developing conversational AI systems like myself?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm looking to integrate AI in the Financial Services Industry\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's a great area of focus, Chinedu. Integrating AI in the Financial Services Industry can bring about significant improvements in efficiency, accuracy, and customer experience. There are many potential applications, such as risk management, credit scoring, portfolio optimization, and chatbots for customer support.\n",
      "\n",
      "In Nigeria, the financial services industry is rapidly evolving, with the rise of fintech and digital banking. I'm sure you're aware of the challenges and opportunities that come with this growth.\n",
      "\n",
      "Have you considered the regulatory landscape in Nigeria, particularly with regards to AI adoption in the financial services sector? The Central Bank of Nigeria (CBN) has been actively promoting the use of technology in banking, but there are also concerns around data protection and cybersecurity.\n",
      "\n",
      "Also, I'd love to know - what specific AI technologies or techniques are you exploring for integration in the financial services industry? Are you looking at machine learning, deep learning, or perhaps natural language processing for text analysis?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Risk management and credit scoring are my main focus areas\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, my name is Chinedu. I live in Lagos, Nigeria.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Nice to meet you, Chinedu. Lagos is a vibrant city, isn't it? I've been keeping track of our conversation history, but this is our first interaction, so I don't have much to draw from just yet. I'm excited to get to know you better and learn more about your interests and preferences.\n",
      "\n",
      "Since you live in Lagos, I'm curious - what do you like to do in your free time? Are you interested in exploring the city, trying new foods, or perhaps pursuing a hobby?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm an AI Engineer who's currently working on NLP related things\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's fascinating, Chinedu. As an AI Engineer working on NLP, you must be passionate about the intersection of artificial intelligence and human language. I'd love to learn more about your current projects and challenges.\n",
      "\n",
      "In Lagos, there's a growing interest in AI and NLP, with many startups and research institutions exploring its applications. Have you been involved in any local initiatives or collaborations that you'd like to share?\n",
      "\n",
      "Also, I'm curious - what specific areas of NLP are you currently focusing on? Are you working on natural language processing, machine learning, or perhaps developing conversational AI systems like myself?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm looking to integrate AI in the Financial Services Industry\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's a great area of focus, Chinedu. Integrating AI in the Financial Services Industry can bring about significant improvements in efficiency, accuracy, and customer experience. There are many potential applications, such as risk management, credit scoring, portfolio optimization, and chatbots for customer support.\n",
      "\n",
      "In Nigeria, the financial services industry is rapidly evolving, with the rise of fintech and digital banking. I'm sure you're aware of the challenges and opportunities that come with this growth.\n",
      "\n",
      "Have you considered the regulatory landscape in Nigeria, particularly with regards to AI adoption in the financial services sector? The Central Bank of Nigeria (CBN) has been actively promoting the use of technology in banking, but there are also concerns around data protection and cybersecurity.\n",
      "\n",
      "Also, I'd love to know - what specific AI technologies or techniques are you exploring for integration in the financial services industry? Are you looking at machine learning, deep learning, or perhaps natural language processing for text analysis?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Risk management and credit scoring are my main focus areas\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Risk management and credit scoring are critical components of the financial services industry, and AI can bring significant improvements in accuracy and efficiency.\n",
      "\n",
      "In risk management, AI can help identify potential risks and anomalies in financial data, enabling early detection and mitigation of potential losses. This can be achieved through techniques such as anomaly detection, predictive modeling, and decision tree analysis.\n",
      "\n",
      "For credit scoring, AI can help analyze vast amounts of data, including credit history, income, employment, and other factors, to provide more accurate and personalized credit scores. This can lead to better lending decisions, reduced defaults, and improved customer experience.\n",
      "\n",
      "In Nigeria, there's a growing need for more robust credit scoring systems, given the country's large informal economy and limited access to credit for many individuals and businesses. I'm sure you're aware of the challenges and opportunities in this space.\n",
      "\n",
      "Have you explored any specific AI models or techniques for risk management and credit scoring, such as logistic regression, random forests, or neural networks? Additionally, are you working with any local financial institutions or fintech companies to develop and implement these solutions?\n"
     ]
    }
   ],
   "source": [
    "msgs = [\"Risk management and credit scoring are my main focus areas\"]\n",
    "input_state = MessageState(messages=[HumanMessage(content=msg) for msg in msgs])\n",
    "\n",
    "async for event in graph.astream(input_state, config=config, stream_mode=\"values\"):\n",
    "    for msg in event[\"messages\"]:\n",
    "        msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "860f3fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'memories'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"User's name is Chinedu.\"</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'User lives in Lagos, Nigeria.'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'User is an AI Engineer working on NLP related things.'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'User is interested in integrating AI in the Financial Services Industry.'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'User is exploring AI technologies for integration in the Financial Services Industry.'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'User is looking to integrate AI in the Financial Services Industry.'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"User's main focus areas are risk management and credit scoring.\"</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'User is currently working on NLP related projects.'</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'memories'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'content'\u001b[0m: \u001b[32m\"User's name is Chinedu.\"\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'content'\u001b[0m: \u001b[32m'User lives in Lagos, Nigeria.'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'content'\u001b[0m: \u001b[32m'User is an AI Engineer working on NLP related things.'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'content'\u001b[0m: \u001b[32m'User is interested in integrating AI in the Financial Services Industry.'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'content'\u001b[0m: \u001b[32m'User is exploring AI technologies for integration in the Financial Services Industry.'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'content'\u001b[0m: \u001b[32m'User is looking to integrate AI in the Financial Services Industry.'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'content'\u001b[0m: \u001b[32m\"User's main focus areas are risk management and credit scoring.\"\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'content'\u001b[0m: \u001b[32m'User is currently working on NLP related projects.'\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for m in across_thread_memory.search((\"memories\", \"1\")):\n",
    "    console.print(m.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d0dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Type, TypeVar\n",
    "\n",
    "from openai import AsyncOpenAI  # type: ignore\n",
    "from pydantic import BaseModel, SecretStr, validate_call\n",
    "\n",
    "T = TypeVar(\"T\", bound=BaseModel)\n",
    "SYSTEM_MESSAGE: str = \"\"\"\n",
    "<system>\n",
    "/no_think\n",
    "\n",
    "<role>\n",
    "You are a data extraction expert. Extract information from the provided text and return ONLY a \n",
    "valid JSON object that matches this exact schema:\n",
    "\n",
    "<schema>\n",
    "{json_schema}\n",
    "</schema>\n",
    "</role>\n",
    "\n",
    "<guidelines>\n",
    "- Return only valid JSON - no explanations, markdown, or additional text\n",
    "- Extract data precisely as it appears in the source text\n",
    "- Do not include fields not present in the schema\n",
    "- For missing required fields, use these defaults:\n",
    "  * Numbers: 0\n",
    "  * Strings: null\n",
    "  * Booleans: false\n",
    "  * Arrays: []\n",
    "  * Objects: {{}}\n",
    "- Preserve original data types and formatting where possible\n",
    "- If text contains ambiguous information, choose the most likely interpretation\n",
    "</guidelines>\n",
    "\n",
    "<validation>\n",
    "Rsponse must:\n",
    "- Be parseable by json.loads\n",
    "- Contain only fields defined in the schema\n",
    "- Use correct data types for each field\n",
    "- Have no trailing commas or syntax errors\n",
    "</validation>\n",
    "\n",
    "</system>\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_MESSAGE_VLLM: str = \"\"\"\n",
    "<system>\n",
    "/no_think\n",
    "\n",
    "<role>\n",
    "You're an AI assistant that helps people extract relevant information.\n",
    "</role>\n",
    "\n",
    "</system>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def _clean_response_text_single_regex(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean response text by removing XML-like tags and backticks using regex pattern.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        Input text containing XML-like tags and backticks to be cleaned.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Cleaned text with XML-like tags and backticks removed.\n",
    "    \"\"\"\n",
    "    pattern: str = r\"<think>.*?</think>|`+json|`+\"\n",
    "    cleaned_text: str = re.sub(pattern, \"\", text, flags=re.DOTALL)\n",
    "\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class LLMResponse:\n",
    "    \"\"\"Class for handling LLM API responses.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    api_key : SecretStr\n",
    "        The API key for authentication.\n",
    "    base_url : str\n",
    "        The base URL for the API endpoint.\n",
    "    model : str\n",
    "        The name of the LLM model to use.\n",
    "    \"\"\"\n",
    "\n",
    "    api_key: SecretStr\n",
    "    base_url: str\n",
    "    model: str\n",
    "    use_vllm: bool = False\n",
    "\n",
    "    def _get_client(self) -> AsyncOpenAI:\n",
    "        \"\"\"Get an instance of the OpenAI client.\"\"\"\n",
    "        return AsyncOpenAI(\n",
    "            api_key=self.api_key.get_secret_value(),\n",
    "            base_url=self.base_url,\n",
    "            max_retries=3,\n",
    "            timeout=180,  # type: ignore\n",
    "        )\n",
    "\n",
    "    @validate_call\n",
    "    async def ainvoke(\n",
    "        self, messages: list[dict[str, str]]\n",
    "    ) -> tuple[str, Type[T]] | tuple[None, dict[str, str]]:\n",
    "        \"\"\"Asynchronously invoke the LLM API with the given messages.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        messages : list[dict[str, str]]\n",
    "            List of message dictionaries containing role and content.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple[str, Type[T]] | tuple[None, dict[str, str]]\n",
    "            A tuple containing either:\n",
    "            - (content, raw_response)\n",
    "            - (None, error_info)\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            aclient: AsyncOpenAI = self._get_client()\n",
    "\n",
    "            raw_response = await aclient.chat.completions.create(  # type: ignore\n",
    "                model=self.model,\n",
    "                messages=messages,  # type: ignore\n",
    "                temperature=0,\n",
    "                seed=42,\n",
    "            )\n",
    "\n",
    "            content = _clean_response_text_single_regex(raw_response.choices[0].message.content)  # type: ignore\n",
    "            return (content, raw_response)  # type: ignore\n",
    "\n",
    "        except Exception as e:\n",
    "            return (None, {\"status\": \"error\", \"error\": str(e)})  # type: ignore\n",
    "\n",
    "    @validate_call\n",
    "    async def get_structured_response(\n",
    "        self, message: str, response_model: Type[T]\n",
    "    ) -> tuple[Type[T], Type[T]] | tuple[None, dict[str, str]]:\n",
    "        \"\"\"Get structured response from OpenAI API.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            message : str\n",
    "                The user message to send to the API.\n",
    "            response_model : Type[T]\n",
    "                The Pydantic model class to validate the response.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A tuple containing either:\n",
    "        - (structured_output, raw_response)\n",
    "        - (None, error_info)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            aclient: AsyncOpenAI = self._get_client()\n",
    "            json_schema: dict[str, str] = response_model.model_json_schema()\n",
    "            if not self.use_vllm:\n",
    "                raw_response: Type[T] = await aclient.chat.completions.create(  # type: ignore\n",
    "                    model=self.model,\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": SYSTEM_MESSAGE.format(json_schema=json_schema),\n",
    "                        },\n",
    "                        {\"role\": \"user\", \"content\": message},\n",
    "                    ],\n",
    "                    response_format={\"type\": \"json_schema\", \"schema\": json_schema, \"strict\": True},\n",
    "                    temperature=0,\n",
    "                    seed=42,\n",
    "                )\n",
    "\n",
    "                _value = _clean_response_text_single_regex(raw_response.choices[0].message.content)  # type: ignore\n",
    "                structured_output: Type[T] = response_model.model_validate(json.loads(_value))  # type: ignore\n",
    "                return (structured_output, raw_response)  # type: ignore\n",
    "\n",
    "            raw_response = await aclient.chat.completions.create(  # type: ignore\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_MESSAGE_VLLM},\n",
    "                    {\"role\": \"user\", \"content\": message},\n",
    "                ],\n",
    "                extra_body={\"enable_thinking\": False, \"guided_json\": json_schema},\n",
    "                temperature=0,\n",
    "                seed=42,\n",
    "            )\n",
    "\n",
    "            _value = _clean_response_text_single_regex(raw_response.choices[0].message.content)  # type: ignore\n",
    "            structured_output = response_model.model_validate(json.loads(_value))  # type: ignore\n",
    "            return (structured_output, raw_response)  # type: ignore\n",
    "\n",
    "        except Exception as e:\n",
    "            return (\n",
    "                None,\n",
    "                {\"status\": \"error\", \"error\": str(e)},\n",
    "            )\n",
    "\n",
    "\n",
    "@validate_call\n",
    "def convert_openai_messages_to_string(messages: list[dict[str, Any]]) -> str:\n",
    "    \"\"\"\n",
    "    Convert a list of OpenAI messages to a formatted string representation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    messages : list[dict[str, Any]]\n",
    "        List of OpenAI message dictionaries containing 'role' and 'content' keys.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A formatted string with each message's role and content on separate lines.\n",
    "    \"\"\"\n",
    "    msgs: list[str] = [f\"\\nRole: {msg['role']}\\nContent: {msg['content']}\" for msg in messages]\n",
    "    return \"\\n\".join(msgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8b176a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
