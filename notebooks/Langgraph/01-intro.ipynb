{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e958c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in library\n",
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import Any, Literal, Optional, Union\n",
    "\n",
    "# Standard imports\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "\n",
    "custom_theme = Theme(\n",
    "    {\n",
    "        \"white\": \"#FFFFFF\",  # Bright white\n",
    "        \"info\": \"#00FF00\",  # Bright green\n",
    "        \"warning\": \"#FFD700\",  # Bright gold\n",
    "        \"error\": \"#FF1493\",  # Deep pink\n",
    "        \"success\": \"#00FFFF\",  # Cyan\n",
    "        \"highlight\": \"#FF4500\",  # Orange-red\n",
    "    }\n",
    ")\n",
    "console = Console(theme=custom_theme)\n",
    "\n",
    "# Visualization\n",
    "# import matplotlib.pyplot as pltife\n",
    "\n",
    "# NumPy settings\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "# Polars settings\n",
    "pl.Config.set_fmt_str_lengths(1_000)\n",
    "pl.Config.set_tbl_cols(n=1_000)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_up_from_current_directory(*, go_up: int = 1) -> None:\n",
    "    \"\"\"This is used to up a number of directories.\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    go_up: int, default=1\n",
    "        This indicates the number of times to go back up from the current directory.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import sys\n",
    "\n",
    "    CONST: str = \"../\"\n",
    "    NUM: str = CONST * go_up\n",
    "\n",
    "    # Goto the previous directory\n",
    "    prev_directory = os.path.join(os.path.dirname(__name__), NUM)\n",
    "    # Get the 'absolute path' of the previous directory\n",
    "    abs_path_prev_directory = os.path.abspath(prev_directory)\n",
    "\n",
    "    # Add the path to the System paths\n",
    "    sys.path.insert(0, abs_path_prev_directory)\n",
    "    print(abs_path_prev_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/neidu/Desktop/Projects/Personal/My_Projects/AI-Tutorials\n"
     ]
    }
   ],
   "source": [
    "go_up_from_current_directory(go_up=2)\n",
    "from settings import refresh_settings  # noqa: E402\n",
    "\n",
    "settings = refresh_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7d36425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from instructor import AsyncInstructor\n",
    "\n",
    "from schemas import GeneralResponse, ModelEnum\n",
    "from utilities.client_utils import get_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mode: <Mode.JSON: 'json_mode'>\n",
      "Using Ollama\n",
      "Using mode: <Mode.JSON: 'json_mode'>\n",
      "Using Remote\n"
     ]
    }
   ],
   "source": [
    "local_client: AsyncInstructor = get_client(is_remote=False)\n",
    "remote_client: AsyncInstructor = get_client(is_remote=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:58:10] </span>San Francisco is known for its iconic Golden Gate Bridge, vibrant cultural scene, and   <a href=\"file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_87067/2829152137.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2829152137.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_87067/2829152137.py#22\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">22</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>the famous Alcatraz Island, which was a federal prison and now a tourist attraction.    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:58:10]\u001b[0m\u001b[2;36m \u001b[0mSan Francisco is known for its iconic Golden Gate Bridge, vibrant cultural scene, and   \u001b]8;id=13463;file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_87067/2829152137.py\u001b\\\u001b[2m2829152137.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=550858;file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_87067/2829152137.py#22\u001b\\\u001b[2m22\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0mthe famous Alcatraz Island, which was a federal prison and now a tourist attraction.    \u001b[2m                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"/no_think You're an expert AI assstance that replies to questions. \"\n",
    "        \"Your responses are returned in a string format only. \",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Tell me briefly something unique about SF. \",\n",
    "    },\n",
    "]\n",
    "\n",
    "response: GeneralResponse = await local_client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    response_model=GeneralResponse,\n",
    "    model=ModelEnum.BASE_MODEL_LOCAL_2.value,\n",
    "    max_tokens=700,\n",
    "    max_retries=3,\n",
    "    temperature=0.0,\n",
    "    seed=0,\n",
    ")\n",
    "console.log(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:58:14] </span>San Francisco, known for its steep hills, fog, and diverse culture, is home to iconic    <a href=\"file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_87067/318393952.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">318393952.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_87067/318393952.py#10\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>landmarks like the Golden Gate Bridge and Alcatraz Island. A unique aspect of SF is its  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>vibrant tech industry, particularly in the Silicon Valley area, which has made it a      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>global hub for innovation and entrepreneurship.                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:58:14]\u001b[0m\u001b[2;36m \u001b[0mSan Francisco, known for its steep hills, fog, and diverse culture, is home to iconic    \u001b]8;id=254253;file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_87067/318393952.py\u001b\\\u001b[2m318393952.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=917698;file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_87067/318393952.py#10\u001b\\\u001b[2m10\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0mlandmarks like the Golden Gate Bridge and Alcatraz Island. A unique aspect of SF is its  \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0mvibrant tech industry, particularly in the Silicon Valley area, which has made it a      \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0mglobal hub for innovation and entrepreneurship.                                          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response: GeneralResponse = await remote_client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    response_model=GeneralResponse,\n",
    "    model=ModelEnum.BASE_REMOTE_MODEL_1_7B.value,\n",
    "    max_tokens=700,\n",
    "    max_retries=3,\n",
    "    temperature=0.0,\n",
    "    seed=0,\n",
    ")\n",
    "console.log(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f2255d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def llm_response(\n",
    "    message: str, client: AsyncInstructor, model: str, max_tokens: int = 1_000\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate an AI response using the provided message and model parameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    message : str\n",
    "        The input message to send to the AI model.\n",
    "    client : AsyncInstructor\n",
    "        The async client instance for making API calls.\n",
    "    model : str\n",
    "        The name or identifier of the AI model to use.\n",
    "    max_tokens : int, optional\n",
    "        Maximum number of tokens in the response, by default 1,000.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The generated AI response content.\n",
    "    \"\"\"\n",
    "    response: GeneralResponse = await client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"<prompt>/no_think You're an expert AI assstance that \"\n",
    "                \"replies to questions. Your responses are returned in a string format only. \"\n",
    "                \"e.g. '</your_answer_here>' </prompt>\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"<user>{message}</user>\",\n",
    "            },\n",
    "        ],\n",
    "        response_model=GeneralResponse,\n",
    "        model=model,\n",
    "        max_tokens=max_tokens,\n",
    "        max_retries=3,\n",
    "        temperature=0.0,\n",
    "        seed=0,\n",
    "    )\n",
    "\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2771205c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why don't Lannisters ever get cold? Because they always wear multiple layers of 'I'm not a threat'!\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await llm_response(\n",
    "    message=\"Tell me a joke about Cercei Lannister.\",\n",
    "    client=local_client,\n",
    "    model=ModelEnum.BASE_MODEL_LOCAL_2.value,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24db9fcb",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c595484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49792cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "605cc193",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    # This appends messages instead of overwriting\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder: StateGraph = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0aef63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11a161a90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "def get_client_and_model() -> (\n",
    "    tuple[Annotated[AsyncInstructor, \"client\"], Annotated[str, \"model\"]]\n",
    "):\n",
    "    \"\"\"Get the local client and model configuration.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[AsyncInstructor, str]\n",
    "        A tuple containing:\n",
    "        - client: The AsyncInstructor instance for local model interaction\n",
    "        - model: The string identifier for the base local model\n",
    "    \"\"\"\n",
    "    return local_client, ModelEnum.BASE_MODEL_LOCAL_2.value\n",
    "\n",
    "\n",
    "# Add chatbot\n",
    "async def chatbot(state: State) -> dict[str, Any]:\n",
    "    \"\"\"Process chat messages using an LLM model and return the response.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    state : State\n",
    "        The current state containing chat messages.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, Any]\n",
    "        A dictionary containing the LLM response with key 'messages'.\n",
    "    \"\"\"\n",
    "    client, model = get_client_and_model()\n",
    "    response: str = await llm_response(state[\"messages\"], client=client, model=model)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# (unique_name, function) when the node is called\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add entrypoint\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# Compile graph\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cc5576",
   "metadata": {},
   "source": [
    "## Visualize Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# uv add pygraphviz or pip install pygraphviz\n",
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fbbdad",
   "metadata": {},
   "source": [
    "### Run The Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16ccb2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "async def stream_graph_updates(user_input: str) -> None:\n",
    "    \"\"\"Process user input through a graph and stream assistant responses.\n",
    "\n",
    "    This function takes a user input string and streams it through an async graph,\n",
    "    printing the assistant's messages as they are generated.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    user_input : str\n",
    "        The input text from the user to process\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        This function prints output but does not return any value\n",
    "    \"\"\"\n",
    "    async for event in graph.astream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]}\n",
    "    ):\n",
    "        print(f\"Assistant: {event['chatbot']['messages']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f24e2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Why did Cercei Lannister bring a ladder to the wedding? Because she wanted to reach the top of the heap (a play on 'heap' meaning a pile of money or resources, and 'top of the heap' meaning the highest position or power).\n"
     ]
    }
   ],
   "source": [
    "# Test user input\n",
    "await stream_graph_updates(user_input=\"Tell me a joke about Cercei Lannister.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e32634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        user_input: str = input(\"User: \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        await stream_graph_updates(user_input)\n",
    "\n",
    "    except Exception:\n",
    "        # Fallback\n",
    "        user_input = \"Tell me a joke about Cercei Lannister.\"\n",
    "        print(f\"User: {user_input}\")\n",
    "        await stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e324e7e2",
   "metadata": {},
   "source": [
    "## Tool Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from tavily import TavilyClient\n",
    "\n",
    "\n",
    "@tool(\"tavily_search\")\n",
    "def tavily_search(query: str) -> dict:\n",
    "    \"\"\"\n",
    "    Search for information using the Tavily API.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    query : str\n",
    "        The search query string.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        The search results from Tavily.\n",
    "    \"\"\"\n",
    "    tavily_client = TavilyClient(api_key=settings.TAVILY_API_KEY.get_secret_value())\n",
    "    return tavily_client.search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f5252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = tavily_search(\"Who is Leo Messi?\")\n",
    "console.log(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deba7b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response[\"results\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82498b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_client: AsyncInstructor = get_client(is_remote=False, mode=\"tool_mode\")\n",
    "remote_client: AsyncInstructor = get_client(is_remote=True, mode=\"tool_mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6962d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "await llm_response(\n",
    "    \"Who is Lionel Messi?\",\n",
    "    client=local_client,\n",
    "    model=ModelEnum.BASE_MODEL_LOCAL_2.value,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "316cb462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "\n",
    "def get_weather(latitude, longitude):\n",
    "    response = requests.get(\n",
    "        f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}\"\n",
    "        f\"&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\"\n",
    "    )\n",
    "    data = response.json()\n",
    "    return data[\"current\"][\"temperature_2m\"]\n",
    "\n",
    "\n",
    "remote_client: AsyncOpenAI = AsyncOpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=settings.OPENROUTER_API_KEY.get_secret_value(),\n",
    ")\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get current temperature for provided coordinates in celsius.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"latitude\": {\"type\": \"number\"},\n",
    "                    \"longitude\": {\"type\": \"number\"},\n",
    "                },\n",
    "                \"required\": [\"latitude\", \"longitude\"],\n",
    "                \"additionalProperties\": False,\n",
    "            },\n",
    "            \"strict\": True,\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"You're a worldclass AI assistant that answers users \"\n",
    "        \"questions. You use the available tools to answer the questions. \"\n",
    "        \"You only respond in a string format. e.g. '</your_answer_here>'\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"What is the weather like in Paris today?\"},\n",
    "]\n",
    "response = await remote_client.chat.completions.create(\n",
    "    model=ModelEnum.GPT_4_o_MINI_REMOTE.value,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    temperature=0.0,\n",
    "    seed=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a2b437c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[23:15:39] </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>                                                                   <a href=\"file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_87067/4258338503.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4258338503.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_87067/4258338503.py#1\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,                                                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,                                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">annotations</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">audio</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                                                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[</span>                                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessageToolCall</span><span style=\"font-weight: bold\">(</span>                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'call_ZQaBINkMdPUN3aFMCB0grFNW'</span>,                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>            <span style=\"color: #808000; text-decoration-color: #808000\">function</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Function</span><span style=\"font-weight: bold\">(</span>                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                <span style=\"color: #808000; text-decoration-color: #808000\">arguments</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{\"latitude\":48.8566,\"longitude\":2.3522}'</span>,                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'get_weather'</span>                                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>            <span style=\"font-weight: bold\">)</span>,                                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>            <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'function'</span>,                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>        <span style=\"font-weight: bold\">)</span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"font-weight: bold\">]</span>,                                                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">reasoning</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>                                                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">)</span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[23:15:39]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m                                                                   \u001b]8;id=939461;file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_87067/4258338503.py\u001b\\\u001b[2m4258338503.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=589963;file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_87067/4258338503.py#1\u001b\\\u001b[2m1\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33mcontent\u001b[0m=\u001b[32m''\u001b[0m,                                                                          \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                                        \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,                                                                    \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33mannotations\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                                    \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33maudio\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                                          \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                                  \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m                                                                         \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m        \u001b[1;35mChatCompletionMessageToolCall\u001b[0m\u001b[1m(\u001b[0m                                                   \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m            \u001b[33mid\u001b[0m=\u001b[32m'call_ZQaBINkMdPUN3aFMCB0grFNW'\u001b[0m,                                          \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m            \u001b[33mfunction\u001b[0m=\u001b[1;35mFunction\u001b[0m\u001b[1m(\u001b[0m                                                           \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                \u001b[33marguments\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"latitude\":48.8566,\"longitude\":2.3522\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,                     \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                \u001b[33mname\u001b[0m=\u001b[32m'get_weather'\u001b[0m                                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m            \u001b[1m)\u001b[0m,                                                                           \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m            \u001b[33mtype\u001b[0m=\u001b[32m'function'\u001b[0m,                                                             \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m                                                                      \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m        \u001b[1m)\u001b[0m                                                                                \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[1m]\u001b[0m,                                                                                   \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33mreasoning\u001b[0m=\u001b[3;35mNone\u001b[0m                                                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[1m)\u001b[0m                                                                                        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.log(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed55a8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[23:15:47] </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15.6</span>                                                                                     <a href=\"file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_87067/3472273555.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3472273555.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_87067/3472273555.py#6\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[23:15:47]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;36m15.6\u001b[0m                                                                                     \u001b]8;id=986878;file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_87067/3472273555.py\u001b\\\u001b[2m3472273555.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=600559;file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_87067/3472273555.py#6\u001b\\\u001b[2m6\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[23:15:48] </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletion</span><span style=\"font-weight: bold\">(</span>                                                                         <a href=\"file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_87067/3472273555.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3472273555.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_87067/3472273555.py#24\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">24</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gen-1747174548-uMlFO68I2blW50OiCooy'</span>,                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>                                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>                                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,                                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,                                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>            <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>            <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"'The current temperature in Paris today is 15.6C.'\"</span>,          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                <span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,                                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                <span style=\"color: #808000; text-decoration-color: #808000\">annotations</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                <span style=\"color: #808000; text-decoration-color: #808000\">audio</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                <span style=\"color: #808000; text-decoration-color: #808000\">reasoning</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>                                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>            <span style=\"font-weight: bold\">)</span>,                                                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>            <span style=\"color: #808000; text-decoration-color: #808000\">native_finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>        <span style=\"font-weight: bold\">)</span>                                                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"font-weight: bold\">]</span>,                                                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1747174548</span>,                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'openai/gpt-4o-mini'</span>,                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_dbaca60df0'</span>,                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>                                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>,                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">136</span>,                                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>        <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">152</span>,                                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionTokensDetails</span><span style=\"font-weight: bold\">(</span>                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>            <span style=\"color: #808000; text-decoration-color: #808000\">accepted_prediction_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>            <span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>            <span style=\"color: #808000; text-decoration-color: #808000\">reasoning_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>            <span style=\"color: #808000; text-decoration-color: #808000\">rejected_prediction_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>        <span style=\"font-weight: bold\">)</span>,                                                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTokensDetails</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">cached_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"font-weight: bold\">)</span>,                                                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>    <span style=\"color: #808000; text-decoration-color: #808000\">provider</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'OpenAI'</span>                                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">)</span>                                                                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[23:15:48]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m                                                                         \u001b]8;id=812609;file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_87067/3472273555.py\u001b\\\u001b[2m3472273555.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=413808;file:///var/folders/ny/dl75sc_x2tb54lsymt5bh5p00000gn/T/ipykernel_87067/3472273555.py#24\u001b\\\u001b[2m24\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33mid\u001b[0m=\u001b[32m'gen-1747174548-uMlFO68I2blW50OiCooy'\u001b[0m,                                           \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m                                                                           \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m        \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m                                                                         \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m            \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,                                                       \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,                                                                    \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m            \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                              \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m            \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m                                              \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                \u001b[33mcontent\u001b[0m=\u001b[32m\"'The current temperature in Paris today is 15.6C.'\"\u001b[0m,          \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                \u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                           \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,                                                       \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                \u001b[33mannotations\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                       \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                \u001b[33maudio\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                             \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                     \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                        \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                \u001b[33mreasoning\u001b[0m=\u001b[3;35mNone\u001b[0m                                                          \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m            \u001b[1m)\u001b[0m,                                                                          \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m            \u001b[33mnative_finish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m                                                 \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m        \u001b[1m)\u001b[0m                                                                               \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[1m]\u001b[0m,                                                                                  \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33mcreated\u001b[0m=\u001b[1;36m1747174548\u001b[0m,                                                                 \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33mmodel\u001b[0m=\u001b[32m'openai/gpt-4o-mini'\u001b[0m,                                                         \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,                                                           \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33mservice_tier\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                                  \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_dbaca60df0'\u001b[0m,                                                 \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33musage\u001b[0m=\u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m                                                              \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m        \u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m16\u001b[0m,                                                           \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m        \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m136\u001b[0m,                                                              \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m        \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m152\u001b[0m,                                                               \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m        \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[1;35mCompletionTokensDetails\u001b[0m\u001b[1m(\u001b[0m                              \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m            \u001b[33maccepted_prediction_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,                                            \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m            \u001b[33maudio_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                          \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m            \u001b[33mreasoning_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,                                                         \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m            \u001b[33mrejected_prediction_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m                                             \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m        \u001b[1m)\u001b[0m,                                                                              \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m        \u001b[33mprompt_tokens_details\u001b[0m=\u001b[1;35mPromptTokensDetails\u001b[0m\u001b[1m(\u001b[0m\u001b[33maudio_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mcached_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m   \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[1m)\u001b[0m,                                                                                  \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m    \u001b[33mprovider\u001b[0m=\u001b[32m'OpenAI'\u001b[0m                                                                   \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[1m)\u001b[0m                                                                                       \u001b[2m                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2\n",
    "tool_call = response.choices[0].message.tool_calls[0]\n",
    "args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "result = get_weather(args[\"latitude\"], args[\"longitude\"])\n",
    "console.log(result)\n",
    "\n",
    "# Step 3\n",
    "messages.append(response.choices[0].message)  # append model's function call message\n",
    "messages.append(\n",
    "    {  # append result message\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_call_id\": tool_call.id,\n",
    "        \"content\": str(result),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Step 4\n",
    "response_2 = await remote_client.chat.completions.create(\n",
    "    model=ModelEnum.GPT_4_o_MINI_REMOTE.value,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    ")\n",
    "console.log(response_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389fa4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "console.log(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4e9963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2216a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import ChatResponse, chat\n",
    "\n",
    "\n",
    "def add_two_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Add two numbers\n",
    "\n",
    "    Args:\n",
    "      a (int): The first number\n",
    "      b (int): The second number\n",
    "\n",
    "    Returns:\n",
    "      int: The sum of the two numbers\n",
    "    \"\"\"\n",
    "\n",
    "    # The cast is necessary as returned tool call arguments don't always conform exactly to schema\n",
    "    # E.g. this would prevent \"what is 30 + 12\" to produce '3012' instead of 42\n",
    "    return int(a) + int(b)\n",
    "\n",
    "\n",
    "def subtract_two_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Subtract two numbers\n",
    "    \"\"\"\n",
    "\n",
    "    # The cast is necessary as returned tool call arguments don't always conform exactly to schema\n",
    "    return int(a) - int(b)\n",
    "\n",
    "\n",
    "# Tools can still be manually defined and passed into chat\n",
    "subtract_two_numbers_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"subtract_two_numbers\",\n",
    "        \"description\": \"Subtract two numbers\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"required\": [\"a\", \"b\"],\n",
    "            \"properties\": {\n",
    "                \"a\": {\"type\": \"integer\", \"description\": \"The first number\"},\n",
    "                \"b\": {\"type\": \"integer\", \"description\": \"The second number\"},\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"<user>What is three plus one?</user>\"}]\n",
    "print(\"Prompt:\", messages[0][\"content\"])\n",
    "\n",
    "available_functions = {\n",
    "    \"add_two_numbers\": add_two_numbers,\n",
    "    \"subtract_two_numbers\": subtract_two_numbers,\n",
    "}\n",
    "\n",
    "response: ChatResponse = chat(\n",
    "    ModelEnum.BASE_MODEL_LOCAL_2.value,\n",
    "    messages=messages,\n",
    "    tools=[add_two_numbers, subtract_two_numbers_tool],\n",
    ")\n",
    "\n",
    "if response.message.tool_calls:\n",
    "    # There may be multiple tool calls in the response\n",
    "    for tool in response.message.tool_calls:\n",
    "        # Ensure the function is available, and then call it\n",
    "        if function_to_call := available_functions.get(tool.function.name):\n",
    "            print(\"Calling function:\", tool.function.name)\n",
    "            print(\"Arguments:\", tool.function.arguments)\n",
    "            output = function_to_call(**tool.function.arguments)\n",
    "            print(\"Function output:\", output)\n",
    "        else:\n",
    "            print(\"Function\", tool.function.name, \"not found\")\n",
    "\n",
    "# Only needed to chat with the model using the tool call results\n",
    "if response.message.tool_calls:\n",
    "    # Add the function response to messages for the model to use\n",
    "    messages.append(response.message)\n",
    "    messages.append({\"role\": \"tool\", \"content\": str(output), \"name\": tool.function.name})\n",
    "\n",
    "    # Get final response from model with function outputs\n",
    "    final_response = chat(ModelEnum.BASE_MODEL_LOCAL_2.value, messages=messages)\n",
    "    print(\"Final response:\", final_response.message.content)\n",
    "\n",
    "else:\n",
    "    print(\"No tool calls returned from model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26652c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await remote_client.chat.completions.create(\n",
    "    response_model=GeneralResponse,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is seven plus twelve?\"}],\n",
    "    model=ModelEnum.BASE_REMOTE_MODEL_2_8B.value,\n",
    "    tools=[add_two_numbers, subtract_two_numbers],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7ff2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33304997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c13bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e455a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
