{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc0ce639",
   "metadata": {},
   "source": [
    "# Research Assistant Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b2aa0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in library\n",
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import (\n",
    "    Annotated,\n",
    "    Any,\n",
    "    Generator,\n",
    "    Iterable,\n",
    "    Literal,\n",
    "    Optional,\n",
    "    TypedDict,\n",
    "    Union,\n",
    ")\n",
    "\n",
    "# Standard imports\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "\n",
    "custom_theme = Theme(\n",
    "    {\n",
    "        \"white\": \"#FFFFFF\",  # Bright white\n",
    "        \"info\": \"#00FF00\",  # Bright green\n",
    "        \"warning\": \"#FFD700\",  # Bright gold\n",
    "        \"error\": \"#FF1493\",  # Deep pink\n",
    "        \"success\": \"#00FFFF\",  # Cyan\n",
    "        \"highlight\": \"#FF4500\",  # Orange-red\n",
    "    }\n",
    ")\n",
    "console = Console(theme=custom_theme)\n",
    "\n",
    "# Visualization\n",
    "# import matplotlib.pyplot as pltife\n",
    "\n",
    "# NumPy settings\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "# Polars settings\n",
    "pl.Config.set_fmt_str_lengths(1_000)\n",
    "pl.Config.set_tbl_cols(n=1_000)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_up_from_current_directory(*, go_up: int = 1) -> None:\n",
    "    \"\"\"This is used to up a number of directories.\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    go_up: int, default=1\n",
    "        This indicates the number of times to go back up from the current directory.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import sys\n",
    "\n",
    "    CONST: str = \"../\"\n",
    "    NUM: str = CONST * go_up\n",
    "\n",
    "    # Goto the previous directory\n",
    "    prev_directory = os.path.join(os.path.dirname(__name__), NUM)\n",
    "    # Get the 'absolute path' of the previous directory\n",
    "    abs_path_prev_directory = os.path.abspath(prev_directory)\n",
    "\n",
    "    # Add the path to the System paths\n",
    "    sys.path.insert(0, abs_path_prev_directory)\n",
    "    print(abs_path_prev_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d4f1fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/neidu/Desktop/Projects/Personal/My_Projects/AI-Tutorials\n"
     ]
    }
   ],
   "source": [
    "go_up_from_current_directory(go_up=2)\n",
    "\n",
    "\n",
    "from schemas import ModelEnum  # noqa: E402\n",
    "from settings import refresh_settings  # noqa: E402\n",
    "from utilities.client_utils import check_rate_limit  # noqa: E402\n",
    "\n",
    "settings = refresh_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82f1daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, Markdown, display\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "from langchain_litellm import ChatLiteLLM\n",
    "from langchain_tavily import TavilySearch\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, MessagesState, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.types import Command, interrupt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637ea699",
   "metadata": {},
   "source": [
    "### Goal\n",
    "\n",
    "- Build a lightweight, multi-agent system using chat models to customize the research process.\n",
    "\n",
    "### Key Themes\n",
    "\n",
    "- Integrates LangGraph themes like memory, human-in-the-loop, and controllability.\n",
    "\n",
    "### Source Selection\n",
    "\n",
    "- Allows users to choose input sources for their research.\n",
    "\n",
    "### Planning\n",
    "\n",
    "- Users provide a topic.\n",
    "- The system generates a team of AI analysts, each focusing on a sub-topic.\n",
    "- Human-in-the-loop will be used to refine sub-topics before research starts.\n",
    "\n",
    "### LLM Utilization (Research Process)\n",
    "\n",
    "- Each analyst conducts in-depth, multi-turn interviews with an expert AI based on selected sources, similar to the STORM paper.\n",
    "- Interviews are captured in sub-graphs with internal state.\n",
    "- Experts gather information in parallel and interviews are conducted simultaneously via map-reduce.\n",
    "\n",
    "### Output Format\n",
    "\n",
    "- Gathered insights from each interview are synthesized into a final report.\n",
    "- Customizable prompts allow for flexible report output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9c6b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "\n",
    "model_str: str = \"mistralai:open-mixtral-8x22b\"\n",
    "llm: BaseChatModel = init_chat_model(model=model_str, temperature=0.0)\n",
    "\n",
    "\n",
    "llm = init_chat_model(\n",
    "    model_provider=\"openai\",\n",
    "    openai_api_key=settings.OPENROUTER_API_KEY.get_secret_value(),\n",
    "    base_url=settings.OPENROUTER_URL,\n",
    "    model=\"openai/gpt-4o-mini\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffe4a5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bola Ahmed Tinubu is a Nigerian politician and the President of Nigeria, having taken office on May 29, 2023. He is a member of the All Progressives Congress (APC) and was formerly the Governor of Lagos State from 1999 to 2007. Tinubu is a key figure in Nigerian politics and is often referred to as a political godfather in Lagos and beyond, having played instrumental roles in the formation and success of various political parties in the country. His tenure as governor is noted for various reforms in Lagos State, particularly in public transport and infrastructure development. Tinubu's political influence continues to be significant in Nigeria’s political landscape.\n"
     ]
    }
   ],
   "source": [
    "question = \"Who be Tinubu?\"\n",
    "\n",
    "print(llm.invoke(question).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa09db5",
   "metadata": {},
   "source": [
    "## Create Analysts: Human-in-the-loop\n",
    "\n",
    "- Create analysts and review them using human-in-the-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c1250a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Analyst(BaseModel):\n",
    "    affiliation: str = Field(description=\"The primary affiliation of the analyst.\")\n",
    "    role: str = Field(description=\"The role of the analyst.\")\n",
    "    name: str = Field(description=\"The name of the analyst.\")\n",
    "    description: str = Field(\n",
    "        description=\"The description of the analyst's focus, concerns and motives.\"\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def persona(self) -> str:\n",
    "        return (\n",
    "            f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\"\n",
    "            f\"\\nDescription: {self.description}\"\n",
    "        )\n",
    "\n",
    "\n",
    "class Perpectives(BaseModel):\n",
    "    analysts: list[Analyst] = Field(\n",
    "        description=\"A list of analysts with their detailed information.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class GenerateAnalystState(TypedDict):\n",
    "    topic: str  # Research topic\n",
    "    max_analyst: int  # Maximum number of analysts\n",
    "    human_analyst_feedback: str  # Human feedback\n",
    "    analysts: list[Analyst]  # Analyst asking questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27d191ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst_instructions: str = \"\"\"\n",
    "<instruction>\n",
    "You're tasked with creating a set of AI analyst personas. Follow these instructions carefully:\n",
    "1. First, review the reseacrch topic: \\n{topic}\n",
    "2. Examine any editorial feedback that has been optionally provided to guide the creation of the analysts:\n",
    "{human_analyst_feedback}\n",
    "3. Determine the most interesting themes based upon documents and/or feedback above.\n",
    "4. Pick the top {max_analyst} themes.\n",
    "5. Assign one analyst to each theme.\n",
    "</instruction>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "async def create_analysts(state: GenerateAnalystState) -> dict[str, Any]:\n",
    "    topic: str = state[\"topic\"]\n",
    "    max_analyst: int = state[\"max_analyst\"]\n",
    "    human_analyst_feedback: str = state.get(\"human_analyst_feedback\", \"\")\n",
    "\n",
    "    structured_llm = llm.with_structured_output(Perpectives)\n",
    "    system_message = analyst_instructions.format(\n",
    "        topic=topic,\n",
    "        human_analyst_feedback=human_analyst_feedback,\n",
    "        max_analyst=max_analyst,\n",
    "    )\n",
    "    analysts = await structured_llm.ainvoke(\n",
    "        [SystemMessage(content=system_message)]\n",
    "        + [HumanMessage(content=\"Generate the set of analysts.\")]\n",
    "    )\n",
    "\n",
    "    return {\"analysts\": analysts.analysts}\n",
    "\n",
    "\n",
    "def human_feedback(state: GenerateAnalystState) -> None:\n",
    "    pass\n",
    "\n",
    "\n",
    "def should_continue(state: GenerateAnalystState) -> Literal[\"create_analysts\", END]:\n",
    "    human_analyst_feedback = state.get(\"human_analyst_feedback\", None)\n",
    "    if human_analyst_feedback:\n",
    "        return \"create_analysts\"\n",
    "\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7ae95d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph.state import CompiledStateGraph\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(GenerateAnalystState)\n",
    "\n",
    "# Add nodes\n",
    "graph_builder.add_node(\"create_analysts\", create_analysts)\n",
    "graph_builder.add_node(\"human_feedback\", human_feedback)\n",
    "\n",
    "# Add edges\n",
    "graph_builder.add_edge(START, \"create_analysts\")\n",
    "graph_builder.add_edge(\"create_analysts\", \"human_feedback\")\n",
    "# Add conditions\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"human_feedback\", should_continue, [\"create_analysts\", END]\n",
    ")\n",
    "\n",
    "# Compile the graph\n",
    "memory = MemorySaver()\n",
    "langfuse_handler = CallbackHandler()\n",
    "graph: CompiledStateGraph = graph_builder.compile(\n",
    "    interrupt_before=[\"human_feedback\"], checkpointer=memory\n",
    ").with_config({\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "# Visualize the graph\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273e25bd",
   "metadata": {},
   "source": [
    "#### Test The Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85775822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Dr. Emily Carter\n",
      "Role: Cultural Analyst\n",
      "Affiliation: Harvard Divinity School\n",
      "Description: Dr. Emily Carter focuses on the cultural impacts of Christianity, exploring how Christian values influence social behavior and community cohesion. Her research emphasizes the positive societal transformations brought about by Christian teachings.\n",
      "--------------------------------------------------\n",
      "Name: Professor Johnathan Blake\n",
      "Role: Theological Researcher\n",
      "Affiliation: Oxford University Press\n",
      "Description: Professor Johnathan Blake specializes in theological studies, analyzing the spiritual benefits of Christianity. He examines how Christian beliefs shape individual purpose, morality, and psychological well-being, advocating for the role of faith in leading a fulfilling life.\n",
      "--------------------------------------------------\n",
      "Name: Dr. Sarah Gonzalez\n",
      "Role: Sociological Analyst\n",
      "Affiliation: Pew Research Center\n",
      "Description: Dr. Sarah Gonzalez conducts sociological studies to understand the demographic benefits of Christianity, focusing on community support networks, charitable activities, and the role of faith in public health and social services.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Inputs\n",
    "max_analyst: int = 3\n",
    "topic: str = \"The benefits of Christianity\"\n",
    "thread: dict[str, Any] = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Run the graph\n",
    "async for event in graph.astream(\n",
    "    {\"topic\": topic, \"max_analyst\": max_analyst}, thread, stream_mode=\"values\"\n",
    "):\n",
    "    analysts = event.get(\"analysts\", \"\")\n",
    "\n",
    "    if analysts:\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Affiliation: {analyst.affiliation}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08fbdb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('human_feedback',)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the state and look at the next node\n",
    "state = graph.get_state(thread)\n",
    "state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c11e080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f04324e-9e73-639c-8002-6be0d4289ac4'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The next step is t update the state as if we're the human_feedback node\n",
    "graph.update_state(\n",
    "    thread,\n",
    "    {\n",
    "        \"human_analyst_feedback\": \"Add a priest to add some apostolic and traditional perspective\"\n",
    "    },\n",
    "    as_node=\"human_feedback\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4442c69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Dr. Emily Carter\n",
      "Role: Cultural Analyst\n",
      "Affiliation: Harvard Divinity School\n",
      "Description: Dr. Emily Carter focuses on the cultural impacts of Christianity, exploring how Christian values influence social behavior and community cohesion. Her research emphasizes the positive societal transformations brought about by Christian teachings.\n",
      "--------------------------------------------------\n",
      "Name: Professor Johnathan Blake\n",
      "Role: Theological Researcher\n",
      "Affiliation: Oxford University Press\n",
      "Description: Professor Johnathan Blake specializes in theological studies, analyzing the spiritual benefits of Christianity. He examines how Christian beliefs shape individual purpose, morality, and psychological well-being, advocating for the role of faith in leading a fulfilling life.\n",
      "--------------------------------------------------\n",
      "Name: Dr. Sarah Gonzalez\n",
      "Role: Sociological Analyst\n",
      "Affiliation: Pew Research Center\n",
      "Description: Dr. Sarah Gonzalez conducts sociological studies to understand the demographic benefits of Christianity, focusing on community support networks, charitable activities, and the role of faith in public health and social services.\n",
      "--------------------------------------------------\n",
      "Name: Father Thomas\n",
      "Role: Priest\n",
      "Affiliation: St. Michael's Church\n",
      "Description: Father Thomas provides a traditional perspective on the benefits of Christianity, focusing on spiritual growth, community support, and moral guidance rooted in apostolic teachings.\n",
      "--------------------------------------------------\n",
      "Name: Dr. Sarah Johnson\n",
      "Role: Social Science Analyst\n",
      "Affiliation: Faith and Values Research Institute\n",
      "Description: Dr. Sarah Johnson specializes in the social benefits of Christianity, examining its impact on community cohesion, social justice, and humanitarian efforts within diverse populations.\n",
      "--------------------------------------------------\n",
      "Name: Professor Michael Chen\n",
      "Role: Theologian\n",
      "Affiliation: Theological Educational Institute\n",
      "Description: Professor Michael Chen focuses on the theological benefits of Christianity, exploring how Christian doctrine contributes to personal purpose, ethical decision-making, and philosophical inquiry into the meaning of life.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Continue the graph execution\n",
    "input_: dict[str, Any] | None = None  # Continue the graph execution\n",
    "\n",
    "# Run the graph\n",
    "async for event in graph.astream(input_, thread, stream_mode=\"values\"):\n",
    "    analysts = event.get(\"analysts\", \"\")\n",
    "\n",
    "    if analysts:\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Affiliation: {analyst.affiliation}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c11ec7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f04324e-c99c-6aaa-8004-57394718a812'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we're satisfied, then we simply supply no feedback\n",
    "further_feedback: str | None = None\n",
    "graph.update_state(\n",
    "    thread, {\"human_analyst_feedback\": further_feedback}, as_node=\"human_feedback\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9fb2264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue the graph execution to the end\n",
    "input_: dict[str, Any] | None = None  # Continue the graph execution\n",
    "thread: dict[str, Any] = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Run the graph\n",
    "async for event in graph.astream(\n",
    "    input_,\n",
    "    thread,\n",
    "    stream_mode=\"updates\",  # NEW - Use \"updates\" instead of \"values\"\n",
    "):\n",
    "    print(\"--Node--\")\n",
    "    print(f\"Role: {analyst.role}\")\n",
    "    node_name: str = next(iter(event.keys()))\n",
    "    print(node_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eff28275",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state = graph.get_state(thread)\n",
    "analysts = final_state.values.get(\"analysts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca645eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Father Thomas\n",
      "Role: Priest\n",
      "Affiliation: St. Michael's Church\n",
      "Description: Father Thomas provides a traditional perspective on the benefits of Christianity, focusing on spiritual growth, community support, and moral guidance rooted in apostolic teachings.\n",
      "--------------------------------------------------\n",
      "Name: Dr. Sarah Johnson\n",
      "Role: Social Science Analyst\n",
      "Affiliation: Faith and Values Research Institute\n",
      "Description: Dr. Sarah Johnson specializes in the social benefits of Christianity, examining its impact on community cohesion, social justice, and humanitarian efforts within diverse populations.\n",
      "--------------------------------------------------\n",
      "Name: Professor Michael Chen\n",
      "Role: Theologian\n",
      "Affiliation: Theological Educational Institute\n",
      "Description: Professor Michael Chen focuses on the theological benefits of Christianity, exploring how Christian doctrine contributes to personal purpose, ethical decision-making, and philosophical inquiry into the meaning of life.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the graph\n",
    "for analyst in analysts:\n",
    "    print(f\"Name: {analyst.name}\")\n",
    "    print(f\"Role: {analyst.role}\")\n",
    "    print(f\"Affiliation: {analyst.affiliation}\")\n",
    "    print(f\"Description: {analyst.description}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233f47d6",
   "metadata": {},
   "source": [
    "## Conduct Interview\n",
    "\n",
    "- The analyst will ask questions to the experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d74eeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<instruction>\n",
      "You're an analyst tasked with interviewing an expert to learn about a specific topic. Your\n",
      "goal is boil down to interesting and specific insights related to your topic.\n",
      "\n",
      "1. Interesting: Insights that people will find surprising and non-obvious.\n",
      "2. Specific: Insights that avoid generalities and include specific examples from the expert.\n",
      "\n",
      "<goals>\n",
      "Here is your topic of focus and set of goals: {goals}\n",
      "</goals>\n",
      "\n",
      "Begin by introducing yourself using a name that fits your persona, and then ask your question.\n",
      "Continue to ask questions to drill down and refine your understanding of the topic. When you\n",
      "are satisfied with your understanding, complete the interview by responding: \n",
      "<response>\"Thank you so much for your help!\"</response>\n",
      "\n",
      "Remember to stay in character throughout your response, reflecting the persona and goals provided to you\n",
      "</instruction>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class InterviewState(MessagesState):\n",
    "    max_num_turns: int  # The maximum number of turns of conversation\n",
    "    context: Annotated[list[Any], add_messages]  # The context of the conversation\n",
    "    analyst: Analyst  # Analyst asking the question\n",
    "    interview: str  # Interview transcript\n",
    "    sections: list[Any]  # Final key used with the Send() method\n",
    "\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    search_query: str | None = Field(\n",
    "        default=None, description=\"Search query for retieval\"\n",
    "    )\n",
    "\n",
    "\n",
    "question_instructions: str = \"\"\"\n",
    "<instruction>\n",
    "You're an analyst tasked with interviewing an expert to learn about a specific topic. Your\n",
    "goal is boil down to interesting and specific insights related to your topic.\n",
    "\n",
    "1. Interesting: Insights that people will find surprising and non-obvious.\n",
    "2. Specific: Insights that avoid generalities and include specific examples from the expert.\n",
    "\n",
    "<goals>\n",
    "Here is your topic of focus and set of goals: {goals}\n",
    "</goals>\n",
    "\n",
    "Begin by introducing yourself using a name that fits your persona, and then ask your question.\n",
    "Continue to ask questions to drill down and refine your understanding of the topic. When you\n",
    "are satisfied with your understanding, complete the interview by responding: \n",
    "<response>\"Thank you so much for your help!\"</response>\n",
    "\n",
    "Remember to stay in character throughout your response, reflecting the persona and goals provided to you\n",
    "</instruction>\n",
    "\"\"\"\n",
    "\n",
    "print(question_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe08478",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Generate Questions And Answers In Parallel\n",
    "\n",
    "- The expert will gather info from multiple sources in parallel to answer questions.\n",
    "- For example, we can use:\n",
    "  - Specific websites\n",
    "  - Indexed documents via RAG\n",
    "  - Web search\n",
    "  - Wikipedia search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30630ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "# Web search tool\n",
    "tavily_search = TavilySearch(max_results=3)\n",
    "\n",
    "\n",
    "search_instructions: str = \"\"\"\n",
    "<instruction>\n",
    "You will be given a conversation between an analyst and an expert.\n",
    "\n",
    "<goal>\n",
    "Your goal is to generate a well-structured query for use in retrieval and / or web-search \n",
    "related to the conversation.\n",
    "</goal>\n",
    "\n",
    "First, analyze the full conversation. Pay particular attention to the final question posed \n",
    "by the analyst.\n",
    "Convert this final question into a well-structured web search query.\n",
    "</instruction>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "answer_instructions: str = \"\"\"\n",
    "<instruction>\n",
    "You are an expert being interviewed by an analyst.\n",
    "\n",
    "Here is analyst area of focus: {goals}.         \n",
    "You goal is to answer a question posed by the interviewer.\n",
    "\n",
    "To answer question, use this context:        \n",
    "{context}\n",
    "\n",
    "<guidelines>\n",
    "When answering questions, follow these guidelines:\n",
    "1. Use only the information provided in the context. \n",
    "2. Do not introduce external information or make assumptions beyond what is explicitly stated in the context.\n",
    "3. The context contain sources at the topic of each individual document.\n",
    "4. Include these sources your answer next to any relevant statements. For example, for source # 1 use [1]. \n",
    "5. List your sources in order at the bottom of your answer. [1] Source 1, [2] Source 2, etc\n",
    "6. If the source is: <Document source=\"assistant/docs/llama3_1.pdf\" page=\"7\"/>' then just list: \n",
    "[1] assistant/docs/llama3_1.pdf, page 7 \n",
    "And skip the addition of the brackets as well as the Document source preamble in your citation.\n",
    "</guidelines>\n",
    "\n",
    "</instruction>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "section_writer_instructions: str = \"\"\"\n",
    "<instruction>\n",
    "You are an expert technical writer. \n",
    "Your task is to create a short, easily digestible section of a report based on a set of source documents.\n",
    "\n",
    "1. Analyze the content of the source documents: \n",
    "- The name of each source document is at the start of the document, with the <Document tag.\n",
    "\n",
    "2. Create a report structure using markdown formatting:\n",
    "- Use ## for the section title\n",
    "- Use ### for sub-section headers\n",
    "\n",
    "3. Write the report following this structure:\n",
    "a. Title (## header)\n",
    "b. Summary (### header)\n",
    "c. Sources (### header)\n",
    "\n",
    "4. Make your title engaging based upon the focus area of the analyst: \n",
    "{focus}\n",
    "\n",
    "5. For the summary section:\n",
    "- Set up summary with general background / context related to the focus area of the analyst\n",
    "- Emphasize what is novel, interesting, or surprising about insights gathered from the interview\n",
    "- Create a numbered list of source documents, as you use them\n",
    "- Do not mention the names of interviewers or experts\n",
    "- Aim for approximately 400 words maximum\n",
    "- Use numbered sources in your report (e.g., [1], [2]) based on information from source documents\n",
    "\n",
    "6. In the Sources section:\n",
    "- Include all sources used in your report\n",
    "- Provide full links to relevant websites or specific document paths\n",
    "- Separate each source by a newline. Use two spaces at the end of each line to create a newline in Markdown.\n",
    "- It will look like:\n",
    "\n",
    "### Sources\n",
    "[1] Link or Document name\n",
    "[2] Link or Document name\n",
    "\n",
    "7. Be sure to combine sources. For example this is not correct:\n",
    "\n",
    "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "[4] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "\n",
    "There should be no redundant sources. It should simply be:\n",
    "\n",
    "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "\n",
    "8. Final review:\n",
    "- Ensure the report follows the required structure\n",
    "- Include no preamble before the title of the report\n",
    "- Check that all guidelines have been followed\n",
    "</instruction>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f80ec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_instructions = \"\"\"\n",
    "<instruction>\n",
    "You are an analyst tasked with interviewing an expert to learn about a specific topic. \n",
    "\n",
    "Your goal is boil down to interesting and specific insights related to your topic.\n",
    "\n",
    "1. Interesting: Insights that people will find surprising or non-obvious.\n",
    "\n",
    "2. Specific: Insights that avoid generalities and include specific examples from the expert.\n",
    "\n",
    "Here is your topic of focus and set of goals: {goals}\n",
    "\n",
    "Begin by introducing yourself using a name that fits your persona, and then ask your question.\n",
    "\n",
    "Continue to ask questions to drill down and refine your understanding of the topic.\n",
    "\n",
    "When you are satisfied with your understanding, complete the interview with: \"Thank you so much for your help!\"\n",
    "\n",
    "Remember to stay in character throughout your response, reflecting the persona and goals provided to you.\n",
    "</instruction>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2288fe55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'current Pope 2023',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'title': 'Pope Francis - Wikipedia',\n",
       "   'url': 'https://en.wikipedia.org/wiki/Pope_Francis',\n",
       "   'content': 'Pope Francis [b] (born Jorge Mario Bergoglio; [c] 17 December 1936 - 21 April 2025) was head of the Catholic Church and sovereign of the Vatican City State from 2013 until his death in 2025. He was the first Jesuit pope, the first Latin American, and the first born or raised outside Europe since the 8th-century Syrian pope Gregory III.',\n",
       "   'score': 0.68496037,\n",
       "   'raw_content': None},\n",
       "  {'title': 'After 10 years as pope, Francis continues to reshape the Catholic ... - NPR',\n",
       "   'url': 'https://www.npr.org/2023/03/13/1162954465/after-10-years-as-pope-francis-continues-to-reshape-the-catholic-church',\n",
       "   'content': 'After 10 years as pope, ... March 13, 2023 5:47 AM ET. Sylvia Poggioli After 10 years as pope, Francis continues to reshape the Catholic Church. Listen · 8:03 8:03. Toggle more options',\n",
       "   'score': 0.5957048,\n",
       "   'raw_content': None},\n",
       "  {'title': 'Pope Francis has stacked the next conclave — but will it matter?',\n",
       "   'url': 'https://religionnews.com/2023/09/25/pope-conclave/',\n",
       "   'content': 'But papal succession is a constant conversation at the Vatican, no matter the health of the current pope, and even Francis is in on it. ... 2013 vs. 2023\" Sources: Publicly available Vatican',\n",
       "   'score': 0.43813655,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 1.89}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message: str = \"Tell me a who the current Pope is.\"\n",
    "search_query: SearchQuery = await llm.with_structured_output(SearchQuery).ainvoke(\n",
    "    [SystemMessage(content=search_instructions)] + [message]\n",
    ")\n",
    "search_docs = await tavily_search.ainvoke(search_query.search_query)\n",
    "\n",
    "search_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377b689a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query: SearchQuery = await llm.with_structured_output(SearchQuery).ainvoke(\n",
    "    [SystemMessage(content=search_instructions)] + [message]\n",
    ")\n",
    "search_docs = WikipediaLoader(search_query.search_query, load_max_docs=2).load()\n",
    "search_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c730cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import get_buffer_string\n",
    "\n",
    "\n",
    "async def generate_question(state: InterviewState) -> dict[str, Any]:\n",
    "    # Get state\n",
    "    analyst: Analyst = state[\"analyst\"]\n",
    "    messages: list[Any] = state[\"messages\"]\n",
    "\n",
    "    # Generate questions\n",
    "    system_message = question_instructions.format(goals=analyst.persona)\n",
    "    question = await llm.ainvoke([SystemMessage(content=system_message)] + messages)\n",
    "\n",
    "    # Write the message to the state\n",
    "    return {\"question\": question}\n",
    "\n",
    "\n",
    "async def search_web(state: InterviewState) -> dict[str, Any]:\n",
    "    structured_llm = llm.with_structured_output(SearchQuery)\n",
    "    search_query: SearchQuery = await structured_llm.ainvoke(\n",
    "        [SystemMessage(content=search_instructions)] + state[\"messages\"]\n",
    "    )\n",
    "\n",
    "    # Search web\n",
    "    search_docs = await tavily_search.ainvoke(search_query.search_query)\n",
    "\n",
    "    formatted_search_docs = \"\\n\\n ---\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "            for doc in search_docs.get(\"results\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return {\"context\": [formatted_search_docs]}\n",
    "\n",
    "\n",
    "async def search_wikipedia(state: InterviewState) -> dict[str, Any]:\n",
    "    structured_llm = llm.with_structured_output(SearchQuery)\n",
    "    search_query: SearchQuery = await structured_llm.ainvoke(\n",
    "        [SystemMessage(content=search_instructions)] + state[\"messages\"]\n",
    "    )\n",
    "\n",
    "    # Search wikipedia\n",
    "    search_docs = WikipediaLoader(search_query.search_query, load_max_docs=2).load()\n",
    "\n",
    "    formatted_search_docs = \"\\n\\n ---\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document source=\"{doc.metadata[\"source\"]}\" '\n",
    "            f'page=\"{doc.metadata.get(\"page\", \"\")}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "            for doc in search_docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return {\"context\": [formatted_search_docs]}\n",
    "\n",
    "\n",
    "async def generate_answer(state: InterviewState) -> dict[str, Any]:\n",
    "    # Get state\n",
    "    analyst: Analyst = state[\"analyst\"]\n",
    "    messages: list[Any] = state[\"messages\"]\n",
    "    context: list[Any] = state[\"context\"]\n",
    "\n",
    "    # Answer questions\n",
    "    system_message: str = answer_instructions.format(\n",
    "        goals=analyst.persona, context=context\n",
    "    )\n",
    "    answer = await llm.ainvoke([SystemMessage(content=system_message)] + messages)\n",
    "    answer.name = \"expert\"  # Add a name to the answer\n",
    "\n",
    "    # Write the message to the state\n",
    "    return {\"answer\": [answer]}\n",
    "\n",
    "\n",
    "def save_interview(state: InterviewState) -> dict[str, Any]:\n",
    "    messages = state[\"messages\"]\n",
    "    # Convert interview to string\n",
    "    interview = get_buffer_string(messages)\n",
    "\n",
    "    return {\"interview\": interview}\n",
    "\n",
    "\n",
    "def route_messages(\n",
    "    state: InterviewState, name: str = \"expert\"\n",
    ") -> Literal[\"ask_question\", \"save_interview\"]:\n",
    "    messages: list[Any] = state[\"messages\"]\n",
    "    max_num_turns: int = state.get(\"max_num_turns\", 2)\n",
    "\n",
    "    # Check the number of responses by the `expert`\n",
    "    num_responses: int = len(\n",
    "        [m for m in messages if isinstance(m, AIMessage) and m.name == name]\n",
    "    )\n",
    "    # End if the `expert` has answered more than `max_num_turns`\n",
    "    if num_responses >= max_num_turns:\n",
    "        return \"save_interview\"\n",
    "\n",
    "    # Get the last qs asked to check if it signals the end of the interview\n",
    "    try:\n",
    "        last_message = messages[-2]\n",
    "        if \"thank you so much for your help\" in last_message.content.lower():\n",
    "            return \"save_interview\"\n",
    "    except IndexError:\n",
    "        return \"ask_question\"\n",
    "\n",
    "    return \"ask_question\"\n",
    "\n",
    "\n",
    "async def write_section(state: InterviewState) -> dict[str, Any]:\n",
    "    # Get state\n",
    "    context: list[Any] = state[\"context\"]\n",
    "    analyst: Analyst = state[\"analyst\"]\n",
    "\n",
    "    # Create the source doc using either the context or the interview\n",
    "    system_message = section_writer_instructions.format(focus=analyst.description)\n",
    "    section = await llm.ainvoke(\n",
    "        [SystemMessage(content=system_message)]\n",
    "        + [HumanMessage(content=f\"Use this source to write your section: {context}\")]\n",
    "    )\n",
    "\n",
    "    # Write the message to the state\n",
    "    return {\"sections\": [section.content]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "\n",
    "# Create graph\n",
    "graph_builder = StateGraph(InterviewState)\n",
    "\n",
    "# Add nodes\n",
    "graph_builder.add_node(\"search_web\", search_web)\n",
    "graph_builder.add_node(\"search_wikipedia\", search_wikipedia)\n",
    "graph_builder.add_node(\"ask_question\", generate_question)\n",
    "graph_builder.add_node(\"answer_question\", generate_answer)\n",
    "graph_builder.add_node(\"save_interview\", save_interview)\n",
    "graph_builder.add_node(\"write_section\", write_section)\n",
    "\n",
    "# Connect nodes\n",
    "graph_builder.add_edge(START, \"ask_question\")\n",
    "graph_builder.add_edge(\"ask_question\", \"search_wikipedia\")\n",
    "graph_builder.add_edge(\"ask_question\", \"search_web\")\n",
    "graph_builder.add_edge(\"search_web\", \"answer_question\")\n",
    "graph_builder.add_edge(\"search_wikipedia\", \"answer_question\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"answer_question\", route_messages, [\"ask_question\", \"save_interview\"]\n",
    ")\n",
    "graph_builder.add_edge(\"save_interview\", \"write_section\")\n",
    "graph_builder.add_edge(\"write_section\", END)\n",
    "\n",
    "# Compile the graph\n",
    "memory = MemorySaver()\n",
    "langfuse_handler = CallbackHandler()\n",
    "config = RunnableConfig(callbacks=[langfuse_handler], run_name=\"Conduct Interviews\")\n",
    "graph: CompiledStateGraph = graph_builder.compile(checkpointer=memory).with_config(\n",
    "    config\n",
    ")\n",
    "\n",
    "# Visualize the graph\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaeb560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one analyst\n",
    "console.log(analysts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7211716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    HumanMessage(content=f\"So you said you were writing an article on {topic}?\")\n",
    "]\n",
    "thread: dict[str, Any] = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "input_values: dict[str, Any] = {\n",
    "    \"analyst\": analysts[0],\n",
    "    \"messages\": messages,\n",
    "    \"max_num_turns\": 2,\n",
    "}\n",
    "\n",
    "interview = await graph.ainvoke(input_values, thread)\n",
    "\n",
    "Markdown(interview[\"sections\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbeab4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3237bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "/no_think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e1ea86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2084ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"query\": \"current Pope\",\n",
    "    \"follow_up_questions\": None,\n",
    "    \"answer\": None,\n",
    "    \"images\": [],\n",
    "    \"results\": [\n",
    "        {\n",
    "            \"title\": \"Pope Leo XIV - Wikipedia\",\n",
    "            \"url\": \"https://en.wikipedia.org/wiki/Pope_Leo_XIV\",\n",
    "            \"content\": \"Pope Leo XIV [a] (born Robert Francis Prevost, [b] [c] September 14, 1955) ...\",\n",
    "            \"score\": 0.73755574,\n",
    "            \"raw_content\": None,\n",
    "        },\n",
    "        ...,\n",
    "    ],\n",
    "    \"response_time\": 1.79,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88521bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b673729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117a299a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc2cfff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8b176a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
