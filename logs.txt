136287143s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 19:11:46 | 200 |    7.738821ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:11:56 | 200 |   12.545806ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:12:22 | 200 |   13.507106ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:12:58 | 200 |    9.018068ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:13:34 | 200 |    7.703939ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:14:10 | 200 |     8.30077ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:14:46 | 200 |    7.549312ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:15:22 | 200 |    9.026096ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:15:58 | 200 |    8.547229ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:16:34 | 200 |   15.719861ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:17:10 | 200 |   22.073399ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:17:46 | 200 |   13.441513ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:18:22 | 200 |   14.237461ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:18:58 | 200 |      7.9123ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:19:34 | 200 |     8.42454ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:20:10 | 200 |   20.285544ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:20:46 | 200 |   13.834416ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:21:22 | 200 |     7.82941ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:21:58 | 200 |    8.189964ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:22:34 | 200 |    7.977562ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:23:10 | 200 |   13.628118ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:23:46 | 200 |   13.792116ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:24:22 | 200 |    8.046549ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:24:58 | 200 |    7.608489ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:25:34 | 200 |   14.021339ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:26:10 | 200 |   14.494752ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:26:46 | 200 |   13.537619ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:27:22 | 200 |    7.633787ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:27:58 | 200 |    7.611932ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:28:34 | 200 |    8.471781ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:29:10 | 200 |    7.727706ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:29:46 | 200 |    8.000214ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:30:22 | 200 |    7.691634ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:30:58 | 200 |    7.779835ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:31:34 | 200 |    8.155573ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:32:10 | 200 |    10.02307ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:32:46 | 200 |    7.918145ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:33:22 | 200 |    7.900157ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:33:58 | 200 |   10.689262ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:34:34 | 200 |    7.696382ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:35:10 | 200 |     8.70712ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:35:46 | 200 |    8.266533ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:36:22 | 200 |   76.991715ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:36:58 | 200 |    7.954449ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:37:34 | 200 |    7.505371ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:38:10 | 200 |    7.687221ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:38:46 | 200 |    11.40925ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:39:22 | 200 |   10.813489ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:39:58 | 200 |    8.149294ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:40:34 | 200 |    8.383531ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:41:10 | 200 |    9.007861ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:41:46 | 200 |    8.096134ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:42:22 | 200 |    8.919253ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:42:58 | 200 |    7.632561ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:43:34 | 200 |    8.692429ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:44:10 | 200 |   12.417075ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:44:46 | 200 |   22.351821ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:45:22 | 200 |    7.724575ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:45:58 | 200 |    20.81743ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:46:34 | 200 |    8.303593ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:47:10 | 200 |    7.530518ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:47:46 | 200 |    8.134528ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:48:22 | 200 |    7.886337ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:48:58 | 200 |    8.244192ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:49:34 | 200 |  119.341282ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:50:10 | 200 |    9.245452ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:50:46 | 200 |    8.174065ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:51:22 | 200 |    8.488541ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:51:58 | 200 |    9.031132ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:52:34 | 200 |   10.708721ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:53:10 | 200 |   16.268483ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:53:46 | 200 |    7.852954ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:54:22 | 200 |    7.994802ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:54:58 | 200 |    8.115581ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:55:34 | 200 |    7.823747ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:56:10 | 200 |    8.271555ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:56:46 | 200 |    7.570699ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:57:22 | 200 |    8.681011ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:57:58 | 200 |    8.248502ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:58:34 | 200 |    9.438284ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:59:10 | 200 |    7.606658ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 19:59:46 | 200 |    8.143035ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:00:22 | 200 |    7.494672ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:00:58 | 200 |   12.401905ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:01:34 | 200 |     8.03553ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:02:10 | 200 |    8.396456ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:02:46 | 200 |    8.560733ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:03:22 | 200 |   10.056095ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:03:58 | 200 |    7.854393ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:04:34 | 200 |    7.520734ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:05:10 | 200 |    7.874831ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:05:46 | 200 |    8.458888ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:06:22 | 200 |     7.93372ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:06:58 | 200 |    7.629426ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:07:34 | 200 |    8.155203ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:08:10 | 200 |    8.992467ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:08:46 | 200 |    8.275354ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:09:22 | 200 |    7.405366ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:09:58 | 200 |    8.005795ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:10:34 | 200 |    7.876767ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:11:10 | 200 |    7.770944ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:11:46 | 200 |    8.170809ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:12:22 | 200 |     7.60931ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:12:58 | 200 |    8.117969ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:13:34 | 200 |    7.727406ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:14:10 | 200 |    8.364037ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:14:46 | 200 |   10.680447ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:15:22 | 200 |    8.118546ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:15:58 | 200 |    9.140059ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:16:34 | 200 |    8.762545ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:17:10 | 200 |    7.564998ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:17:46 | 200 |    7.674162ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:18:22 | 200 |    7.836167ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:18:58 | 200 |    7.681057ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:19:34 | 200 |    10.56702ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:20:10 | 200 |    8.325081ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:20:46 | 200 |    7.765397ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:21:22 | 200 |    7.856735ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:21:58 | 200 |    7.769643ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:22:34 | 200 |    8.940508ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:23:10 | 200 |    7.537632ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:23:47 | 200 |    8.447524ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:24:23 | 200 |    7.671478ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:24:59 | 200 |     7.94262ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:25:35 | 200 |    7.730216ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:26:11 | 200 |    8.022294ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:26:47 | 200 |    7.680955ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:27:23 | 200 |    9.046768ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:27:59 | 200 |    9.874558ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:28:35 | 200 |   11.993613ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:29:11 | 200 |    8.141805ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:29:47 | 200 |   11.468801ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:30:23 | 200 |    8.033483ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:30:59 | 200 |    8.138726ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:31:35 | 200 |    8.183831ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:32:11 | 200 |    9.020184ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:32:47 | 200 |    7.584787ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:33:23 | 200 |    8.279429ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:33:59 | 200 |    8.194421ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:34:35 | 200 |    7.712104ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:35:11 | 200 |    7.645789ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:35:47 | 200 |    7.814261ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:36:23 | 200 |    7.893424ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:36:59 | 200 |    7.986716ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:37:35 | 200 |    7.700355ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:38:11 | 200 |    7.782851ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:38:47 | 200 |    8.372168ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:39:23 | 200 |    8.485595ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:39:59 | 200 |    7.571989ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:40:35 | 200 |    7.797449ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:41:11 | 200 |    8.798354ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T20:41:18.294+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T20:41:18.359+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T20:41:18.388+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T20:41:18.390+01:00 level=INFO source=server.go:105 msg="system memory" total="16.0 GiB" free="5.6 GiB" free_swap="0 B"
time=2025-05-05T20:41:18.390+01:00 level=WARN source=ggml.go:152 msg="key not found" key=qwen3.vision.block_count default=0
time=2025-05-05T20:41:18.391+01:00 level=INFO source=server.go:138 msg=offload library=cpu layers.requested=-1 layers.model=37 layers.offload=0 layers.split="" memory.available="[5.7 GiB]" memory.gpu_overhead="0 B" memory.required.full="4.4 GiB" memory.required.partial="0 B" memory.required.kv="1.1 GiB" memory.required.allocations="[4.4 GiB]" memory.weights.total="2.4 GiB" memory.weights.repeating="2.1 GiB" memory.weights.nonrepeating="304.3 MiB" memory.graph.full="768.0 MiB" memory.graph.partial="768.0 MiB"
time=2025-05-05T20:41:18.391+01:00 level=WARN source=server.go:173 msg="flash attention enabled but not supported by gpu"
llama_model_loader: loaded meta data with 27 key-value pairs and 398 tensors from /Users/neidu/.ollama/models/blobs/sha256-163553aea1b1de62de7c5eb2ef5afb756b4b3133308d9ae7e42e951d8d696ef5 (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = qwen3
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Qwen3 4B
llama_model_loader: - kv   3:                           general.basename str              = Qwen3
llama_model_loader: - kv   4:                         general.size_label str              = 4B
llama_model_loader: - kv   5:                          qwen3.block_count u32              = 36
llama_model_loader: - kv   6:                       qwen3.context_length u32              = 40960
llama_model_loader: - kv   7:                     qwen3.embedding_length u32              = 2560
llama_model_loader: - kv   8:                  qwen3.feed_forward_length u32              = 9728
llama_model_loader: - kv   9:                 qwen3.attention.head_count u32              = 32
llama_model_loader: - kv  10:              qwen3.attention.head_count_kv u32              = 8
llama_model_loader: - kv  11:                       qwen3.rope.freq_base f32              = 1000000.000000
llama_model_loader: - kv  12:     qwen3.attention.layer_norm_rms_epsilon f32              = 0.000001
llama_model_loader: - kv  13:                 qwen3.attention.key_length u32              = 128
llama_model_loader: - kv  14:               qwen3.attention.value_length u32              = 128
llama_model_loader: - kv  15:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  16:                         tokenizer.ggml.pre str              = qwen2
llama_model_loader: - kv  17:                      tokenizer.ggml.tokens arr[str,151936]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  18:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  19:                      tokenizer.ggml.merges arr[str,151387]  = ["Ġ Ġ", "ĠĠ ĠĠ", "i n", "Ġ t",...
llama_model_loader: - kv  20:                tokenizer.ggml.eos_token_id u32              = 151645
llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 151643
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 151643
llama_model_loader: - kv  23:               tokenizer.ggml.add_bos_token bool             = false
llama_model_loader: - kv  24:                    tokenizer.chat_template str              = {%- if tools %}\n    {{- '<|im_start|>...
llama_model_loader: - kv  25:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:                          general.file_type u32              = 15
llama_model_loader: - type  f32:  145 tensors
llama_model_loader: - type  f16:   36 tensors
llama_model_loader: - type q4_K:  198 tensors
llama_model_loader: - type q6_K:   19 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 2.44 GiB (5.20 BPW) 
load: special tokens cache size = 26
load: token to piece cache size = 0.9311 MB
print_info: arch             = qwen3
print_info: vocab_only       = 1
print_info: model type       = ?B
print_info: model params     = 4.02 B
print_info: general.name     = Qwen3 4B
print_info: vocab type       = BPE
print_info: n_vocab          = 151936
print_info: n_merges         = 151387
print_info: BOS token        = 151643 '<|endoftext|>'
print_info: EOS token        = 151645 '<|im_end|>'
print_info: EOT token        = 151645 '<|im_end|>'
print_info: PAD token        = 151643 '<|endoftext|>'
print_info: LF token         = 198 'Ċ'
print_info: FIM PRE token    = 151659 '<|fim_prefix|>'
print_info: FIM SUF token    = 151661 '<|fim_suffix|>'
print_info: FIM MID token    = 151660 '<|fim_middle|>'
print_info: FIM PAD token    = 151662 '<|fim_pad|>'
print_info: FIM REP token    = 151663 '<|repo_name|>'
print_info: FIM SEP token    = 151664 '<|file_sep|>'
print_info: EOG token        = 151643 '<|endoftext|>'
print_info: EOG token        = 151645 '<|im_end|>'
print_info: EOG token        = 151662 '<|fim_pad|>'
print_info: EOG token        = 151663 '<|repo_name|>'
print_info: EOG token        = 151664 '<|file_sep|>'
print_info: max token length = 256
llama_model_load: vocab only - skipping tensors
time=2025-05-05T20:41:18.827+01:00 level=INFO source=server.go:405 msg="starting llama server" cmd="/Applications/Ollama.app/Contents/Resources/ollama runner --model /Users/neidu/.ollama/models/blobs/sha256-163553aea1b1de62de7c5eb2ef5afb756b4b3133308d9ae7e42e951d8d696ef5 --ctx-size 8192 --batch-size 512 --threads 6 --no-mmap --parallel 4 --port 59834"
time=2025-05-05T20:41:18.834+01:00 level=INFO source=sched.go:451 msg="loaded runners" count=1
time=2025-05-05T20:41:18.834+01:00 level=INFO source=server.go:580 msg="waiting for llama runner to start responding"
time=2025-05-05T20:41:18.834+01:00 level=INFO source=server.go:614 msg="waiting for server to become available" status="llm server error"
time=2025-05-05T20:41:18.882+01:00 level=INFO source=runner.go:853 msg="starting go runner"
load_backend: loaded CPU backend from /Applications/Ollama.app/Contents/Resources/libggml-cpu-haswell.so
time=2025-05-05T20:41:18.923+01:00 level=INFO source=ggml.go:109 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.LLAMAFILE=1 CPU.1.SSE3=1 CPU.1.SSSE3=1 CPU.1.LLAMAFILE=1 compiler=cgo(clang)
time=2025-05-05T20:41:18.923+01:00 level=INFO source=runner.go:913 msg="Server listening on 127.0.0.1:59834"
llama_model_loader: loaded meta data with 27 key-value pairs and 398 tensors from /Users/neidu/.ollama/models/blobs/sha256-163553aea1b1de62de7c5eb2ef5afb756b4b3133308d9ae7e42e951d8d696ef5 (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = qwen3
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Qwen3 4B
llama_model_loader: - kv   3:                           general.basename str              = Qwen3
llama_model_loader: - kv   4:                         general.size_label str              = 4B
llama_model_loader: - kv   5:                          qwen3.block_count u32              = 36
llama_model_loader: - kv   6:                       qwen3.context_length u32              = 40960
llama_model_loader: - kv   7:                     qwen3.embedding_length u32              = 2560
llama_model_loader: - kv   8:                  qwen3.feed_forward_length u32              = 9728
llama_model_loader: - kv   9:                 qwen3.attention.head_count u32              = 32
llama_model_loader: - kv  10:              qwen3.attention.head_count_kv u32              = 8
llama_model_loader: - kv  11:                       qwen3.rope.freq_base f32              = 1000000.000000
llama_model_loader: - kv  12:     qwen3.attention.layer_norm_rms_epsilon f32              = 0.000001
llama_model_loader: - kv  13:                 qwen3.attention.key_length u32              = 128
llama_model_loader: - kv  14:               qwen3.attention.value_length u32              = 128
llama_model_loader: - kv  15:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  16:                         tokenizer.ggml.pre str              = qwen2
llama_model_loader: - kv  17:                      tokenizer.ggml.tokens arr[str,151936]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  18:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  19:                      tokenizer.ggml.merges arr[str,151387]  = ["Ġ Ġ", "ĠĠ ĠĠ", "i n", "Ġ t",...
llama_model_loader: - kv  20:                tokenizer.ggml.eos_token_id u32              = 151645
llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 151643
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 151643
llama_model_loader: - kv  23:               tokenizer.ggml.add_bos_token bool             = false
llama_model_loader: - kv  24:                    tokenizer.chat_template str              = {%- if tools %}\n    {{- '<|im_start|>...
llama_model_loader: - kv  25:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:                          general.file_type u32              = 15
llama_model_loader: - type  f32:  145 tensors
llama_model_loader: - type  f16:   36 tensors
llama_model_loader: - type q4_K:  198 tensors
llama_model_loader: - type q6_K:   19 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 2.44 GiB (5.20 BPW) 
time=2025-05-05T20:41:19.085+01:00 level=INFO source=server.go:614 msg="waiting for server to become available" status="llm server loading model"
load: special tokens cache size = 26
load: token to piece cache size = 0.9311 MB
print_info: arch             = qwen3
print_info: vocab_only       = 0
print_info: n_ctx_train      = 40960
print_info: n_embd           = 2560
print_info: n_layer          = 36
print_info: n_head           = 32
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa_pattern    = 1
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 4
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-06
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 9728
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: rope type        = 2
print_info: rope scaling     = linear
print_info: freq_base_train  = 1000000.0
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 40960
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = ?B
print_info: model params     = 4.02 B
print_info: general.name     = Qwen3 4B
print_info: vocab type       = BPE
print_info: n_vocab          = 151936
print_info: n_merges         = 151387
print_info: BOS token        = 151643 '<|endoftext|>'
print_info: EOS token        = 151645 '<|im_end|>'
print_info: EOT token        = 151645 '<|im_end|>'
print_info: PAD token        = 151643 '<|endoftext|>'
print_info: LF token         = 198 'Ċ'
print_info: FIM PRE token    = 151659 '<|fim_prefix|>'
print_info: FIM SUF token    = 151661 '<|fim_suffix|>'
print_info: FIM MID token    = 151660 '<|fim_middle|>'
print_info: FIM PAD token    = 151662 '<|fim_pad|>'
print_info: FIM REP token    = 151663 '<|repo_name|>'
print_info: FIM SEP token    = 151664 '<|file_sep|>'
print_info: EOG token        = 151643 '<|endoftext|>'
print_info: EOG token        = 151645 '<|im_end|>'
print_info: EOG token        = 151662 '<|fim_pad|>'
print_info: EOG token        = 151663 '<|repo_name|>'
print_info: EOG token        = 151664 '<|file_sep|>'
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = false)
load_tensors:          CPU model buffer size =  2493.69 MiB
llama_context: constructing llama_context
llama_context: n_seq_max     = 4
llama_context: n_ctx         = 8192
llama_context: n_ctx_per_seq = 2048
llama_context: n_batch       = 2048
llama_context: n_ubatch      = 512
llama_context: causal_attn   = 1
llama_context: flash_attn    = 0
llama_context: freq_base     = 1000000.0
llama_context: freq_scale    = 1
llama_context: n_ctx_per_seq (2048) < n_ctx_train (40960) -- the full capacity of the model will not be utilized
llama_context:        CPU  output buffer size =     2.36 MiB
init: kv_size = 8192, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 36, can_shift = 1
init:        CPU KV buffer size =  1152.00 MiB
llama_context: KV self size  = 1152.00 MiB, K (f16):  576.00 MiB, V (f16):  576.00 MiB
llama_context:        CPU compute buffer size =   554.01 MiB
llama_context: graph nodes  = 1374
llama_context: graph splits = 1
time=2025-05-05T20:41:25.430+01:00 level=INFO source=server.go:619 msg="llama runner started in 6.59 seconds"
[GIN] 2025/05/05 - 20:41:33 | 200 | 15.339114004s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 20:41:47 | 200 |   28.736274ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:42:23 | 200 |   13.339151ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:42:59 | 200 |   13.592581ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:43:35 | 200 |   12.827841ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T20:43:56.813+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 20:44:11 | 200 |   16.563018ms |       127.0.0.1 | GET      "/api/tags"
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              [GIN] 2025/05/05 - 20:44:47 | 200 |    10.86965ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:45:23 | 200 |   10.407402ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T20:45:45.617+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 20:45:59 | 200 |   14.084208ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:46:17 | 200 | 31.796370308s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 20:46:35 | 200 |   10.345013ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T20:46:50.447+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 20:46:54 | 200 |  4.529951465s |       127.0.0.1 | POST     "/v1/chat/completions"
time=2025-05-05T20:47:01.175+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 20:47:04 | 200 |  3.835475013s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 20:47:11 | 200 |   13.337175ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T20:47:21.981+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 20:47:47 | 200 |   14.162192ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:47:51 | 200 | 29.875889072s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 20:48:23 | 200 |    12.24446ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:48:59 | 200 |    9.210212ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T20:49:17.431+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 20:49:27 | 200 | 10.512975336s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 20:49:35 | 200 |   10.486843ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T20:49:39.489+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 20:49:46 | 200 |  7.361454549s |       127.0.0.1 | POST     "/v1/chat/completions"
time=2025-05-05T20:49:56.891+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 20:50:11 | 200 |   14.616154ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:50:28 | 200 | 31.180121319s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 20:50:47 | 200 |    8.051213ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T20:50:50.157+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 20:51:15 | 200 | 25.753131245s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 20:51:23 | 200 |    8.192875ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T20:51:57.366+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 20:51:59 | 200 |    9.929463ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:52:21 | 200 | 24.562749062s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 20:52:35 | 200 |    7.892139ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:53:11 | 200 |   11.351599ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:53:47 | 200 |    7.947462ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:54:23 | 200 |    7.836044ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:54:59 | 200 |   13.125403ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:55:35 | 200 |    7.676012ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:56:11 | 200 |    7.772226ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:56:47 | 200 |    8.267292ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:57:23 | 200 |    7.918617ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:57:59 | 200 |     7.49371ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:58:35 | 200 |    7.867649ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:59:11 | 200 |    8.289512ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 20:59:47 | 200 |   10.974533ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:00:23 | 200 |    8.026063ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:00:59 | 200 |    8.867993ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:01:35 | 200 |    8.260298ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:02:11 | 200 |    8.435423ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:02:47 | 200 |    7.525288ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:03:23 | 200 |    7.347277ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T21:03:37.825+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 21:03:59 | 200 |   11.178071ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:04:02 | 200 | 25.005639566s |       127.0.0.1 | POST     "/v1/chat/completions"
time=2025-05-05T21:04:11.947+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 21:04:35 | 200 |   11.919001ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:04:36 | 200 | 24.960900985s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 21:05:11 | 200 |   17.437617ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:05:47 | 200 |   10.488518ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T21:05:53.424+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 21:06:05 | 200 | 12.125295557s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 21:06:23 | 200 |   18.937576ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T21:06:33.063+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 21:06:44 | 200 | 11.693728092s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 21:06:59 | 200 |    7.400883ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:07:35 | 200 |   15.749876ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:08:11 | 200 |    8.589181ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:08:47 | 200 |   21.604088ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:09:23 | 200 |    8.339978ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T21:09:28.349+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 21:09:38 | 200 | 10.284890565s |       127.0.0.1 | POST     "/v1/chat/completions"
time=2025-05-05T21:09:50.424+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 21:09:59 | 200 |    11.49439ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:10:00 | 200 | 10.354205545s |       127.0.0.1 | POST     "/v1/chat/completions"
time=2025-05-05T21:10:00.777+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 21:10:24 | 200 | 23.926635616s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 21:10:35 | 200 |    7.840417ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:11:11 | 200 |    13.24309ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:11:47 | 200 |   20.473036ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:12:23 | 200 |   13.525988ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:12:59 | 200 |    7.995839ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:13:35 | 200 |     8.27657ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:14:11 | 200 |      8.1095ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:14:47 | 200 |    8.558384ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:15:23 | 200 |    7.890672ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:15:59 | 200 |    7.097737ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:16:35 | 200 |    7.367577ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T21:17:06.901+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 21:17:11 | 200 |   13.420591ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:17:19 | 200 | 12.202419111s |       127.0.0.1 | POST     "/v1/chat/completions"
time=2025-05-05T21:17:19.083+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 21:17:42 | 200 | 23.308825037s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 21:17:47 | 200 |    9.055561ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T21:18:11.287+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 21:18:23 | 200 | 12.138508959s |       127.0.0.1 | POST     "/v1/chat/completions"
time=2025-05-05T21:18:23.423+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 21:18:23 | 200 |    10.33095ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:18:48 | 200 |  24.64851291s |       127.0.0.1 | POST     "/v1/chat/completions"
time=2025-05-05T21:18:51.543+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 21:18:59 | 200 |   10.720432ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:19:04 | 200 | 12.862788503s |       127.0.0.1 | POST     "/v1/chat/completions"
time=2025-05-05T21:19:04.409+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 21:19:27 | 200 | 23.334705659s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 21:19:35 | 200 |    9.488462ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:20:11 | 200 |   10.587504ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T21:20:17.941+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 21:20:29 | 200 | 12.001374381s |       127.0.0.1 | POST     "/v1/chat/completions"
time=2025-05-05T21:20:29.939+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 21:20:47 | 200 |   10.866295ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:20:54 | 200 | 24.162906993s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 21:21:23 | 200 |     16.0387ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T21:21:36.053+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 21:21:49 | 200 | 13.007952362s |       127.0.0.1 | POST     "/v1/chat/completions"
time=2025-05-05T21:21:49.055+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 21:21:59 | 200 |   13.474581ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:22:13 | 200 | 24.109030807s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 21:22:35 | 200 |    9.854088ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:23:11 | 200 |    8.037573ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:23:47 | 200 |    7.728592ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:24:23 | 200 |    7.894531ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:24:59 | 200 |    7.911475ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:25:35 | 200 |    7.548834ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:26:11 | 200 |    7.728929ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:26:47 | 200 |   14.994314ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:27:23 | 200 |   13.484378ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:27:59 | 200 |   18.295843ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:28:35 | 200 |    7.502013ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:29:11 | 200 |    8.647388ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:29:47 | 200 |     7.94639ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T21:29:53.507+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 21:30:05 | 200 | 12.270446383s |       127.0.0.1 | POST     "/v1/chat/completions"
time=2025-05-05T21:30:05.775+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 21:30:23 | 200 |   11.561451ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:30:30 | 200 | 24.591914161s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 21:30:59 | 200 |   19.506813ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:31:35 | 200 |   14.921627ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:32:11 | 200 |   21.315808ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:32:47 | 200 |    8.167361ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:33:23 | 200 |    7.749333ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:33:59 | 200 |    8.041022ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:34:35 | 200 |    8.265693ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T21:35:11.331+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 21:35:11 | 200 |   15.193351ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:35:23 | 200 | 11.973852963s |       127.0.0.1 | POST     "/v1/chat/completions"
time=2025-05-05T21:35:23.292+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 21:35:41 | 200 | 17.865915624s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 21:35:47 | 200 |    7.984521ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:36:23 | 200 |    7.863219ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:36:59 | 200 |    8.927653ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:37:35 | 200 |    7.752071ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:38:11 | 200 |    8.141255ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:38:47 | 200 |   13.022712ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:39:23 | 200 |    7.804404ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:39:59 | 200 |      9.7016ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:40:35 | 200 |    8.208531ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:41:11 | 200 |    8.074328ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:41:47 | 200 |   15.244834ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:42:23 | 200 |   21.215395ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:42:59 | 200 |   13.459969ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:43:35 | 200 |   17.881573ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:44:11 | 200 |   12.598707ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:44:47 | 200 |    12.44087ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:45:23 | 200 |   15.747174ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:45:59 | 200 |   12.835106ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:46:35 | 200 |    13.56023ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:47:11 | 200 |   15.241122ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:47:47 | 200 |   16.527493ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:48:23 | 200 |   14.117898ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:48:59 | 200 |   13.457161ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:49:35 | 200 |    7.672641ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:50:11 | 200 |    7.172927ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:50:47 | 200 |    7.958694ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:51:23 | 200 |    7.898656ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:51:59 | 200 |     8.15724ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T21:52:06.036+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T21:52:06.063+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T21:52:06.090+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T21:52:06.093+01:00 level=INFO source=server.go:105 msg="system memory" total="16.0 GiB" free="8.2 GiB" free_swap="0 B"
time=2025-05-05T21:52:06.093+01:00 level=WARN source=ggml.go:152 msg="key not found" key=qwen3.vision.block_count default=0
time=2025-05-05T21:52:06.094+01:00 level=INFO source=server.go:138 msg=offload library=cpu layers.requested=-1 layers.model=37 layers.offload=0 layers.split="" memory.available="[8.2 GiB]" memory.gpu_overhead="0 B" memory.required.full="4.4 GiB" memory.required.partial="0 B" memory.required.kv="1.1 GiB" memory.required.allocations="[4.4 GiB]" memory.weights.total="2.4 GiB" memory.weights.repeating="2.1 GiB" memory.weights.nonrepeating="304.3 MiB" memory.graph.full="768.0 MiB" memory.graph.partial="768.0 MiB"
time=2025-05-05T21:52:06.094+01:00 level=WARN source=server.go:173 msg="flash attention enabled but not supported by gpu"
llama_model_loader: loaded meta data with 27 key-value pairs and 398 tensors from /Users/neidu/.ollama/models/blobs/sha256-163553aea1b1de62de7c5eb2ef5afb756b4b3133308d9ae7e42e951d8d696ef5 (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = qwen3
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Qwen3 4B
llama_model_loader: - kv   3:                           general.basename str              = Qwen3
llama_model_loader: - kv   4:                         general.size_label str              = 4B
llama_model_loader: - kv   5:                          qwen3.block_count u32              = 36
llama_model_loader: - kv   6:                       qwen3.context_length u32              = 40960
llama_model_loader: - kv   7:                     qwen3.embedding_length u32              = 2560
llama_model_loader: - kv   8:                  qwen3.feed_forward_length u32              = 9728
llama_model_loader: - kv   9:                 qwen3.attention.head_count u32              = 32
llama_model_loader: - kv  10:              qwen3.attention.head_count_kv u32              = 8
llama_model_loader: - kv  11:                       qwen3.rope.freq_base f32              = 1000000.000000
llama_model_loader: - kv  12:     qwen3.attention.layer_norm_rms_epsilon f32              = 0.000001
llama_model_loader: - kv  13:                 qwen3.attention.key_length u32              = 128
llama_model_loader: - kv  14:               qwen3.attention.value_length u32              = 128
llama_model_loader: - kv  15:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  16:                         tokenizer.ggml.pre str              = qwen2
llama_model_loader: - kv  17:                      tokenizer.ggml.tokens arr[str,151936]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  18:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  19:                      tokenizer.ggml.merges arr[str,151387]  = ["Ġ Ġ", "ĠĠ ĠĠ", "i n", "Ġ t",...
llama_model_loader: - kv  20:                tokenizer.ggml.eos_token_id u32              = 151645
llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 151643
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 151643
llama_model_loader: - kv  23:               tokenizer.ggml.add_bos_token bool             = false
llama_model_loader: - kv  24:                    tokenizer.chat_template str              = {%- if tools %}\n    {{- '<|im_start|>...
llama_model_loader: - kv  25:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:                          general.file_type u32              = 15
llama_model_loader: - type  f32:  145 tensors
llama_model_loader: - type  f16:   36 tensors
llama_model_loader: - type q4_K:  198 tensors
llama_model_loader: - type q6_K:   19 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 2.44 GiB (5.20 BPW) 
load: special tokens cache size = 26
load: token to piece cache size = 0.9311 MB
print_info: arch             = qwen3
print_info: vocab_only       = 1
print_info: model type       = ?B
print_info: model params     = 4.02 B
print_info: general.name     = Qwen3 4B
print_info: vocab type       = BPE
print_info: n_vocab          = 151936
print_info: n_merges         = 151387
print_info: BOS token        = 151643 '<|endoftext|>'
print_info: EOS token        = 151645 '<|im_end|>'
print_info: EOT token        = 151645 '<|im_end|>'
print_info: PAD token        = 151643 '<|endoftext|>'
print_info: LF token         = 198 'Ċ'
print_info: FIM PRE token    = 151659 '<|fim_prefix|>'
print_info: FIM SUF token    = 151661 '<|fim_suffix|>'
print_info: FIM MID token    = 151660 '<|fim_middle|>'
print_info: FIM PAD token    = 151662 '<|fim_pad|>'
print_info: FIM REP token    = 151663 '<|repo_name|>'
print_info: FIM SEP token    = 151664 '<|file_sep|>'
print_info: EOG token        = 151643 '<|endoftext|>'
print_info: EOG token        = 151645 '<|im_end|>'
print_info: EOG token        = 151662 '<|fim_pad|>'
print_info: EOG token        = 151663 '<|repo_name|>'
print_info: EOG token        = 151664 '<|file_sep|>'
print_info: max token length = 256
llama_model_load: vocab only - skipping tensors
time=2025-05-05T21:52:06.512+01:00 level=INFO source=server.go:405 msg="starting llama server" cmd="/Applications/Ollama.app/Contents/Resources/ollama runner --model /Users/neidu/.ollama/models/blobs/sha256-163553aea1b1de62de7c5eb2ef5afb756b4b3133308d9ae7e42e951d8d696ef5 --ctx-size 8192 --batch-size 512 --threads 6 --no-mmap --parallel 4 --port 63440"
time=2025-05-05T21:52:06.517+01:00 level=INFO source=sched.go:451 msg="loaded runners" count=1
time=2025-05-05T21:52:06.518+01:00 level=INFO source=server.go:580 msg="waiting for llama runner to start responding"
time=2025-05-05T21:52:06.519+01:00 level=INFO source=server.go:614 msg="waiting for server to become available" status="llm server error"
time=2025-05-05T21:52:06.652+01:00 level=INFO source=runner.go:853 msg="starting go runner"
load_backend: loaded CPU backend from /Applications/Ollama.app/Contents/Resources/libggml-cpu-haswell.so
time=2025-05-05T21:52:06.691+01:00 level=INFO source=ggml.go:109 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.LLAMAFILE=1 CPU.1.SSE3=1 CPU.1.SSSE3=1 CPU.1.LLAMAFILE=1 compiler=cgo(clang)
time=2025-05-05T21:52:06.693+01:00 level=INFO source=runner.go:913 msg="Server listening on 127.0.0.1:63440"
llama_model_loader: loaded meta data with 27 key-value pairs and 398 tensors from /Users/neidu/.ollama/models/blobs/sha256-163553aea1b1de62de7c5eb2ef5afb756b4b3133308d9ae7e42e951d8d696ef5 (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = qwen3
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Qwen3 4B
llama_model_loader: - kv   3:                           general.basename str              = Qwen3
llama_model_loader: - kv   4:                         general.size_label str              = 4B
llama_model_loader: - kv   5:                          qwen3.block_count u32              = 36
llama_model_loader: - kv   6:                       qwen3.context_length u32              = 40960
llama_model_loader: - kv   7:                     qwen3.embedding_length u32              = 2560
llama_model_loader: - kv   8:                  qwen3.feed_forward_length u32              = 9728
llama_model_loader: - kv   9:                 qwen3.attention.head_count u32              = 32
llama_model_loader: - kv  10:              qwen3.attention.head_count_kv u32              = 8
llama_model_loader: - kv  11:                       qwen3.rope.freq_base f32              = 1000000.000000
llama_model_loader: - kv  12:     qwen3.attention.layer_norm_rms_epsilon f32              = 0.000001
llama_model_loader: - kv  13:                 qwen3.attention.key_length u32              = 128
llama_model_loader: - kv  14:               qwen3.attention.value_length u32              = 128
llama_model_loader: - kv  15:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  16:                         tokenizer.ggml.pre str              = qwen2
time=2025-05-05T21:52:06.771+01:00 level=INFO source=server.go:614 msg="waiting for server to become available" status="llm server loading model"
llama_model_loader: - kv  17:                      tokenizer.ggml.tokens arr[str,151936]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  18:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  19:                      tokenizer.ggml.merges arr[str,151387]  = ["Ġ Ġ", "ĠĠ ĠĠ", "i n", "Ġ t",...
llama_model_loader: - kv  20:                tokenizer.ggml.eos_token_id u32              = 151645
llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 151643
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 151643
llama_model_loader: - kv  23:               tokenizer.ggml.add_bos_token bool             = false
llama_model_loader: - kv  24:                    tokenizer.chat_template str              = {%- if tools %}\n    {{- '<|im_start|>...
llama_model_loader: - kv  25:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:                          general.file_type u32              = 15
llama_model_loader: - type  f32:  145 tensors
llama_model_loader: - type  f16:   36 tensors
llama_model_loader: - type q4_K:  198 tensors
llama_model_loader: - type q6_K:   19 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 2.44 GiB (5.20 BPW) 
load: special tokens cache size = 26
load: token to piece cache size = 0.9311 MB
print_info: arch             = qwen3
print_info: vocab_only       = 0
print_info: n_ctx_train      = 40960
print_info: n_embd           = 2560
print_info: n_layer          = 36
print_info: n_head           = 32
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa_pattern    = 1
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 4
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-06
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 9728
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: rope type        = 2
print_info: rope scaling     = linear
print_info: freq_base_train  = 1000000.0
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 40960
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = ?B
print_info: model params     = 4.02 B
print_info: general.name     = Qwen3 4B
print_info: vocab type       = BPE
print_info: n_vocab          = 151936
print_info: n_merges         = 151387
print_info: BOS token        = 151643 '<|endoftext|>'
print_info: EOS token        = 151645 '<|im_end|>'
print_info: EOT token        = 151645 '<|im_end|>'
print_info: PAD token        = 151643 '<|endoftext|>'
print_info: LF token         = 198 'Ċ'
print_info: FIM PRE token    = 151659 '<|fim_prefix|>'
print_info: FIM SUF token    = 151661 '<|fim_suffix|>'
print_info: FIM MID token    = 151660 '<|fim_middle|>'
print_info: FIM PAD token    = 151662 '<|fim_pad|>'
print_info: FIM REP token    = 151663 '<|repo_name|>'
print_info: FIM SEP token    = 151664 '<|file_sep|>'
print_info: EOG token        = 151643 '<|endoftext|>'
print_info: EOG token        = 151645 '<|im_end|>'
print_info: EOG token        = 151662 '<|fim_pad|>'
print_info: EOG token        = 151663 '<|repo_name|>'
print_info: EOG token        = 151664 '<|file_sep|>'
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = false)
load_tensors:          CPU model buffer size =  2493.69 MiB
llama_context: constructing llama_context
llama_context: n_seq_max     = 4
llama_context: n_ctx         = 8192
llama_context: n_ctx_per_seq = 2048
llama_context: n_batch       = 2048
llama_context: n_ubatch      = 512
llama_context: causal_attn   = 1
llama_context: flash_attn    = 0
llama_context: freq_base     = 1000000.0
llama_context: freq_scale    = 1
llama_context: n_ctx_per_seq (2048) < n_ctx_train (40960) -- the full capacity of the model will not be utilized
llama_context:        CPU  output buffer size =     2.36 MiB
init: kv_size = 8192, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 36, can_shift = 1
init:        CPU KV buffer size =  1152.00 MiB
llama_context: KV self size  = 1152.00 MiB, K (f16):  576.00 MiB, V (f16):  576.00 MiB
llama_context:        CPU compute buffer size =   554.01 MiB
llama_context: graph nodes  = 1374
llama_context: graph splits = 1
time=2025-05-05T21:52:12.354+01:00 level=INFO source=server.go:619 msg="llama runner started in 5.84 seconds"
[GIN] 2025/05/05 - 21:52:27 | 200 | 21.924751446s |       127.0.0.1 | POST     "/v1/chat/completions"
time=2025-05-05T21:52:27.977+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 21:52:35 | 200 |   14.736685ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:52:45 | 200 | 17.568583391s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 21:53:11 | 200 |   10.877397ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:53:47 | 200 |     9.24107ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:54:23 | 200 |    8.850898ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:54:59 | 200 |    8.660829ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:55:35 | 200 |    8.315492ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:56:11 | 200 |    8.898789ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T21:56:30.093+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 21:56:43 | 200 |  13.09650018s |       127.0.0.1 | POST     "/v1/chat/completions"
time=2025-05-05T21:56:43.169+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 21:56:47 | 200 |   10.758917ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:56:49 | 200 |    1.374581ms |       127.0.0.1 | HEAD     "/"
[GIN] 2025/05/05 - 21:56:49 | 200 |    6.196201ms |       127.0.0.1 | GET      "/api/ps"
[GIN] 2025/05/05 - 21:57:01 | 200 |  18.03472374s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 21:57:23 | 200 |   10.447726ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:57:59 | 200 |    8.715075ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:58:35 | 200 |    7.760351ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:59:11 | 200 |    7.322389ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 21:59:47 | 200 |    8.079074ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T21:59:57.409+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T21:59:57.476+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T21:59:57.542+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T21:59:57.543+01:00 level=WARN source=ggml.go:152 msg="key not found" key=gemma3.vision.block_count default=0
time=2025-05-05T21:59:57.546+01:00 level=INFO source=server.go:105 msg="system memory" total="16.0 GiB" free="5.9 GiB" free_swap="0 B"
time=2025-05-05T21:59:57.546+01:00 level=WARN source=ggml.go:152 msg="key not found" key=gemma3.vision.block_count default=0
time=2025-05-05T21:59:57.549+01:00 level=INFO source=server.go:138 msg=offload library=cpu layers.requested=-1 layers.model=27 layers.offload=0 layers.split="" memory.available="[5.9 GiB]" memory.gpu_overhead="0 B" memory.required.full="1.4 GiB" memory.required.partial="0 B" memory.required.kv="87.0 MiB" memory.required.allocations="[1.4 GiB]" memory.weights.total="762.5 MiB" memory.weights.repeating="456.5 MiB" memory.weights.nonrepeating="306.0 MiB" memory.graph.full="514.2 MiB" memory.graph.partial="750.5 MiB"
time=2025-05-05T21:59:57.549+01:00 level=WARN source=server.go:173 msg="flash attention enabled but not supported by gpu"
time=2025-05-05T21:59:57.724+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T21:59:57.749+01:00 level=WARN source=ggml.go:152 msg="key not found" key=tokenizer.ggml.add_eot_token default=false
time=2025-05-05T21:59:57.754+01:00 level=WARN source=ggml.go:152 msg="key not found" key=gemma3.vision.image_size default=0
time=2025-05-05T21:59:57.754+01:00 level=WARN source=ggml.go:152 msg="key not found" key=gemma3.vision.patch_size default=0
time=2025-05-05T21:59:57.754+01:00 level=WARN source=ggml.go:152 msg="key not found" key=gemma3.vision.num_channels default=0
time=2025-05-05T21:59:57.754+01:00 level=WARN source=ggml.go:152 msg="key not found" key=gemma3.vision.block_count default=0
time=2025-05-05T21:59:57.754+01:00 level=WARN source=ggml.go:152 msg="key not found" key=gemma3.vision.embedding_length default=0
time=2025-05-05T21:59:57.755+01:00 level=WARN source=ggml.go:152 msg="key not found" key=gemma3.vision.attention.head_count default=0
time=2025-05-05T21:59:57.755+01:00 level=WARN source=ggml.go:152 msg="key not found" key=gemma3.vision.image_size default=0
time=2025-05-05T21:59:57.755+01:00 level=WARN source=ggml.go:152 msg="key not found" key=gemma3.vision.patch_size default=0
time=2025-05-05T21:59:57.755+01:00 level=WARN source=ggml.go:152 msg="key not found" key=gemma3.vision.attention.layer_norm_epsilon default=0
time=2025-05-05T21:59:57.764+01:00 level=WARN source=ggml.go:152 msg="key not found" key=gemma3.rope.freq_scale default=1
time=2025-05-05T21:59:57.765+01:00 level=WARN source=ggml.go:152 msg="key not found" key=gemma3.mm_tokens_per_image default=256
time=2025-05-05T21:59:57.765+01:00 level=INFO source=server.go:405 msg="starting llama server" cmd="/Applications/Ollama.app/Contents/Resources/ollama runner --ollama-engine --model /Users/neidu/.ollama/models/blobs/sha256-7cd4618c1faf8b7233c6c906dac1694b6a47684b37b8895d470ac688520b9c01 --ctx-size 8192 --batch-size 512 --threads 6 --no-mmap --parallel 4 --port 52928"
time=2025-05-05T21:59:57.771+01:00 level=INFO source=sched.go:451 msg="loaded runners" count=2
time=2025-05-05T21:59:57.771+01:00 level=INFO source=server.go:580 msg="waiting for llama runner to start responding"
time=2025-05-05T21:59:57.772+01:00 level=INFO source=server.go:614 msg="waiting for server to become available" status="llm server error"
time=2025-05-05T21:59:57.818+01:00 level=INFO source=runner.go:866 msg="starting ollama engine"
time=2025-05-05T21:59:57.819+01:00 level=INFO source=runner.go:929 msg="Server listening on 127.0.0.1:52928"
time=2025-05-05T21:59:57.990+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T21:59:57.991+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.name default=""
time=2025-05-05T21:59:57.991+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.description default=""
time=2025-05-05T21:59:57.991+01:00 level=INFO source=ggml.go:72 msg="" architecture=gemma3 file_type=Q4_K_M name="" description="" num_tensors=340 num_key_values=32
time=2025-05-05T21:59:58.024+01:00 level=INFO source=server.go:614 msg="waiting for server to become available" status="llm server loading model"
load_backend: loaded CPU backend from /Applications/Ollama.app/Contents/Resources/libggml-cpu-haswell.so
time=2025-05-05T21:59:58.034+01:00 level=INFO source=ggml.go:109 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.LLAMAFILE=1 CPU.1.SSE3=1 CPU.1.SSSE3=1 CPU.1.LLAMAFILE=1 compiler=cgo(clang)
time=2025-05-05T21:59:58.037+01:00 level=INFO source=ggml.go:298 msg="model weights" buffer=CPU size="1.0 GiB"
time=2025-05-05T21:59:59.036+01:00 level=WARN source=ggml.go:152 msg="key not found" key=tokenizer.ggml.add_eot_token default=false
time=2025-05-05T21:59:59.041+01:00 level=WARN source=ggml.go:152 msg="key not found" key=gemma3.vision.image_size default=0
time=2025-05-05T21:59:59.041+01:00 level=WARN source=ggml.go:152 msg="key not found" key=gemma3.vision.patch_size default=0
time=2025-05-05T21:59:59.041+01:00 level=WARN source=ggml.go:152 msg="key not found" key=gemma3.vision.num_channels default=0
time=2025-05-05T21:59:59.041+01:00 level=WARN source=ggml.go:152 msg="key not found" key=gemma3.vision.block_count default=0
time=2025-05-05T21:59:59.041+01:00 level=WARN source=ggml.go:152 msg="key not found" key=gemma3.vision.embedding_length default=0
time=2025-05-05T21:59:59.041+01:00 level=WARN source=ggml.go:152 msg="key not found" key=gemma3.vision.attention.head_count default=0
time=2025-05-05T21:59:59.041+01:00 level=WARN source=ggml.go:152 msg="key not found" key=gemma3.vision.image_size default=0
time=2025-05-05T21:59:59.041+01:00 level=WARN source=ggml.go:152 msg="key not found" key=gemma3.vision.patch_size default=0
time=2025-05-05T21:59:59.041+01:00 level=WARN source=ggml.go:152 msg="key not found" key=gemma3.vision.attention.layer_norm_epsilon default=0
time=2025-05-05T21:59:59.048+01:00 level=WARN source=ggml.go:152 msg="key not found" key=gemma3.rope.freq_scale default=1
time=2025-05-05T21:59:59.048+01:00 level=WARN source=ggml.go:152 msg="key not found" key=gemma3.mm_tokens_per_image default=256
time=2025-05-05T21:59:59.196+01:00 level=INFO source=ggml.go:556 msg="compute graph" backend=CPU buffer_type=CPU size="68.2 MiB"
time=2025-05-05T21:59:59.279+01:00 level=INFO source=server.go:619 msg="llama runner started in 1.51 seconds"
[GIN] 2025/05/05 - 22:00:02 | 200 |  5.214526956s |       127.0.0.1 | POST     "/v1/chat/completions"
time=2025-05-05T22:00:07.775+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 22:00:13 | 200 |  5.460389732s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 22:00:23 | 200 |   10.916792ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T22:00:37.121+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 22:00:43 | 200 |  6.760526235s |       127.0.0.1 | POST     "/v1/chat/completions"
time=2025-05-05T22:00:43.874+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 22:00:57 | 200 |      40.799µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/05/05 - 22:00:57 | 200 |      62.084µs |       127.0.0.1 | GET      "/api/ps"
[GIN] 2025/05/05 - 22:00:59 | 200 |   12.145504ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:01:02 | 200 | 18.717097903s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 22:01:35 | 200 |   10.514499ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:01:40 | 200 |       22.73µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/05/05 - 22:01:40 | 200 |    7.016344ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T22:02:09.269+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T22:02:09.315+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T22:02:09.339+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T22:02:09.340+01:00 level=WARN source=ggml.go:152 msg="key not found" key=qwen2.vision.block_count default=0
time=2025-05-05T22:02:09.341+01:00 level=WARN source=ggml.go:152 msg="key not found" key=qwen2.attention.key_length default=128
time=2025-05-05T22:02:09.341+01:00 level=WARN source=ggml.go:152 msg="key not found" key=qwen2.attention.value_length default=128
time=2025-05-05T22:02:09.341+01:00 level=INFO source=server.go:105 msg="system memory" total="16.0 GiB" free="6.1 GiB" free_swap="0 B"
time=2025-05-05T22:02:09.341+01:00 level=WARN source=ggml.go:152 msg="key not found" key=qwen2.vision.block_count default=0
time=2025-05-05T22:02:09.342+01:00 level=WARN source=ggml.go:152 msg="key not found" key=qwen2.attention.key_length default=128
time=2025-05-05T22:02:09.342+01:00 level=WARN source=ggml.go:152 msg="key not found" key=qwen2.attention.value_length default=128
time=2025-05-05T22:02:09.342+01:00 level=INFO source=server.go:138 msg=offload library=cpu layers.requested=-1 layers.model=29 layers.offload=0 layers.split="" memory.available="[6.1 GiB]" memory.gpu_overhead="0 B" memory.required.full="1.5 GiB" memory.required.partial="0 B" memory.required.kv="224.0 MiB" memory.required.allocations="[1.5 GiB]" memory.weights.total="934.7 MiB" memory.weights.repeating="752.1 MiB" memory.weights.nonrepeating="182.6 MiB" memory.graph.full="299.8 MiB" memory.graph.partial="482.3 MiB"
time=2025-05-05T22:02:09.342+01:00 level=WARN source=server.go:173 msg="flash attention enabled but not supported by gpu"
llama_model_loader: loaded meta data with 26 key-value pairs and 339 tensors from /Users/neidu/.ollama/models/blobs/sha256-aabd4debf0c8f08881923f2c25fc0fdeed24435271c2b3e92c4af36704040dbc (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = qwen2
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = DeepSeek R1 Distill Qwen 1.5B
llama_model_loader: - kv   3:                           general.basename str              = DeepSeek-R1-Distill-Qwen
llama_model_loader: - kv   4:                         general.size_label str              = 1.5B
llama_model_loader: - kv   5:                          qwen2.block_count u32              = 28
llama_model_loader: - kv   6:                       qwen2.context_length u32              = 131072
llama_model_loader: - kv   7:                     qwen2.embedding_length u32              = 1536
llama_model_loader: - kv   8:                  qwen2.feed_forward_length u32              = 8960
llama_model_loader: - kv   9:                 qwen2.attention.head_count u32              = 12
llama_model_loader: - kv  10:              qwen2.attention.head_count_kv u32              = 2
llama_model_loader: - kv  11:                       qwen2.rope.freq_base f32              = 10000.000000
llama_model_loader: - kv  12:     qwen2.attention.layer_norm_rms_epsilon f32              = 0.000001
llama_model_loader: - kv  13:                          general.file_type u32              = 15
llama_model_loader: - kv  14:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  15:                         tokenizer.ggml.pre str              = qwen2
llama_model_loader: - kv  16:                      tokenizer.ggml.tokens arr[str,151936]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  17:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  18:                      tokenizer.ggml.merges arr[str,151387]  = ["Ġ Ġ", "ĠĠ ĠĠ", "i n", "Ġ t",...
llama_model_loader: - kv  19:                tokenizer.ggml.bos_token_id u32              = 151646
llama_model_loader: - kv  20:                tokenizer.ggml.eos_token_id u32              = 151643
llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 151643
llama_model_loader: - kv  22:               tokenizer.ggml.add_bos_token bool             = true
llama_model_loader: - kv  23:               tokenizer.ggml.add_eos_token bool             = false
llama_model_loader: - kv  24:                    tokenizer.chat_template str              = {% if not add_generation_prompt is de...
llama_model_loader: - kv  25:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:  141 tensors
llama_model_loader: - type q4_K:  169 tensors
llama_model_loader: - type q6_K:   29 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 1.04 GiB (5.00 BPW) 
load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect
load: special tokens cache size = 22
load: token to piece cache size = 0.9310 MB
print_info: arch             = qwen2
print_info: vocab_only       = 1
print_info: model type       = ?B
print_info: model params     = 1.78 B
print_info: general.name     = DeepSeek R1 Distill Qwen 1.5B
print_info: vocab type       = BPE
print_info: n_vocab          = 151936
print_info: n_merges         = 151387
print_info: BOS token        = 151646 '<｜begin▁of▁sentence｜>'
print_info: EOS token        = 151643 '<｜end▁of▁sentence｜>'
print_info: EOT token        = 151643 '<｜end▁of▁sentence｜>'
print_info: PAD token        = 151643 '<｜end▁of▁sentence｜>'
print_info: LF token         = 198 'Ċ'
print_info: FIM PRE token    = 151659 '<|fim_prefix|>'
print_info: FIM SUF token    = 151661 '<|fim_suffix|>'
print_info: FIM MID token    = 151660 '<|fim_middle|>'
print_info: FIM PAD token    = 151662 '<|fim_pad|>'
print_info: FIM REP token    = 151663 '<|repo_name|>'
print_info: FIM SEP token    = 151664 '<|file_sep|>'
print_info: EOG token        = 151643 '<｜end▁of▁sentence｜>'
print_info: EOG token        = 151662 '<|fim_pad|>'
print_info: EOG token        = 151663 '<|repo_name|>'
print_info: EOG token        = 151664 '<|file_sep|>'
print_info: max token length = 256
llama_model_load: vocab only - skipping tensors
time=2025-05-05T22:02:09.761+01:00 level=INFO source=server.go:405 msg="starting llama server" cmd="/Applications/Ollama.app/Contents/Resources/ollama runner --model /Users/neidu/.ollama/models/blobs/sha256-aabd4debf0c8f08881923f2c25fc0fdeed24435271c2b3e92c4af36704040dbc --ctx-size 8192 --batch-size 512 --threads 6 --no-mmap --parallel 4 --port 54597"
time=2025-05-05T22:02:09.767+01:00 level=INFO source=sched.go:451 msg="loaded runners" count=3
time=2025-05-05T22:02:09.767+01:00 level=INFO source=server.go:580 msg="waiting for llama runner to start responding"
time=2025-05-05T22:02:09.768+01:00 level=INFO source=server.go:614 msg="waiting for server to become available" status="llm server error"
time=2025-05-05T22:02:09.804+01:00 level=INFO source=runner.go:853 msg="starting go runner"
load_backend: loaded CPU backend from /Applications/Ollama.app/Contents/Resources/libggml-cpu-haswell.so
time=2025-05-05T22:02:09.834+01:00 level=INFO source=ggml.go:109 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.LLAMAFILE=1 CPU.1.SSE3=1 CPU.1.SSSE3=1 CPU.1.LLAMAFILE=1 compiler=cgo(clang)
time=2025-05-05T22:02:09.834+01:00 level=INFO source=runner.go:913 msg="Server listening on 127.0.0.1:54597"
llama_model_loader: loaded meta data with 26 key-value pairs and 339 tensors from /Users/neidu/.ollama/models/blobs/sha256-aabd4debf0c8f08881923f2c25fc0fdeed24435271c2b3e92c4af36704040dbc (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = qwen2
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = DeepSeek R1 Distill Qwen 1.5B
llama_model_loader: - kv   3:                           general.basename str              = DeepSeek-R1-Distill-Qwen
llama_model_loader: - kv   4:                         general.size_label str              = 1.5B
llama_model_loader: - kv   5:                          qwen2.block_count u32              = 28
llama_model_loader: - kv   6:                       qwen2.context_length u32              = 131072
llama_model_loader: - kv   7:                     qwen2.embedding_length u32              = 1536
llama_model_loader: - kv   8:                  qwen2.feed_forward_length u32              = 8960
llama_model_loader: - kv   9:                 qwen2.attention.head_count u32              = 12
llama_model_loader: - kv  10:              qwen2.attention.head_count_kv u32              = 2
llama_model_loader: - kv  11:                       qwen2.rope.freq_base f32              = 10000.000000
llama_model_loader: - kv  12:     qwen2.attention.layer_norm_rms_epsilon f32              = 0.000001
llama_model_loader: - kv  13:                          general.file_type u32              = 15
llama_model_loader: - kv  14:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  15:                         tokenizer.ggml.pre str              = qwen2
llama_model_loader: - kv  16:                      tokenizer.ggml.tokens arr[str,151936]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  17:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  18:                      tokenizer.ggml.merges arr[str,151387]  = ["Ġ Ġ", "ĠĠ ĠĠ", "i n", "Ġ t",...
llama_model_loader: - kv  19:                tokenizer.ggml.bos_token_id u32              = 151646
llama_model_loader: - kv  20:                tokenizer.ggml.eos_token_id u32              = 151643
llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 151643
llama_model_loader: - kv  22:               tokenizer.ggml.add_bos_token bool             = true
llama_model_loader: - kv  23:               tokenizer.ggml.add_eos_token bool             = false
llama_model_loader: - kv  24:                    tokenizer.chat_template str              = {% if not add_generation_prompt is de...
llama_model_loader: - kv  25:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:  141 tensors
llama_model_loader: - type q4_K:  169 tensors
llama_model_loader: - type q6_K:   29 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 1.04 GiB (5.00 BPW) 
time=2025-05-05T22:02:10.020+01:00 level=INFO source=server.go:614 msg="waiting for server to become available" status="llm server loading model"
load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect
load: special tokens cache size = 22
load: token to piece cache size = 0.9310 MB
print_info: arch             = qwen2
print_info: vocab_only       = 0
print_info: n_ctx_train      = 131072
print_info: n_embd           = 1536
print_info: n_layer          = 28
print_info: n_head           = 12
print_info: n_head_kv        = 2
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa_pattern    = 1
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 6
print_info: n_embd_k_gqa     = 256
print_info: n_embd_v_gqa     = 256
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-06
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 8960
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: rope type        = 2
print_info: rope scaling     = linear
print_info: freq_base_train  = 10000.0
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 131072
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = 1.5B
print_info: model params     = 1.78 B
print_info: general.name     = DeepSeek R1 Distill Qwen 1.5B
print_info: vocab type       = BPE
print_info: n_vocab          = 151936
print_info: n_merges         = 151387
print_info: BOS token        = 151646 '<｜begin▁of▁sentence｜>'
print_info: EOS token        = 151643 '<｜end▁of▁sentence｜>'
print_info: EOT token        = 151643 '<｜end▁of▁sentence｜>'
print_info: PAD token        = 151643 '<｜end▁of▁sentence｜>'
print_info: LF token         = 198 'Ċ'
print_info: FIM PRE token    = 151659 '<|fim_prefix|>'
print_info: FIM SUF token    = 151661 '<|fim_suffix|>'
print_info: FIM MID token    = 151660 '<|fim_middle|>'
print_info: FIM PAD token    = 151662 '<|fim_pad|>'
print_info: FIM REP token    = 151663 '<|repo_name|>'
print_info: FIM SEP token    = 151664 '<|file_sep|>'
print_info: EOG token        = 151643 '<｜end▁of▁sentence｜>'
print_info: EOG token        = 151662 '<|fim_pad|>'
print_info: EOG token        = 151663 '<|repo_name|>'
print_info: EOG token        = 151664 '<|file_sep|>'
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = false)
load_tensors:          CPU model buffer size =  1059.89 MiB
[GIN] 2025/05/05 - 22:02:11 | 200 |   19.711009ms |       127.0.0.1 | GET      "/api/tags"
llama_context: constructing llama_context
llama_context: n_seq_max     = 4
llama_context: n_ctx         = 8192
llama_context: n_ctx_per_seq = 2048
llama_context: n_batch       = 2048
llama_context: n_ubatch      = 512
llama_context: causal_attn   = 1
llama_context: flash_attn    = 0
llama_context: freq_base     = 10000.0
llama_context: freq_scale    = 1
llama_context: n_ctx_per_seq (2048) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_context:        CPU  output buffer size =     2.34 MiB
init: kv_size = 8192, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1
init:        CPU KV buffer size =   224.00 MiB
llama_context: KV self size  =  224.00 MiB, K (f16):  112.00 MiB, V (f16):  112.00 MiB
llama_context:        CPU compute buffer size =   302.75 MiB
llama_context: graph nodes  = 1042
llama_context: graph splits = 1
time=2025-05-05T22:02:13.062+01:00 level=INFO source=server.go:619 msg="llama runner started in 3.29 seconds"
[GIN] 2025/05/05 - 22:02:47 | 200 |    16.44822ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:03:21 | 200 |         1m12s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 22:03:23 | 200 |   10.435103ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:03:59 | 200 |   13.651893ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:04:35 | 200 |   14.903404ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:05:11 | 200 |    7.948666ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:05:47 | 200 |   13.880943ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T22:06:00.434+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 22:06:23 | 200 | 23.139113807s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 22:06:23 | 200 |   11.181439ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T22:06:40.100+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 22:06:59 | 200 |      81.091µs |       127.0.0.1 | GET      "/"
[GIN] 2025/05/05 - 22:06:59 | 200 |   29.260497ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:06:59 | 200 |    17.57089ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:06:59 | 200 |   13.122473ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:07:03 | 200 | 23.440690996s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 22:07:07 | 200 |      54.804µs |       127.0.0.1 | GET      "/"
[GIN] 2025/05/05 - 22:07:07 | 200 |    12.71797ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:07:07 | 200 |    12.27593ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T22:07:21.463+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 22:07:33 | 200 |   25.081823ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:07:33 | 200 |   16.910523ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:07:35 | 200 |   11.234219ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:07:44 | 200 |  22.90199498s |       127.0.0.1 | POST     "/api/chat"
time=2025-05-05T22:07:44.401+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 22:08:11 | 200 |   12.061382ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T22:08:46.048+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T22:08:46.250+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T22:08:46.288+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T22:08:46.290+01:00 level=WARN source=ggml.go:152 msg="key not found" key=qwen3.vision.block_count default=0
time=2025-05-05T22:08:46.291+01:00 level=INFO source=server.go:105 msg="system memory" total="16.0 GiB" free="6.6 GiB" free_swap="0 B"
time=2025-05-05T22:08:46.291+01:00 level=WARN source=ggml.go:152 msg="key not found" key=qwen3.vision.block_count default=0
time=2025-05-05T22:08:46.292+01:00 level=INFO source=server.go:138 msg=offload library=cpu layers.requested=-1 layers.model=37 layers.offload=0 layers.split="" memory.available="[6.6 GiB]" memory.gpu_overhead="0 B" memory.required.full="6.6 GiB" memory.required.partial="0 B" memory.required.kv="1.1 GiB" memory.required.allocations="[6.6 GiB]" memory.weights.total="4.5 GiB" memory.weights.repeating="4.1 GiB" memory.weights.nonrepeating="486.9 MiB" memory.graph.full="768.0 MiB" memory.graph.partial="768.0 MiB"
time=2025-05-05T22:08:46.292+01:00 level=WARN source=server.go:173 msg="flash attention enabled but not supported by gpu"
llama_model_loader: loaded meta data with 28 key-value pairs and 399 tensors from /Users/neidu/.ollama/models/blobs/sha256-a3de86cd1c132c822487ededd47a324c50491393e6565cd14bafa40d0b8e686f (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = qwen3
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Qwen3 8B
llama_model_loader: - kv   3:                           general.basename str              = Qwen3
llama_model_loader: - kv   4:                         general.size_label str              = 8B
llama_model_loader: - kv   5:                            general.license str              = apache-2.0
llama_model_loader: - kv   6:                          qwen3.block_count u32              = 36
llama_model_loader: - kv   7:                       qwen3.context_length u32              = 40960
llama_model_loader: - kv   8:                     qwen3.embedding_length u32              = 4096
llama_model_loader: - kv   9:                  qwen3.feed_forward_length u32              = 12288
llama_model_loader: - kv  10:                 qwen3.attention.head_count u32              = 32
llama_model_loader: - kv  11:              qwen3.attention.head_count_kv u32              = 8
llama_model_loader: - kv  12:                       qwen3.rope.freq_base f32              = 1000000.000000
llama_model_loader: - kv  13:     qwen3.attention.layer_norm_rms_epsilon f32              = 0.000001
llama_model_loader: - kv  14:                 qwen3.attention.key_length u32              = 128
llama_model_loader: - kv  15:               qwen3.attention.value_length u32              = 128
llama_model_loader: - kv  16:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  17:                         tokenizer.ggml.pre str              = qwen2
llama_model_loader: - kv  18:                      tokenizer.ggml.tokens arr[str,151936]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  19:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  20:                      tokenizer.ggml.merges arr[str,151387]  = ["Ġ Ġ", "ĠĠ ĠĠ", "i n", "Ġ t",...
llama_model_loader: - kv  21:                tokenizer.ggml.eos_token_id u32              = 151645
llama_model_loader: - kv  22:            tokenizer.ggml.padding_token_id u32              = 151643
llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 151643
llama_model_loader: - kv  24:               tokenizer.ggml.add_bos_token bool             = false
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {%- if tools %}\n    {{- '<|im_start|>...
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - kv  27:                          general.file_type u32              = 15
llama_model_loader: - type  f32:  145 tensors
llama_model_loader: - type  f16:   36 tensors
llama_model_loader: - type q4_K:  199 tensors
llama_model_loader: - type q6_K:   19 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 4.86 GiB (5.10 BPW) 
load: special tokens cache size = 26
load: token to piece cache size = 0.9311 MB
print_info: arch             = qwen3
print_info: vocab_only       = 1
print_info: model type       = ?B
print_info: model params     = 8.19 B
print_info: general.name     = Qwen3 8B
print_info: vocab type       = BPE
print_info: n_vocab          = 151936
print_info: n_merges         = 151387
print_info: BOS token        = 151643 '<|endoftext|>'
print_info: EOS token        = 151645 '<|im_end|>'
print_info: EOT token        = 151645 '<|im_end|>'
print_info: PAD token        = 151643 '<|endoftext|>'
print_info: LF token         = 198 'Ċ'
print_info: FIM PRE token    = 151659 '<|fim_prefix|>'
print_info: FIM SUF token    = 151661 '<|fim_suffix|>'
print_info: FIM MID token    = 151660 '<|fim_middle|>'
print_info: FIM PAD token    = 151662 '<|fim_pad|>'
print_info: FIM REP token    = 151663 '<|repo_name|>'
print_info: FIM SEP token    = 151664 '<|file_sep|>'
print_info: EOG token        = 151643 '<|endoftext|>'
print_info: EOG token        = 151645 '<|im_end|>'
print_info: EOG token        = 151662 '<|fim_pad|>'
print_info: EOG token        = 151663 '<|repo_name|>'
print_info: EOG token        = 151664 '<|file_sep|>'
print_info: max token length = 256
llama_model_load: vocab only - skipping tensors
time=2025-05-05T22:08:46.869+01:00 level=INFO source=server.go:405 msg="starting llama server" cmd="/Applications/Ollama.app/Contents/Resources/ollama runner --model /Users/neidu/.ollama/models/blobs/sha256-a3de86cd1c132c822487ededd47a324c50491393e6565cd14bafa40d0b8e686f --ctx-size 8192 --batch-size 512 --threads 6 --no-mmap --parallel 4 --port 59470"
time=2025-05-05T22:08:46.880+01:00 level=INFO source=sched.go:451 msg="loaded runners" count=3
time=2025-05-05T22:08:46.880+01:00 level=INFO source=server.go:580 msg="waiting for llama runner to start responding"
time=2025-05-05T22:08:46.881+01:00 level=INFO source=server.go:614 msg="waiting for server to become available" status="llm server error"
time=2025-05-05T22:08:46.927+01:00 level=INFO source=runner.go:853 msg="starting go runner"
load_backend: loaded CPU backend from /Applications/Ollama.app/Contents/Resources/libggml-cpu-haswell.so
time=2025-05-05T22:08:46.984+01:00 level=INFO source=ggml.go:109 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.LLAMAFILE=1 CPU.1.SSE3=1 CPU.1.SSSE3=1 CPU.1.LLAMAFILE=1 compiler=cgo(clang)
time=2025-05-05T22:08:46.985+01:00 level=INFO source=runner.go:913 msg="Server listening on 127.0.0.1:59470"
llama_model_loader: loaded meta data with 28 key-value pairs and 399 tensors from /Users/neidu/.ollama/models/blobs/sha256-a3de86cd1c132c822487ededd47a324c50491393e6565cd14bafa40d0b8e686f (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = qwen3
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Qwen3 8B
llama_model_loader: - kv   3:                           general.basename str              = Qwen3
llama_model_loader: - kv   4:                         general.size_label str              = 8B
llama_model_loader: - kv   5:                            general.license str              = apache-2.0
llama_model_loader: - kv   6:                          qwen3.block_count u32              = 36
llama_model_loader: - kv   7:                       qwen3.context_length u32              = 40960
llama_model_loader: - kv   8:                     qwen3.embedding_length u32              = 4096
llama_model_loader: - kv   9:                  qwen3.feed_forward_length u32              = 12288
llama_model_loader: - kv  10:                 qwen3.attention.head_count u32              = 32
llama_model_loader: - kv  11:              qwen3.attention.head_count_kv u32              = 8
llama_model_loader: - kv  12:                       qwen3.rope.freq_base f32              = 1000000.000000
llama_model_loader: - kv  13:     qwen3.attention.layer_norm_rms_epsilon f32              = 0.000001
llama_model_loader: - kv  14:                 qwen3.attention.key_length u32              = 128
llama_model_loader: - kv  15:               qwen3.attention.value_length u32              = 128
llama_model_loader: - kv  16:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  17:                         tokenizer.ggml.pre str              = qwen2
llama_model_loader: - kv  18:                      tokenizer.ggml.tokens arr[str,151936]  = ["!", "\"", "#", "$", "%", "&", "'", ...
time=2025-05-05T22:08:47.133+01:00 level=INFO source=server.go:614 msg="waiting for server to become available" status="llm server loading model"
llama_model_loader: - kv  19:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  20:                      tokenizer.ggml.merges arr[str,151387]  = ["Ġ Ġ", "ĠĠ ĠĠ", "i n", "Ġ t",...
llama_model_loader: - kv  21:                tokenizer.ggml.eos_token_id u32              = 151645
llama_model_loader: - kv  22:            tokenizer.ggml.padding_token_id u32              = 151643
llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 151643
llama_model_loader: - kv  24:               tokenizer.ggml.add_bos_token bool             = false
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {%- if tools %}\n    {{- '<|im_start|>...
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - kv  27:                          general.file_type u32              = 15
llama_model_loader: - type  f32:  145 tensors
llama_model_loader: - type  f16:   36 tensors
llama_model_loader: - type q4_K:  199 tensors
llama_model_loader: - type q6_K:   19 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 4.86 GiB (5.10 BPW) 
load: special tokens cache size = 26
load: token to piece cache size = 0.9311 MB
print_info: arch             = qwen3
print_info: vocab_only       = 0
print_info: n_ctx_train      = 40960
print_info: n_embd           = 4096
print_info: n_layer          = 36
print_info: n_head           = 32
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa_pattern    = 1
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 4
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-06
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 12288
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: rope type        = 2
print_info: rope scaling     = linear
print_info: freq_base_train  = 1000000.0
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 40960
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = ?B
print_info: model params     = 8.19 B
print_info: general.name     = Qwen3 8B
print_info: vocab type       = BPE
print_info: n_vocab          = 151936
print_info: n_merges         = 151387
print_info: BOS token        = 151643 '<|endoftext|>'
print_info: EOS token        = 151645 '<|im_end|>'
print_info: EOT token        = 151645 '<|im_end|>'
print_info: PAD token        = 151643 '<|endoftext|>'
print_info: LF token         = 198 'Ċ'
print_info: FIM PRE token    = 151659 '<|fim_prefix|>'
print_info: FIM SUF token    = 151661 '<|fim_suffix|>'
print_info: FIM MID token    = 151660 '<|fim_middle|>'
print_info: FIM PAD token    = 151662 '<|fim_pad|>'
print_info: FIM REP token    = 151663 '<|repo_name|>'
print_info: FIM SEP token    = 151664 '<|file_sep|>'
print_info: EOG token        = 151643 '<|endoftext|>'
print_info: EOG token        = 151645 '<|im_end|>'
print_info: EOG token        = 151662 '<|fim_pad|>'
print_info: EOG token        = 151663 '<|repo_name|>'
print_info: EOG token        = 151664 '<|file_sep|>'
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = false)
load_tensors:          CPU model buffer size =  4977.62 MiB
[GIN] 2025/05/05 - 22:08:47 | 200 |    12.39249ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:08:48 | 200 |   15.261516ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:08:48 | 200 |   21.620318ms |       127.0.0.1 | GET      "/api/tags"
llama_context: constructing llama_context
llama_context: n_seq_max     = 4
llama_context: n_ctx         = 8192
llama_context: n_ctx_per_seq = 2048
llama_context: n_batch       = 2048
llama_context: n_ubatch      = 512
llama_context: causal_attn   = 1
llama_context: flash_attn    = 0
llama_context: freq_base     = 1000000.0
llama_context: freq_scale    = 1
llama_context: n_ctx_per_seq (2048) < n_ctx_train (40960) -- the full capacity of the model will not be utilized
llama_context:        CPU  output buffer size =     2.38 MiB
init: kv_size = 8192, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 36, can_shift = 1
init:        CPU KV buffer size =  1152.00 MiB
llama_context: KV self size  = 1152.00 MiB, K (f16):  576.00 MiB, V (f16):  576.00 MiB
llama_context:        CPU compute buffer size =   560.01 MiB
llama_context: graph nodes  = 1374
llama_context: graph splits = 1
time=2025-05-05T22:09:02.250+01:00 level=INFO source=server.go:619 msg="llama runner started in 15.37 seconds"
[GIN] 2025/05/05 - 22:09:02 | 200 |         1m18s |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/05/05 - 22:09:04 | 200 |      69.255µs |       127.0.0.1 | GET      "/"
[GIN] 2025/05/05 - 22:09:04 | 200 |    34.89501ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:09:04 | 200 |   19.571864ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:09:22 | 200 |      46.763µs |       127.0.0.1 | GET      "/"
[GIN] 2025/05/05 - 22:09:22 | 200 |   94.308268ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:09:22 | 200 |   28.673535ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:09:23 | 200 |   16.706829ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T22:09:34.034+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 22:09:45 | 200 | 59.442329423s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 22:09:59 | 200 |     32.9272ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T22:10:08.027+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 22:10:10 | 200 |   25.642121ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:10:10 | 200 |   16.883689ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:10:21 | 200 | 47.795614779s |       127.0.0.1 | POST     "/api/chat"
time=2025-05-05T22:10:21.893+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 22:10:35 | 200 |   13.335692ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:10:49 | 200 | 41.182300806s |       127.0.0.1 | POST     "/v1/chat/completions"
time=2025-05-05T22:10:49.276+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 22:11:11 | 200 |   20.369992ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:11:39 | 200 |      68.274µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/05/05 - 22:11:39 | 200 |      74.787µs |       127.0.0.1 | GET      "/api/ps"
[GIN] 2025/05/05 - 22:11:47 | 200 |   26.975111ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:11:52 | 200 |      33.736µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/05/05 - 22:11:52 | 200 |   15.239741ms |       127.0.0.1 | POST     "/api/generate"
[GIN] 2025/05/05 - 22:11:57 | 200 |      30.875µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/05/05 - 22:11:57 | 200 |      31.556µs |       127.0.0.1 | GET      "/api/ps"
[GIN] 2025/05/05 - 22:12:00 | 200 |  115.805064ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:12:00 | 200 |    11.67536ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:12:10 | 200 |         1m20s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 22:12:23 | 200 |   24.878027ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:12:34 | 200 |         2m12s |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/05/05 - 22:12:59 | 200 |   21.923175ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:13:35 | 200 |   14.499268ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:13:39 | 200 |   14.988499ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:13:39 | 200 |   13.230099ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:14:11 | 200 |   20.033441ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T22:14:17.335+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 22:14:47 | 200 |   19.231117ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:15:23 | 200 |   12.356743ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:15:59 | 200 |   11.924258ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:16:32 | 200 |         2m15s |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/05/05 - 22:16:35 | 200 |   26.998987ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:16:54 | 200 |   15.000176ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:16:54 | 200 |   12.600865ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:17:11 | 200 |    8.437586ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T22:17:14.950+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 22:17:47 | 200 |   23.337128ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:18:23 | 200 |          1m8s |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/05/05 - 22:18:23 | 200 |   15.746546ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T22:18:32.255+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 22:18:59 | 200 |   14.098523ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:19:15 | 200 | 43.220412724s |       127.0.0.1 | POST     "/api/chat"
time=2025-05-05T22:19:30.751+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 22:19:35 | 200 |   12.981288ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:20:11 | 200 |   12.293387ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:20:47 | 200 |   10.851133ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:20:48 | 200 |         1m17s |       127.0.0.1 | POST     "/api/chat"
time=2025-05-05T22:21:14.712+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 22:21:23 | 200 |   15.104998ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:21:59 | 200 |   53.261682ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:22:35 | 200 |   17.098083ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:23:11 | 200 |   16.203738ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:23:17 | 200 |   21.997412ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:23:17 | 200 |   24.274338ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:23:47 | 200 |   26.550858ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:24:23 | 200 |    11.14207ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:24:59 | 200 |   16.166253ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:25:35 | 200 |   14.216817ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:26:09 | 200 |   16.717694ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:26:09 | 200 |   22.097979ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:26:11 | 200 |   10.758771ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:26:47 | 200 |   15.034808ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:27:23 | 200 |    12.74447ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:27:59 | 200 |   23.671897ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:28:35 | 200 |   11.763994ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:29:02 | 200 |   21.246798ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:29:02 | 200 |   17.807287ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:29:11 | 200 |   11.234461ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:29:47 | 200 |   11.689216ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:30:23 | 200 |   11.472278ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:30:29 | 200 |   12.956475ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:30:29 | 200 |   11.165978ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:30:59 | 200 |   13.888305ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:31:35 | 200 |   12.272942ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:32:11 | 200 |   12.593249ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:32:36 | 200 |   40.013027ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:32:36 | 200 |   27.518812ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:32:47 | 200 |   16.569381ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:33:23 | 200 |   28.102355ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:33:59 | 200 |   34.208303ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:34:35 | 200 |   12.345471ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:35:11 | 200 |   16.677368ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:35:47 | 200 |   11.491798ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:36:23 | 200 |   20.659463ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:36:36 | 200 |   17.408809ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:36:36 | 200 |   18.126333ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:36:59 | 200 |   12.071764ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:37:21 | 200 |       55.41µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/05/05 - 22:37:21 | 200 |      35.401µs |       127.0.0.1 | GET      "/api/ps"
[GIN] 2025/05/05 - 22:37:35 | 200 |   17.013274ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:38:11 | 200 |   23.810554ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:38:47 | 200 |   13.065125ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:39:23 | 200 |   19.614019ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:39:59 | 200 |   12.661244ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:40:35 | 200 |   11.442035ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:41:11 | 200 |   17.977328ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:41:47 | 200 |   27.737149ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:42:23 | 200 |   17.255163ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:42:59 | 200 |    10.56928ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:43:35 | 200 |   17.688023ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:43:46 | 200 |    13.33772ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:43:46 | 200 |   13.769111ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:44:11 | 200 |   19.928311ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:44:47 | 200 |   11.048726ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:45:23 | 200 |   12.184173ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:45:59 | 200 |   12.229148ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:46:35 | 200 |   17.529671ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:47:11 | 200 |   11.426537ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:47:47 | 200 |   15.124007ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:48:23 | 200 |   12.239765ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:48:59 | 200 |   18.397944ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:49:35 | 200 |   12.054485ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:50:11 | 200 |   39.147574ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:50:47 | 200 |   11.949427ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:51:23 | 200 |   12.120543ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:51:59 | 200 |    10.96752ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:52:35 | 200 |   13.080404ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:53:11 | 200 |   11.709263ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:53:47 | 200 |    16.89903ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:54:23 | 200 |   10.420379ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:54:59 | 200 |   11.798838ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:55:35 | 200 |   10.547627ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:56:11 | 200 |   19.141823ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:56:47 | 200 |   11.563332ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:57:23 | 200 |   19.235337ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:57:59 | 200 |      11.396ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:58:32 | 200 |   18.698575ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:58:32 | 200 |   24.332179ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:58:35 | 200 |   11.655508ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:58:37 | 200 |        37m22s |       127.0.0.1 | POST     "/api/chat"
time=2025-05-05T22:59:03.272+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 22:59:11 | 200 |   13.333638ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 22:59:31 | 200 | 28.203884084s |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/05/05 - 22:59:47 | 200 |   10.827539ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:00:23 | 200 |    19.29307ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:00:59 | 200 |    7.869152ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:01:35 | 200 |    7.865945ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:02:11 | 200 |    8.112402ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:02:47 | 200 |    8.827242ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:03:23 | 200 |    14.07704ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:03:59 | 200 |    9.249456ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:04:36 | 200 |   12.922804ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:05:12 | 200 |    14.62175ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:05:41 | 200 |   16.126846ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:05:41 | 200 |   10.697163ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:05:48 | 200 |     8.72371ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T23:06:01.764+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 23:06:24 | 200 |   12.055907ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:06:34 | 200 | 33.051487765s |       127.0.0.1 | POST     "/api/chat"
time=2025-05-05T23:06:48.448+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 23:07:00 | 200 |   17.004787ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:07:36 | 200 |    13.84722ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:07:49 | 200 |          1m1s |       127.0.0.1 | POST     "/api/chat"
time=2025-05-05T23:08:10.553+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 23:08:12 | 200 |   10.071272ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:08:48 | 200 |   13.699859ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:09:24 | 200 |   11.478216ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:09:45 | 200 |         1m35s |       127.0.0.1 | POST     "/api/chat"
time=2025-05-05T23:09:56.112+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 23:10:00 | 200 |   10.814568ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:10:36 | 200 |    11.14261ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:11:00 | 200 |          1m4s |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/05/05 - 23:11:12 | 200 |   17.224922ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T23:11:15.563+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 23:11:48 | 200 |    19.90887ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:12:22 | 200 |          1m7s |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/05/05 - 23:12:24 | 200 |     7.78719ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T23:12:47.291+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 23:13:00 | 200 |   17.796436ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:13:36 | 200 |   23.728292ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:14:04 | 200 |         1m16s |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/05/05 - 23:14:12 | 200 |    13.67233ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:14:48 | 200 |    7.841706ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:15:24 | 200 |   20.086698ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T23:15:52.153+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T23:15:52.178+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T23:15:52.204+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T23:15:52.206+01:00 level=WARN source=ggml.go:152 msg="key not found" key=qwen3.vision.block_count default=0
time=2025-05-05T23:15:52.698+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T23:15:52.722+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T23:15:52.724+01:00 level=INFO source=server.go:105 msg="system memory" total="16.0 GiB" free="7.5 GiB" free_swap="0 B"
time=2025-05-05T23:15:52.724+01:00 level=WARN source=ggml.go:152 msg="key not found" key=qwen3.vision.block_count default=0
time=2025-05-05T23:15:52.725+01:00 level=INFO source=server.go:138 msg=offload library=cpu layers.requested=-1 layers.model=37 layers.offload=0 layers.split="" memory.available="[7.5 GiB]" memory.gpu_overhead="0 B" memory.required.full="6.6 GiB" memory.required.partial="0 B" memory.required.kv="1.1 GiB" memory.required.allocations="[6.6 GiB]" memory.weights.total="4.5 GiB" memory.weights.repeating="4.1 GiB" memory.weights.nonrepeating="486.9 MiB" memory.graph.full="768.0 MiB" memory.graph.partial="768.0 MiB"
time=2025-05-05T23:15:52.725+01:00 level=WARN source=server.go:173 msg="flash attention enabled but not supported by gpu"
llama_model_loader: loaded meta data with 28 key-value pairs and 399 tensors from /Users/neidu/.ollama/models/blobs/sha256-a3de86cd1c132c822487ededd47a324c50491393e6565cd14bafa40d0b8e686f (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = qwen3
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Qwen3 8B
llama_model_loader: - kv   3:                           general.basename str              = Qwen3
llama_model_loader: - kv   4:                         general.size_label str              = 8B
llama_model_loader: - kv   5:                            general.license str              = apache-2.0
llama_model_loader: - kv   6:                          qwen3.block_count u32              = 36
llama_model_loader: - kv   7:                       qwen3.context_length u32              = 40960
llama_model_loader: - kv   8:                     qwen3.embedding_length u32              = 4096
llama_model_loader: - kv   9:                  qwen3.feed_forward_length u32              = 12288
llama_model_loader: - kv  10:                 qwen3.attention.head_count u32              = 32
llama_model_loader: - kv  11:              qwen3.attention.head_count_kv u32              = 8
llama_model_loader: - kv  12:                       qwen3.rope.freq_base f32              = 1000000.000000
llama_model_loader: - kv  13:     qwen3.attention.layer_norm_rms_epsilon f32              = 0.000001
llama_model_loader: - kv  14:                 qwen3.attention.key_length u32              = 128
llama_model_loader: - kv  15:               qwen3.attention.value_length u32              = 128
llama_model_loader: - kv  16:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  17:                         tokenizer.ggml.pre str              = qwen2
llama_model_loader: - kv  18:                      tokenizer.ggml.tokens arr[str,151936]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  19:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  20:                      tokenizer.ggml.merges arr[str,151387]  = ["Ġ Ġ", "ĠĠ ĠĠ", "i n", "Ġ t",...
llama_model_loader: - kv  21:                tokenizer.ggml.eos_token_id u32              = 151645
llama_model_loader: - kv  22:            tokenizer.ggml.padding_token_id u32              = 151643
llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 151643
llama_model_loader: - kv  24:               tokenizer.ggml.add_bos_token bool             = false
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {%- if tools %}\n    {{- '<|im_start|>...
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - kv  27:                          general.file_type u32              = 15
llama_model_loader: - type  f32:  145 tensors
llama_model_loader: - type  f16:   36 tensors
llama_model_loader: - type q4_K:  199 tensors
llama_model_loader: - type q6_K:   19 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 4.86 GiB (5.10 BPW) 
load: special tokens cache size = 26
load: token to piece cache size = 0.9311 MB
print_info: arch             = qwen3
print_info: vocab_only       = 1
print_info: model type       = ?B
print_info: model params     = 8.19 B
print_info: general.name     = Qwen3 8B
print_info: vocab type       = BPE
print_info: n_vocab          = 151936
print_info: n_merges         = 151387
print_info: BOS token        = 151643 '<|endoftext|>'
print_info: EOS token        = 151645 '<|im_end|>'
print_info: EOT token        = 151645 '<|im_end|>'
print_info: PAD token        = 151643 '<|endoftext|>'
print_info: LF token         = 198 'Ċ'
print_info: FIM PRE token    = 151659 '<|fim_prefix|>'
print_info: FIM SUF token    = 151661 '<|fim_suffix|>'
print_info: FIM MID token    = 151660 '<|fim_middle|>'
print_info: FIM PAD token    = 151662 '<|fim_pad|>'
print_info: FIM REP token    = 151663 '<|repo_name|>'
print_info: FIM SEP token    = 151664 '<|file_sep|>'
print_info: EOG token        = 151643 '<|endoftext|>'
print_info: EOG token        = 151645 '<|im_end|>'
print_info: EOG token        = 151662 '<|fim_pad|>'
print_info: EOG token        = 151663 '<|repo_name|>'
print_info: EOG token        = 151664 '<|file_sep|>'
print_info: max token length = 256
llama_model_load: vocab only - skipping tensors
time=2025-05-05T23:15:53.123+01:00 level=INFO source=server.go:405 msg="starting llama server" cmd="/Applications/Ollama.app/Contents/Resources/ollama runner --model /Users/neidu/.ollama/models/blobs/sha256-a3de86cd1c132c822487ededd47a324c50491393e6565cd14bafa40d0b8e686f --ctx-size 8192 --batch-size 512 --threads 6 --no-mmap --parallel 4 --port 60692"
time=2025-05-05T23:15:53.128+01:00 level=INFO source=sched.go:451 msg="loaded runners" count=1
time=2025-05-05T23:15:53.128+01:00 level=INFO source=server.go:580 msg="waiting for llama runner to start responding"
time=2025-05-05T23:15:53.129+01:00 level=INFO source=server.go:614 msg="waiting for server to become available" status="llm server error"
time=2025-05-05T23:15:53.166+01:00 level=INFO source=runner.go:853 msg="starting go runner"
load_backend: loaded CPU backend from /Applications/Ollama.app/Contents/Resources/libggml-cpu-haswell.so
time=2025-05-05T23:15:53.205+01:00 level=INFO source=ggml.go:109 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.LLAMAFILE=1 CPU.1.SSE3=1 CPU.1.SSSE3=1 CPU.1.LLAMAFILE=1 compiler=cgo(clang)
time=2025-05-05T23:15:53.206+01:00 level=INFO source=runner.go:913 msg="Server listening on 127.0.0.1:60692"
llama_model_loader: loaded meta data with 28 key-value pairs and 399 tensors from /Users/neidu/.ollama/models/blobs/sha256-a3de86cd1c132c822487ededd47a324c50491393e6565cd14bafa40d0b8e686f (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = qwen3
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Qwen3 8B
llama_model_loader: - kv   3:                           general.basename str              = Qwen3
llama_model_loader: - kv   4:                         general.size_label str              = 8B
llama_model_loader: - kv   5:                            general.license str              = apache-2.0
llama_model_loader: - kv   6:                          qwen3.block_count u32              = 36
llama_model_loader: - kv   7:                       qwen3.context_length u32              = 40960
llama_model_loader: - kv   8:                     qwen3.embedding_length u32              = 4096
llama_model_loader: - kv   9:                  qwen3.feed_forward_length u32              = 12288
llama_model_loader: - kv  10:                 qwen3.attention.head_count u32              = 32
llama_model_loader: - kv  11:              qwen3.attention.head_count_kv u32              = 8
llama_model_loader: - kv  12:                       qwen3.rope.freq_base f32              = 1000000.000000
llama_model_loader: - kv  13:     qwen3.attention.layer_norm_rms_epsilon f32              = 0.000001
llama_model_loader: - kv  14:                 qwen3.attention.key_length u32              = 128
llama_model_loader: - kv  15:               qwen3.attention.value_length u32              = 128
llama_model_loader: - kv  16:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  17:                         tokenizer.ggml.pre str              = qwen2
llama_model_loader: - kv  18:                      tokenizer.ggml.tokens arr[str,151936]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  19:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  20:                      tokenizer.ggml.merges arr[str,151387]  = ["Ġ Ġ", "ĠĠ ĠĠ", "i n", "Ġ t",...
llama_model_loader: - kv  21:                tokenizer.ggml.eos_token_id u32              = 151645
llama_model_loader: - kv  22:            tokenizer.ggml.padding_token_id u32              = 151643
llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 151643
llama_model_loader: - kv  24:               tokenizer.ggml.add_bos_token bool             = false
llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {%- if tools %}\n    {{- '<|im_start|>...
llama_model_loader: - kv  26:               general.quantization_version u32              = 2
llama_model_loader: - kv  27:                          general.file_type u32              = 15
llama_model_loader: - type  f32:  145 tensors
llama_model_loader: - type  f16:   36 tensors
llama_model_loader: - type q4_K:  199 tensors
llama_model_loader: - type q6_K:   19 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 4.86 GiB (5.10 BPW) 
time=2025-05-05T23:15:53.381+01:00 level=INFO source=server.go:614 msg="waiting for server to become available" status="llm server loading model"
load: special tokens cache size = 26
load: token to piece cache size = 0.9311 MB
print_info: arch             = qwen3
print_info: vocab_only       = 0
print_info: n_ctx_train      = 40960
print_info: n_embd           = 4096
print_info: n_layer          = 36
print_info: n_head           = 32
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa_pattern    = 1
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 4
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-06
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 12288
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: rope type        = 2
print_info: rope scaling     = linear
print_info: freq_base_train  = 1000000.0
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 40960
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = ?B
print_info: model params     = 8.19 B
print_info: general.name     = Qwen3 8B
print_info: vocab type       = BPE
print_info: n_vocab          = 151936
print_info: n_merges         = 151387
print_info: BOS token        = 151643 '<|endoftext|>'
print_info: EOS token        = 151645 '<|im_end|>'
print_info: EOT token        = 151645 '<|im_end|>'
print_info: PAD token        = 151643 '<|endoftext|>'
print_info: LF token         = 198 'Ċ'
print_info: FIM PRE token    = 151659 '<|fim_prefix|>'
print_info: FIM SUF token    = 151661 '<|fim_suffix|>'
print_info: FIM MID token    = 151660 '<|fim_middle|>'
print_info: FIM PAD token    = 151662 '<|fim_pad|>'
print_info: FIM REP token    = 151663 '<|repo_name|>'
print_info: FIM SEP token    = 151664 '<|file_sep|>'
print_info: EOG token        = 151643 '<|endoftext|>'
print_info: EOG token        = 151645 '<|im_end|>'
print_info: EOG token        = 151662 '<|fim_pad|>'
print_info: EOG token        = 151663 '<|repo_name|>'
print_info: EOG token        = 151664 '<|file_sep|>'
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = false)
load_tensors:          CPU model buffer size =  4977.62 MiB
[GIN] 2025/05/05 - 23:16:00 | 200 |  199.300427ms |       127.0.0.1 | GET      "/api/tags"
llama_context: constructing llama_context
llama_context: n_seq_max     = 4
llama_context: n_ctx         = 8192
llama_context: n_ctx_per_seq = 2048
llama_context: n_batch       = 2048
llama_context: n_ubatch      = 512
llama_context: causal_attn   = 1
llama_context: flash_attn    = 0
llama_context: freq_base     = 1000000.0
llama_context: freq_scale    = 1
llama_context: n_ctx_per_seq (2048) < n_ctx_train (40960) -- the full capacity of the model will not be utilized
llama_context:        CPU  output buffer size =     2.38 MiB
init: kv_size = 8192, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 36, can_shift = 1
init:        CPU KV buffer size =  1152.00 MiB
llama_context: KV self size  = 1152.00 MiB, K (f16):  576.00 MiB, V (f16):  576.00 MiB
llama_context:        CPU compute buffer size =   560.01 MiB
llama_context: graph nodes  = 1374
llama_context: graph splits = 1
time=2025-05-05T23:16:03.296+01:00 level=INFO source=server.go:619 msg="llama runner started in 10.17 seconds"
[GIN] 2025/05/05 - 23:16:09 | 200 |   25.278415ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:16:09 | 200 |   17.316008ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T23:16:31.112+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T23:16:31.156+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T23:16:31.193+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T23:16:31.195+01:00 level=WARN source=ggml.go:152 msg="key not found" key=qwen3.vision.block_count default=0
time=2025-05-05T23:16:31.197+01:00 level=INFO source=server.go:105 msg="system memory" total="16.0 GiB" free="6.2 GiB" free_swap="0 B"
time=2025-05-05T23:16:31.197+01:00 level=WARN source=ggml.go:152 msg="key not found" key=qwen3.vision.block_count default=0
time=2025-05-05T23:16:31.198+01:00 level=INFO source=server.go:138 msg=offload library=cpu layers.requested=-1 layers.model=37 layers.offload=0 layers.split="" memory.available="[6.2 GiB]" memory.gpu_overhead="0 B" memory.required.full="4.4 GiB" memory.required.partial="0 B" memory.required.kv="1.1 GiB" memory.required.allocations="[4.4 GiB]" memory.weights.total="2.4 GiB" memory.weights.repeating="2.1 GiB" memory.weights.nonrepeating="304.3 MiB" memory.graph.full="768.0 MiB" memory.graph.partial="768.0 MiB"
time=2025-05-05T23:16:31.198+01:00 level=WARN source=server.go:173 msg="flash attention enabled but not supported by gpu"
llama_model_loader: loaded meta data with 27 key-value pairs and 398 tensors from /Users/neidu/.ollama/models/blobs/sha256-163553aea1b1de62de7c5eb2ef5afb756b4b3133308d9ae7e42e951d8d696ef5 (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = qwen3
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Qwen3 4B
llama_model_loader: - kv   3:                           general.basename str              = Qwen3
llama_model_loader: - kv   4:                         general.size_label str              = 4B
llama_model_loader: - kv   5:                          qwen3.block_count u32              = 36
llama_model_loader: - kv   6:                       qwen3.context_length u32              = 40960
llama_model_loader: - kv   7:                     qwen3.embedding_length u32              = 2560
llama_model_loader: - kv   8:                  qwen3.feed_forward_length u32              = 9728
llama_model_loader: - kv   9:                 qwen3.attention.head_count u32              = 32
llama_model_loader: - kv  10:              qwen3.attention.head_count_kv u32              = 8
llama_model_loader: - kv  11:                       qwen3.rope.freq_base f32              = 1000000.000000
llama_model_loader: - kv  12:     qwen3.attention.layer_norm_rms_epsilon f32              = 0.000001
llama_model_loader: - kv  13:                 qwen3.attention.key_length u32              = 128
llama_model_loader: - kv  14:               qwen3.attention.value_length u32              = 128
llama_model_loader: - kv  15:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  16:                         tokenizer.ggml.pre str              = qwen2
llama_model_loader: - kv  17:                      tokenizer.ggml.tokens arr[str,151936]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  18:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  19:                      tokenizer.ggml.merges arr[str,151387]  = ["Ġ Ġ", "ĠĠ ĠĠ", "i n", "Ġ t",...
llama_model_loader: - kv  20:                tokenizer.ggml.eos_token_id u32              = 151645
llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 151643
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 151643
llama_model_loader: - kv  23:               tokenizer.ggml.add_bos_token bool             = false
llama_model_loader: - kv  24:                    tokenizer.chat_template str              = {%- if tools %}\n    {{- '<|im_start|>...
llama_model_loader: - kv  25:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:                          general.file_type u32              = 15
llama_model_loader: - type  f32:  145 tensors
llama_model_loader: - type  f16:   36 tensors
llama_model_loader: - type q4_K:  198 tensors
llama_model_loader: - type q6_K:   19 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 2.44 GiB (5.20 BPW) 
load: special tokens cache size = 26
load: token to piece cache size = 0.9311 MB
print_info: arch             = qwen3
print_info: vocab_only       = 1
print_info: model type       = ?B
print_info: model params     = 4.02 B
print_info: general.name     = Qwen3 4B
print_info: vocab type       = BPE
print_info: n_vocab          = 151936
print_info: n_merges         = 151387
print_info: BOS token        = 151643 '<|endoftext|>'
print_info: EOS token        = 151645 '<|im_end|>'
print_info: EOT token        = 151645 '<|im_end|>'
print_info: PAD token        = 151643 '<|endoftext|>'
print_info: LF token         = 198 'Ċ'
print_info: FIM PRE token    = 151659 '<|fim_prefix|>'
print_info: FIM SUF token    = 151661 '<|fim_suffix|>'
print_info: FIM MID token    = 151660 '<|fim_middle|>'
print_info: FIM PAD token    = 151662 '<|fim_pad|>'
print_info: FIM REP token    = 151663 '<|repo_name|>'
print_info: FIM SEP token    = 151664 '<|file_sep|>'
print_info: EOG token        = 151643 '<|endoftext|>'
print_info: EOG token        = 151645 '<|im_end|>'
print_info: EOG token        = 151662 '<|fim_pad|>'
print_info: EOG token        = 151663 '<|repo_name|>'
print_info: EOG token        = 151664 '<|file_sep|>'
print_info: max token length = 256
llama_model_load: vocab only - skipping tensors
time=2025-05-05T23:16:31.782+01:00 level=INFO source=server.go:405 msg="starting llama server" cmd="/Applications/Ollama.app/Contents/Resources/ollama runner --model /Users/neidu/.ollama/models/blobs/sha256-163553aea1b1de62de7c5eb2ef5afb756b4b3133308d9ae7e42e951d8d696ef5 --ctx-size 8192 --batch-size 512 --threads 6 --no-mmap --parallel 4 --port 61154"
time=2025-05-05T23:16:31.793+01:00 level=INFO source=sched.go:451 msg="loaded runners" count=2
time=2025-05-05T23:16:31.794+01:00 level=INFO source=server.go:580 msg="waiting for llama runner to start responding"
time=2025-05-05T23:16:31.794+01:00 level=INFO source=server.go:614 msg="waiting for server to become available" status="llm server error"
time=2025-05-05T23:16:31.851+01:00 level=INFO source=runner.go:853 msg="starting go runner"
load_backend: loaded CPU backend from /Applications/Ollama.app/Contents/Resources/libggml-cpu-haswell.so
time=2025-05-05T23:16:31.898+01:00 level=INFO source=ggml.go:109 msg=system CPU.0.SSE3=1 CPU.0.SSSE3=1 CPU.0.AVX=1 CPU.0.AVX2=1 CPU.0.F16C=1 CPU.0.FMA=1 CPU.0.BMI2=1 CPU.0.LLAMAFILE=1 CPU.1.SSE3=1 CPU.1.SSSE3=1 CPU.1.LLAMAFILE=1 compiler=cgo(clang)
time=2025-05-05T23:16:31.899+01:00 level=INFO source=runner.go:913 msg="Server listening on 127.0.0.1:61154"
llama_model_loader: loaded meta data with 27 key-value pairs and 398 tensors from /Users/neidu/.ollama/models/blobs/sha256-163553aea1b1de62de7c5eb2ef5afb756b4b3133308d9ae7e42e951d8d696ef5 (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = qwen3
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Qwen3 4B
llama_model_loader: - kv   3:                           general.basename str              = Qwen3
llama_model_loader: - kv   4:                         general.size_label str              = 4B
llama_model_loader: - kv   5:                          qwen3.block_count u32              = 36
llama_model_loader: - kv   6:                       qwen3.context_length u32              = 40960
llama_model_loader: - kv   7:                     qwen3.embedding_length u32              = 2560
llama_model_loader: - kv   8:                  qwen3.feed_forward_length u32              = 9728
llama_model_loader: - kv   9:                 qwen3.attention.head_count u32              = 32
llama_model_loader: - kv  10:              qwen3.attention.head_count_kv u32              = 8
llama_model_loader: - kv  11:                       qwen3.rope.freq_base f32              = 1000000.000000
llama_model_loader: - kv  12:     qwen3.attention.layer_norm_rms_epsilon f32              = 0.000001
llama_model_loader: - kv  13:                 qwen3.attention.key_length u32              = 128
llama_model_loader: - kv  14:               qwen3.attention.value_length u32              = 128
llama_model_loader: - kv  15:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  16:                         tokenizer.ggml.pre str              = qwen2
llama_model_loader: - kv  17:                      tokenizer.ggml.tokens arr[str,151936]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  18:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
time=2025-05-05T23:16:32.049+01:00 level=INFO source=server.go:614 msg="waiting for server to become available" status="llm server loading model"
llama_model_loader: - kv  19:                      tokenizer.ggml.merges arr[str,151387]  = ["Ġ Ġ", "ĠĠ ĠĠ", "i n", "Ġ t",...
llama_model_loader: - kv  20:                tokenizer.ggml.eos_token_id u32              = 151645
llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 151643
llama_model_loader: - kv  22:                tokenizer.ggml.bos_token_id u32              = 151643
llama_model_loader: - kv  23:               tokenizer.ggml.add_bos_token bool             = false
llama_model_loader: - kv  24:                    tokenizer.chat_template str              = {%- if tools %}\n    {{- '<|im_start|>...
llama_model_loader: - kv  25:               general.quantization_version u32              = 2
llama_model_loader: - kv  26:                          general.file_type u32              = 15
llama_model_loader: - type  f32:  145 tensors
llama_model_loader: - type  f16:   36 tensors
llama_model_loader: - type q4_K:  198 tensors
llama_model_loader: - type q6_K:   19 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = Q4_K - Medium
print_info: file size   = 2.44 GiB (5.20 BPW) 
load: special tokens cache size = 26
load: token to piece cache size = 0.9311 MB
print_info: arch             = qwen3
print_info: vocab_only       = 0
print_info: n_ctx_train      = 40960
print_info: n_embd           = 2560
print_info: n_layer          = 36
print_info: n_head           = 32
print_info: n_head_kv        = 8
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: n_swa_pattern    = 1
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 4
print_info: n_embd_k_gqa     = 1024
print_info: n_embd_v_gqa     = 1024
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-06
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 9728
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: rope type        = 2
print_info: rope scaling     = linear
print_info: freq_base_train  = 1000000.0
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 40960
print_info: rope_finetuned   = unknown
print_info: ssm_d_conv       = 0
print_info: ssm_d_inner      = 0
print_info: ssm_d_state      = 0
print_info: ssm_dt_rank      = 0
print_info: ssm_dt_b_c_rms   = 0
print_info: model type       = ?B
print_info: model params     = 4.02 B
print_info: general.name     = Qwen3 4B
print_info: vocab type       = BPE
print_info: n_vocab          = 151936
print_info: n_merges         = 151387
print_info: BOS token        = 151643 '<|endoftext|>'
print_info: EOS token        = 151645 '<|im_end|>'
print_info: EOT token        = 151645 '<|im_end|>'
print_info: PAD token        = 151643 '<|endoftext|>'
print_info: LF token         = 198 'Ċ'
print_info: FIM PRE token    = 151659 '<|fim_prefix|>'
print_info: FIM SUF token    = 151661 '<|fim_suffix|>'
print_info: FIM MID token    = 151660 '<|fim_middle|>'
print_info: FIM PAD token    = 151662 '<|fim_pad|>'
print_info: FIM REP token    = 151663 '<|repo_name|>'
print_info: FIM SEP token    = 151664 '<|file_sep|>'
print_info: EOG token        = 151643 '<|endoftext|>'
print_info: EOG token        = 151645 '<|im_end|>'
print_info: EOG token        = 151662 '<|fim_pad|>'
print_info: EOG token        = 151663 '<|repo_name|>'
print_info: EOG token        = 151664 '<|file_sep|>'
print_info: max token length = 256
load_tensors: loading model tensors, this can take a while... (mmap = false)
load_tensors:          CPU model buffer size =  2493.69 MiB
[GIN] 2025/05/05 - 23:16:34 | 200 | 42.215959447s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 23:16:36 | 200 |   59.851142ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T23:16:36.356+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
time=2025-05-05T23:16:39.166+01:00 level=INFO source=server.go:614 msg="waiting for server to become available" status="llm server not responding"
time=2025-05-05T23:16:39.457+01:00 level=INFO source=server.go:614 msg="waiting for server to become available" status="llm server loading model"
llama_context: constructing llama_context
llama_context: n_seq_max     = 4
llama_context: n_ctx         = 8192
llama_context: n_ctx_per_seq = 2048
llama_context: n_batch       = 2048
llama_context: n_ubatch      = 512
llama_context: causal_attn   = 1
llama_context: flash_attn    = 0
llama_context: freq_base     = 1000000.0
llama_context: freq_scale    = 1
llama_context: n_ctx_per_seq (2048) < n_ctx_train (40960) -- the full capacity of the model will not be utilized
llama_context:        CPU  output buffer size =     2.36 MiB
init: kv_size = 8192, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 36, can_shift = 1
init:        CPU KV buffer size =  1152.00 MiB
llama_context: KV self size  = 1152.00 MiB, K (f16):  576.00 MiB, V (f16):  576.00 MiB
llama_context:        CPU compute buffer size =   554.01 MiB
llama_context: graph nodes  = 1374
llama_context: graph splits = 1
time=2025-05-05T23:16:43.046+01:00 level=INFO source=server.go:619 msg="llama runner started in 11.25 seconds"
[GIN] 2025/05/05 - 23:16:49 | 200 |   29.817006ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:16:49 | 200 |   13.937425ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:17:12 | 200 |   13.945097ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:17:22 | 200 |   12.736818ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:17:22 | 200 |   18.697545ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:17:26 | 200 | 50.555125016s |       127.0.0.1 | POST     "/v1/chat/completions"
time=2025-05-05T23:17:26.863+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 23:17:48 | 200 |    24.32684ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:18:08 | 200 |   19.513589ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:18:08 | 200 |   11.503128ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:18:24 | 200 |    10.99606ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:19:00 | 200 |   22.794111ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:19:09 | 200 |         1m42s |       127.0.0.1 | POST     "/v1/chat/completions"
time=2025-05-05T23:19:10.205+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 23:19:36 | 200 |   43.508068ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:20:12 | 200 |   17.503672ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:20:48 | 200 |   95.760022ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:21:02 | 200 |         1m51s |       127.0.0.1 | POST     "/v1/chat/completions"
time=2025-05-05T23:21:02.707+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 23:21:24 | 200 |   23.293204ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:21:30 | 200 |         4m59s |       127.0.0.1 | POST     "/api/chat"
[GIN] 2025/05/05 - 23:21:40 | 200 | 38.296319624s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 23:22:00 | 200 |   23.472196ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:22:36 | 200 |   18.816046ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:23:12 | 200 |    8.039895ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:23:48 | 200 |   19.721013ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:24:24 | 200 |   21.699246ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:25:00 | 200 |    7.700684ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:25:36 | 200 |   13.906459ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:26:12 | 200 |    9.835704ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:26:48 | 200 |    9.132331ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:27:24 | 200 |   20.943032ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:28:00 | 200 |   15.632618ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:28:36 | 200 |   22.302042ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:29:12 | 200 |   13.344779ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:29:48 | 200 |    20.27901ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:30:24 | 200 |   14.608687ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:31:00 | 200 |   20.062207ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:31:36 | 200 |    9.360686ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:32:12 | 200 |   21.428393ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:32:48 | 200 |   20.814731ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:33:24 | 200 |   17.119132ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:34:00 | 200 |   22.119851ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:34:36 | 200 |    8.914731ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T23:35:03.253+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 23:35:12 | 200 |   23.770561ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:35:28 | 200 | 25.478635562s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 23:35:48 | 200 |    8.838857ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:36:24 | 200 |    9.123473ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:37:00 | 200 |    8.993436ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T23:37:22.626+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 23:37:36 | 200 |   11.957114ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:37:42 | 200 | 20.400077209s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 23:38:12 | 200 |    8.452713ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:38:48 | 200 |    7.910769ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:39:24 | 200 |   13.675324ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:40:00 | 200 |   20.743249ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:40:36 | 200 |   14.429327ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:41:12 | 200 |   13.576008ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:41:48 | 200 |    8.488458ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:42:24 | 200 |   13.385428ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:43:00 | 200 |   17.620586ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:43:36 | 200 |   14.151193ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:44:12 | 200 |   14.831523ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:44:48 | 200 |   14.285463ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:45:24 | 200 |   13.021461ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:46:00 | 200 |    8.497851ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:46:36 | 200 |    7.507784ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:47:12 | 200 |     7.66612ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:47:48 | 200 |   50.300048ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:48:24 | 200 |    8.470468ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T23:48:33.552+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 23:48:58 | 200 | 24.653385991s |       127.0.0.1 | POST     "/v1/chat/completions"
time=2025-05-05T23:48:58.200+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 23:49:00 | 200 |   11.677741ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:49:35 | 200 | 37.017820176s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 23:49:36 | 200 |    8.116856ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:50:12 | 200 |   22.546436ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T23:50:46.935+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 23:50:48 | 200 |    9.649919ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:51:24 | 200 |   14.118305ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:51:24 | 200 | 37.872517767s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 23:52:00 | 200 |    9.848218ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:52:36 | 200 |   13.788442ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T23:52:37.133+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 23:52:57 | 200 | 20.120075179s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 23:53:12 | 200 |    7.830594ms |       127.0.0.1 | GET      "/api/tags"
time=2025-05-05T23:53:42.896+01:00 level=WARN source=ggml.go:152 msg="key not found" key=general.alignment default=32
[GIN] 2025/05/05 - 23:53:48 | 200 |   12.240955ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:54:02 | 200 | 19.643397836s |       127.0.0.1 | POST     "/v1/chat/completions"
[GIN] 2025/05/05 - 23:54:24 | 200 |    9.454861ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/05 - 23:55:00 | 200 |    8.961907ms |       127.0.0.1 | GET      "/api/tags"
